@inproceedings{zemirlineAssistingReuseAdaptive2008,
  title = {Assisting in {{Reuse}} of {{Adaptive Hypermedia Creator}}'s {{Models}}},
  booktitle = {Adaptive {{Hypermedia}} and {{Adaptive Web-Based Systems}}},
  author = {Zemirline, Nadjet and Bourda, Yolaine and Reynaud, Chantal and Popineau, Fabrice},
  editor = {Nejdl, Wolfgang and Kay, Judy and Pu, Pearl and Herder, Eelco},
  year = {2008},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {5149},
  pages = {357--360},
  publisher = {Springer Berlin Heidelberg},
  address = {Hannover,, Germany},
  doi = {10.1007/978-3-540-70987-9\_53},
  urldate = {2019-05-08},
  abstract = {The design of Adaptive Hypermedia is a difficult task which can be made easier if generic systems and AH creators' models are reused. We address this design problem in the setting of the GLAM platform only made up of generic components. We present a rule-based approach helping an AH creator in reusing its user and domain models to create a specific adaptive hypermedia. This semi-automatic approach takes the creator's models as specialisations of GLAM generic models and requires the creator to express a minimum set of mappings between his models and the generic ones. The process results in a merged model consisting of the generic and the corresponding specific model. This merged model can be used by the adaptation model.},
  isbn = {978-3-540-70984-8},
  langid = {english},
  keywords = {conf,EIAH,Invalid DOI,VAE},
  file = {files/2537/Zemirline et al. - 2008 - Assisting in Reuse of Adaptive Hypermedia Creator’.pdf}
}

@incollection{hayAutomaticallySelectingComplementary2018,
  title = {Automatically {{Selecting Complementary Vector Representations}} for {{Semantic Textual Similarity}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Management}}: {{Volume}} 8},
  author = {Hay, Julien and {Van de Cruys}, Tim and Muller, Philippe and Doan, Bich-Li{\^e}n and Popineau, Fabrice and Hay, Julien and Van De Cruys, Tim and Muller, Philippe and Doan, Bich-Lien and Popineau, Fabrice and Ouassim, Ait-Elhara},
  editor = {Pinaud, Bruno and Guillet, Fabrice and Gandon, Fabien and Largeron, Christine},
  year = {2018},
  series = {Studies in {{Computational Intelligence}}},
  volume = {834},
  pages = {45--60},
  publisher = {Springer International Publishing},
  address = {Cham},
  abstract = {The goal of the Semantic Textual Similarity task is to automatically quantify the semantic similarity of two text snippets. Since 2012, the task has been organized on a yearly basis as a part of the SemEval evaluation campaign. This paperHay, Julien~presentsVan de Cruys, Tim~a method that aims to combine differentMuller, Philippe~sentence-based vector representations in order to improve the computation of semantic similarity values. Our hypothesis is that such a combinationDoan, Bich-Li{\^e}n~of different representations allows us to pinpoint different semantic aspects, which improves the accuracy ofPopineau, Fabrice~similarity computations. The method's main difficulty lies in the selection of the most complementaryAit-Elhara, Ouassim{\textasciitilde} representations, for which we present an optimization method. Our final system is based on the winning system of the 2015 evaluation campaign, augmented with the complementary vector representations selected by our optimization method. We also present evaluation results on the dataset of the 2016 campaign, which confirms the benefit of our method.},
  copyright = {All rights reserved},
  isbn = {978-3-030-18129-1},
  keywords = {inbook,Invalid DOI,IR},
  file = {files/5551/Hay et al. - 2019 - Automatically Selecting Complementary Vector Repre.pdf;files/9030/Hay et al. - 2018 - Automatically selecting complementary vector repre.pdf}
}

@inproceedings{dubusParametricReasoningAgents2013,
  title = {Parametric {{Reasoning Agents Extend}} the {{Control}} over {{Standard Behaviors}}},
  booktitle = {2013 {{IEEE}}/{{WIC}}/{{ACM International Joint Conferences}} on {{Web Intelligence}} ({{WI}}) and {{Intelligent Agent Technologies}} ({{IAT}})},
  author = {Dubus, Georges and Popineau, Fabrice and Bourda, Yolaine and Sansonnet, Jean-Paul},
  year = {2013},
  month = nov,
  volume = {2},
  pages = {163--170},
  publisher = {IEEE},
  address = {Atlanta, GA, USA},
  doi = {10.1109/WI-IAT.2013.105},
  urldate = {2019-12-21},
  abstract = {In this paper, we study how to extend the control over the behavioral space of logically specified agents so as they can take into account parameters issuing from constraints and/or preferences that are external to their core reasoning process. Our approach is supported by the proposition of a set of generic transformations to apply to the original agent program that is expressed in IndiGolog, a variant of the Golog language. Several of these transformations exploit the non-determinism present in IndiGolog programs. We also propose an automatic process to apply all those transformations on the basis of a set of parameters. Three case-studies show the significance of the approach in situations where agents are in interaction with human users.},
  isbn = {978-0-7695-5145-6},
  langid = {english},
  keywords = {conf,EIAH,VAE},
  file = {files/5557/Dubus et al. - 2013 - Parametric Reasoning Agents Extend the Control ove.pdf}
}

@inproceedings{jacquiotGLAMGenericLayered2006,
  title = {{{GLAM}}: {{A}} Generic Layered Adaptation Model for Adaptive Hypermedia Systems},
  booktitle = {Adaptive Hypermedia and Adaptive Web-Based Systems, 4th International Conference, {{AH}} 2006, Dublin, Ireland, June 21-23, 2006, Proceedings},
  author = {Jacquiot, C{\'e}dric and Bourda, Yolaine and Popineau, Fabrice and Delteil, Alexandre and Reynaud, Chantal},
  editor = {V. Wade, H. Ashman and Smyth, B.},
  year = {2006},
  month = jun,
  series = {{{LNCS}}},
  volume = {4018},
  pages = {131--140},
  publisher = {Springer-Verlag},
  copyright = {All rights reserved},
  keywords = {conf,EIAH,Invalid DOI,VAE},
  file = {files/8975/Jacquiot et al. - 2006 - GLAM A generic layered adaptation model for adapt.pdf}
}

@inproceedings{zemirlinePatternRulebasedApproach2008,
  title = {A Pattern and Rule-Based Approach for Reusing Adaptive Hypermedia Creator's Models},
  booktitle = {Proceedings of 16th International Conference on Knowledge Engineering and Knowledge Management Knowledge Patterns},
  author = {Zemirline, Nadjet and Reynaud, Chantal and Bourda, Yolaine and Popineau, Fabrice},
  editor = {Gangemi, Aldo and Euzenat, J{\'e}r{\^o}me},
  year = {2008},
  series = {Lecture Notes in Computer Science},
  volume = {5268},
  pages = {17--31},
  publisher = {Springer-Verlag},
  address = {Acitrezza, Catania, Italie},
  doi = {10.1007/978-3-540-87696-0\_5},
  copyright = {All rights reserved},
  keywords = {conf,EIAH,Invalid DOI,Multiple DOI,VAE},
  file = {files/9109/Zemirline et al. - 2008 - A pattern and rule-based approach for reusing adap.pdf}
}

@inproceedings{meguebliBuildingRichUser2014,
  title = {Building Rich User Profiles for Personalized News Recommendation},
  booktitle = {{{UMAP}} 2014 {{Extended Proceedings}}},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2014},
  month = jul,
  pages = {33--40},
  address = {Aalborg, Denmark},
  copyright = {All rights reserved},
  keywords = {conf,IR,VAE},
  file = {files/8974/Meguebli et al. - 2014 - Building rich user profiles for personalized news .pdf}
}

@inproceedings{meguebliUnsupervisedApproachIdentifying2014,
  title = {Unsupervised Approach for Identifying Users' Political Orientations},
  booktitle = {Advances in Information Retrieval - 36th European Conference on {{IR}} Research, {{ECIR}} 2014, Amsterdam, the Netherlands, April 13-16, 2014. {{Proceedings}}},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  editor = {{de Rijke}, Maarten and Kenter, Tom and {de Vries}, Arjen P. and Zhai, ChengXiang and {de Jong}, Franciska and Radinsky, Kira and Hofmann, Katja},
  year = {2014},
  series = {Lecture Notes in Computer Science},
  volume = {8416},
  pages = {507--512},
  publisher = {Springer},
  doi = {10/ghfbvc},
  copyright = {All rights reserved},
  keywords = {conf,Invalid DOI,IR},
  file = {files/9020/Meguebli et al. - 2014 - Unsupervised approach for identifying users' polit.pdf}
}

@inproceedings{popineauPersonalizationPersonificationConstructive2014,
  title = {Personalization and Personification: {{A}} Constructive Approach Based on Parametric Agents},
  booktitle = {Intelligent Virtual Agents - 14th International Conference, {{IVA}} 2014},
  author = {Popineau, Fabrice and Dubus, Georges and Bourda, Yolaine},
  editor = {Bickmore, Timothy W. and Marsella, Stacy and Sidner, Candace L.},
  year = {2014},
  month = aug,
  series = {Lecture Notes in Computer Science},
  volume = {8637},
  pages = {339--344},
  publisher = {Springer},
  address = {Boston, MA, USA},
  doi = {10.1007/978-3-319-09767-1\_44},
  copyright = {All rights reserved},
  keywords = {conf,EIAH,Invalid DOI,VAE},
  file = {files/9089/Popineau et al. - 2014 - Personalization and personification A constructiv.pdf}
}

@article{vieSimulationValidationTests2017,
  title = {Simulation et Validation de Tests Adaptatifs Dans Les {{MOOC}}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Bruillard, Eric and Bourda, Yolaine},
  year = {2017},
  journal = {Sciences et Technologies de l'Information et de la Communication pour l'{\'E}ducation et la Formation},
  volume = {24},
  number = {2},
  pages = {149--167},
  doi = {10/ghfbvd},
  copyright = {All rights reserved},
  keywords = {EIAH,journalnat},
  file = {files/9019/Vie et al. - 2017 - Simulation et validation de tests adaptatifs dans .pdf}
}

@inproceedings{jacquiotSEWAGOGenericAdaptive2003,
  title = {{{SEWAGO}} : {{A}} Generic Adaptive Educational Hypermedia System.},
  booktitle = {{{HYPERTEXT}} '03: {{Proceedings}} of the Fourteenth {{ACM}} Conference on {{Hypertext}} and {{Hypermedia}}},
  author = {Jacquiot, C{\'e}dric and Bourda, Yolaine and Popineau, Fabrice},
  year = {2003},
  month = aug,
  address = {Nottingham, UK},
  abstract = {In this document, we explain the main principles and architecture of SEWAGO (SEveral WAys to GO), a generic adaptive educational hypermedia system we are working on. More precisely, SEWAGO is a platform for creating adaptive educational hypermedias, using the strictest and most reusable architecture. This system is based on first order logic and situation calculus (through a modified version of GoLog).},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {EIAH,poster,VAE},
  file = {files/8977/Jacquiot et al. - 2003 - SEWAGO  A generic adaptive educational hypermedia.pdf;files/9133/57f87d94bee05f3c3433ded9d043a4fa77660cad.html}
}

@article{popineauRapiditeSouplesseAvec1997,
  title = {Rapidit{\'e} et Souplesse Avec Le Moteur {{Web2C-7}}},
  author = {Popineau, Fabrice},
  year = {1997},
  journal = {Cahiers GUTenberg},
  number = {26},
  pages = {96--108},
  doi = {10/ghfbvg},
  keywords = {conf,TeX},
  file = {files/8965/Popineau - 1997 - Rapidité et souplesse avec le moteur Web2C-7.pdf;files/9153/Popineau - 1997 - Rapidité et souplesse avec le moteur Web2C-7.pdf}
}

@article{popineauWindviUserManual1998,
  title = {Windvi User's Manual},
  author = {Popineau, Fabrice},
  year = {1998},
  journal = {MAPS},
  volume = {20},
  pages = {146--149},
  keywords = {journal,TeX},
  file = {files/8968/Popineau - 1998 - Windvi user’s manual.pdf}
}

@misc{popineauUKTUGSpecialWin321999,
  title = {{{UK-TUG}} Special Win32 Meeting},
  author = {Popineau, Fabrice},
  year = {1999},
  month = may,
  keywords = {conf,TeX},
  file = {files/9152/Popineau - 1999 - UK-TUG special win32 meeting.pdf}
}

@article{popineauInformacjaNtTeXLive2001,
  title = {Informacja Nt. {{TeXLive}} 6 (Information about {{TeXlive}} 6)},
  author = {Popineau, Fabrice and Wawrykiewicz, Stanislaw},
  year = {2001},
  month = apr,
  keywords = {poster,TeX}
}

@article{popineauStatusFutureTeXLive2002,
  title = {Status and Future of {{TeXLive}}},
  author = {Popineau, Fabrice},
  year = {2002},
  month = feb,
  keywords = {poster,TeX}
}

@article{popineauTeXLiveWindowsWhat2002,
  title = {{{TeXLive}} under {{Windows}}: What's New with the 7th Edition?},
  author = {Popineau, Fabrice},
  year = {2002},
  month = sep,
  journal = {TUGBoat},
  volume = {23},
  number = {1},
  pages = {74--79},
  abstract = {The 7th edition of TEX Live under Windows has some new features that are explained in this paper. Especially notable are two experiments to extend Kpathsea beyond its original abilities: {$\bullet$} sharing Kpathsea data-structures between several processes for faster processing, {$\bullet$} allow url's in client programs as well as filenames whenever they ask Kpathsea to open a file. Additional points about the TeXSetup.exe program and the evolution of other parts of the distribution will also be discussed.},
  langid = {english},
  keywords = {conf,TeX},
  file = {files/9137/Popineau - 2002 - TeXLive under Windows what's new with the 7ᵗʰ edi.pdf}
}

@article{chaixXEmTeXProject2003,
  title = {The {{XEmTeX}} Project},
  author = {Chaix, Marie-Louise and Popineau, Fabrice},
  year = {2003},
  month = jun,
  journal = {TUGBoat},
  volume = {24},
  number = {3},
  pages = {415--419},
  keywords = {conf,TeX},
  file = {files/9149/Chaix et Popineau - 2003 - The XEmTeX project.pdf}
}

@article{chaixXEmTeXIntegratedPlatform2003,
  title = {{{XEmTeX}}: {{An}} Integrated Platform for High Quality Scientific Typesetting},
  author = {Chaix, Marie-Louise and Popineau, Fabrice},
  year = {2003},
  month = jul,
  keywords = {poster,TeX}
}

@inproceedings{hayRepresentationLearningWriting2020,
  title = {Representation Learning of Writing Style},
  booktitle = {Proceedings of the {{Sixth Workshop}} on {{Noisy User-generated Text}} ({{W-NUT}} 2020)},
  author = {Hay, Julien and Doan, Bich-Lien and Popineau, Fabrice and Ait Elhara, Ouassim},
  year = {2020},
  month = nov,
  pages = {232--243},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2020.wnut-1.30},
  urldate = {2021-03-16},
  abstract = {In this paper, we introduce a new method of representation learning that aims to embed documents in a stylometric space. Previous studies in the field of authorship analysis focused on feature engineering techniques in order to represent document styles and to enhance model performance in specific tasks. Instead, we directly embed documents in a stylometric space by relying on a reference set of authors and the intra-author consistency property which is one of two components in our definition of writing style. The main intuition of this paper is that we can define a general stylometric space from a set of reference authors such that, in this space, the coordinates of different documents will be close when the documents are by the same author, and spread away when they are by different authors, even for documents by authors who are not in the set of reference authors. The method we propose allows for the clustering of documents based on stylistic clues reflecting the authorship of documents. For the empirical validation of the method, we train a deep neural network model to predict authors of a large reference dataset consisting of news and blog articles. Albeit the learning process is supervised, it does not require a dedicated labeling of the data but it relies only on the metadata of the articles which are available in huge amounts. We evaluate the model on multiple datasets, on both the authorship clustering and the authorship attribution tasks.},
  keywords = {conf,IR},
  annotation = {ZSCC: 0000000},
  file = {files/8215/Hay et al. - 2020 - Representation learning of writing style.pdf}
}

@inproceedings{hayFilteringReferenceCorpus2021,
  title = {Filtering a {{Reference Corpus}} to {{Generalize Stylometric Representations}}},
  booktitle = {12th {{International Conference}} on {{Knowledge Discovery}} and {{Information Retrieval}}},
  author = {Hay, Julien and Doan, Bich-Li{\^e}n and Popineau, Fabrice and Elhara, Ouassim},
  year = {2021},
  month = mar,
  pages = {259--268},
  urldate = {2021-03-16},
  abstract = {Digital Library},
  copyright = {All rights reserved},
  isbn = {978-989-758-474-9},
  keywords = {conf,IR},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {files/9025/Hay et al. - 2021 - Filtering a Reference Corpus to Generalize Stylome.pdf;files/8217/Link.html}
}

@inproceedings{choffinEvaluatingDAS3HEdNet2021,
  title = {Evaluating {{DAS3H}} on the {{EdNet Dataset}}},
  booktitle = {{{AAAI}} 2021 - {{The}} 35th {{Conference}} on {{Artificial Intelligence}} / {{Imagining Post-COVID Education}} with {{AI}}},
  author = {Choffin, Beno{\^i}t and Popineau, Fabrice and Bourda, Yolaine and Vie, Jill-J{\^e}nn},
  year = {2021},
  pages = {8},
  abstract = {The EdNet dataset is a massive English language dataset that poses unique challenges for student performance prediction. In this paper, we describe and comment the results of our award-winning model DAS3H in the context of knowledge tracing in EdNet.},
  langid = {english},
  keywords = {conf,EIAH},
  file = {files/9021/Choffin et al. - 2021 - Evaluating DAS3H on the EdNet Dataset.pdf}
}

@article{choffinModellingStudentLearning2020,
  title = {Modelling Student Learning and Forgetting for Optimally Scheduling Skill Review},
  author = {Choffin, Beno{\^i}t and Popineau, Fabrice and Bourda, Yolaine},
  year = {2020},
  journal = {ERCIM News},
  volume = {2020},
  number = {120},
  keywords = {artificial intelligence in education,EIAH,learning analytics,other,otherpub},
  file = {files/9028/Choffin et al. - 2020 - Modelling student learning and forgetting for opti.pdf}
}

@inproceedings{bourdaTuteursIntelligentsBoucler2018,
  title = {{Tuteurs intelligents : boucler la boucle}},
  booktitle = {{PFIA 2018 - Journ{\'e}e << IA pour l'{\'e}ducation >>}},
  author = {Bourda, Yolaine and Chaudet, Claude and Choffin, Beno{\^i}t and Parmentier, Jeanne and Popineau, Fabrice and Vie, Jill-J{\^e}nn},
  year = {2018},
  month = jul,
  pages = {4},
  langid = {french},
  keywords = {EIAH,poster,VAE},
  file = {files/9031/Bourda et al. - 2018 - Tuteurs intelligents  boucler la boucle.pdf}
}

@incollection{hajriPersonalizedRecommendationOpen2018,
  title = {Personalized {{Recommendation}} of {{Open Educational Resources}} in {{MOOCs}}},
  booktitle = {Computer {{Supported Education}} - 10th {{International Conference}}, {{CSEDU}} 2018, {{Funchal}}, {{Madeira}}, {{Portugal}}, {{March}} 15-17, 2018, {{Revised Selected Papers}}},
  author = {Hajri, Hiba and Bourda, Yolaine and Popineau, Fabrice},
  editor = {McLaren, Bruce M. and Reilly, Rob and Zvacek, Susan and Uhomoibhi, James},
  year = {2018},
  series = {Communications in {{Computer}} and {{Information Science}}},
  volume = {1022},
  pages = {166--190},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-21151-6_9},
  urldate = {2021-08-07},
  abstract = {Today Online Learning Environments (OLE) like MOOCs and LMS are very commonly used and a huge number of students with very different profiles and backgrounds follow the same online courses. Still, personalized experience for attendees is not widely spread on the platforms hosting these courses. At the same time, there is a growing number of open educational resources (OER) that can helpfully enrich the content of online courses and even be chosen to match one-by-one the student tastes. Recommender systems may support personalization in OLE by providing each learner with learning objects carefully selected to help reaching their learning objectives. This kind of recommendation is more specific to compute than usual recommendations like consumer products: the recommendation depends not only on the learner profile, but also on the content of the course, because the recommendation needs to fit precisely with the course format at any point. In this article, we introduce MOORS, a MOOC-based OER recommender system that can be plugged in an OLE to dynamically provide recommendations of OER to learners on the basis of their profiles and the profile of the MOOC. We also describe the process for calculating recommendations from OER metadata, assuming these metadata follow the Linked Opend Data (LOD) principles. Our implementation has been done in Open edX, an open source MOOC platform widely used, however the same approach could be implemented in any OLE as long as the learners profiles and the course profile can be extracted. Finally, we discuss a life-size evaluation of our recommender system.},
  isbn = {978-3-030-21150-9},
  langid = {english},
  keywords = {conf,EIAH,inbook,Invalid DOI,VAE},
  file = {files/9036/Hajri et al. - 2018 - Personalized Recommendation of Open Educational Re.pdf}
}

@inproceedings{hajriSystemRecommendOpen2018,
  title = {A {{System}} to {{Recommend Open Educational Resources}} during an {{Online Course}}:},
  shorttitle = {A {{System}} to {{Recommend Open Educational Resources}} during an {{Online Course}}},
  booktitle = {Proceedings of the 10th {{International Conference}} on {{Computer Supported Education}}},
  author = {Hajri, Hiba and Bourda, Yolaine and Popineau, Fabrice},
  year = {2018},
  month = mar,
  pages = {99--109},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {Funchal, Madeira, Portugal},
  doi = {10/gmfn5w},
  urldate = {2021-08-07},
  copyright = {All rights reserved},
  isbn = {978-989-758-291-2},
  langid = {english},
  keywords = {conf,EIAH,VAE},
  file = {files/9038/Hajri et al. - 2018 - A System to Recommend Open Educational Resources d.pdf}
}

@article{meguebliBetterNewsArticle2017,
  title = {Towards Better News Article Recommendation: {{With}} the Help of User Comments},
  shorttitle = {Towards Better News Article Recommendation},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2017},
  month = nov,
  journal = {World Wide Web},
  volume = {20},
  number = {6},
  pages = {1293--1312},
  issn = {1386-145X, 1573-1413},
  doi = {10.1007/s11280-017-0436-2},
  urldate = {2021-08-07},
  abstract = {News media platforms publish articles about daily events letting their users comment on them, and forming interesting discussions in almost real-time. To keep users always active and interested, media platforms need an effective recommender system to bring up new articles that match user interests. In this article, we show that we can improve the quality of recommendation by exploiting valuable information provided by user comments. This information reveals aspects not directly tackled by the news article on which they have been posted. We call such aspects latent aspects. We demonstrate how these latent aspects can make a crucial difference in the accuracy of future recommendation. The challenge in detecting them is due to the noisy nature of user comments. To support our claim, we propose a novel news recommendation system that (1) enriches the description of news articles by latent aspects extracted from user comments, (2) deals with noisy comments by proposing a model for user comments ranking, and (3) proposes a diversification model to remove redundancies and provide a wide coverage of aspects. We have tested our approach using large collections of real user activities in four news Web sites, namely The INDEPENDENT, The Telegraph, CNN and Al-Jazeera. The results show that our approach outperforms baseline approaches achieving a significantly higher accuracy.},
  langid = {english},
  keywords = {IR,journal},
  file = {files/9042/Meguebli et al. - 2017 - Towards better news article recommendation With t.pdf}
}

@inproceedings{hajriMORSSystemRecommending2017,
  title = {{{MORS}}: {{A System}} for {{Recommending OERs}} in a {{MOOC}}},
  shorttitle = {{{MORS}}},
  booktitle = {2017 {{IEEE}} 17th {{International Conference}} on {{Advanced Learning Technologies}} ({{ICALT}})},
  author = {Hajri, Hiba and Bourda, Yolaine and Popineau, Fabrice},
  year = {2017},
  month = jul,
  pages = {50--52},
  doi = {10/ghfbvb},
  abstract = {Personalization in the field of Technology Enhanced Learning (TEL) is a topic that received a lot of concern by researchers. At the same time, there is a growing amount of Open Educational Resources (OER) indexed according to the W3C standards. Relevant OERs can usefully complement the contents delivered to a learner during an online course. Computing the best OERs to offer to the learner at each point of his course is an aspect of personalization that we address in this paper. We designed our MORS system to solve this problem in the context of Massive Open Online Courses (MOOC). Our MORS system described in this paper, is based on a learner profile, on metadata describing the course and on a carefully crafted process to query the SparQL endpoints for OERs.},
  copyright = {All rights reserved},
  keywords = {Computational modeling,Computer architecture,conf,Data mining,Education,EIAH,learner profile,learning,Metadata,MOOC,OER,Personalization,recommendation,Recommender systems,VAE,Videos},
  file = {files/9045/Hajri et al. - 2017 - MORS A System for Recommending OERs in a MOOC.pdf;files/9046/8001713.html}
}

@inproceedings{vieHeuristicMethodLargeScale2017,
  title = {A {{Heuristic Method}} for {{Large-Scale Cognitive-Diagnostic Computerized Adaptive Testing}}},
  booktitle = {Proceedings of the {{Fourth}} (2017) {{ACM Conference}} on {{Learning}} @ {{Scale}}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Tort, Fran{\c c}oise and Marteau, Benjamin and Denos, Nathalie},
  year = {2017},
  month = apr,
  pages = {323--326},
  publisher = {ACM},
  address = {Cambridge Massachusetts USA},
  doi = {10/ghfbvf},
  urldate = {2021-08-07},
  abstract = {In formative assessments, one wants to provide a useful feedback to the examinee at the end of the test. In order to reduce the number of questions asked in an assessment, adaptive testing models have been developed for cognitive diagnosis, such as the ones encountered in knowledge space theory. However, when the number of skills assessed is very huge, such methods cannot scale. In this paper, we present a new method to provide adaptive tests and useful feedback to the examinee, even with large databases of skills. It will be used in Pix, a platform for certification of digital competencies for every French citizen.},
  copyright = {All rights reserved},
  isbn = {978-1-4503-4450-0},
  langid = {english},
  keywords = {EIAH,poster},
  file = {files/9047/Vie et al. - 2017 - A Heuristic Method for Large-Scale Cognitive-Diagn.pdf}
}

@incollection{vieReviewRecentAdvances2017,
  title = {A {{Review}} of {{Recent Advances}} in {{Adaptive Assessment}}},
  booktitle = {Learning {{Analytics}}: {{Fundaments}}, {{Applications}}, and {{Trends}}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Bruillard, {\'E}ric and Bourda, Yolaine},
  year = {2017},
  month = feb,
  series = {Studies in {{Systems}}, {{Decision}} and {{Control}}},
  volume = {94},
  pages = {113--142},
  publisher = {Springer International Publishing},
  urldate = {2021-08-07},
  abstract = {Computerized assessments are an increasingly popular way to evaluate students. They need to be optimized so that students can receive an accurate evaluation in as little time as possible. Such optimization is possible through learning analytics and computerized adaptive tests (CATs): the next question is then chosen according to the previous responses of the student, thereby making assessment more efficient. Using the data collected from previous students in non-adaptive tests, it is thus possible to provide formative adaptive tests to new students by telling them what to do next. This chapter reviews several models of CATs found in various fields, together with their main characteristics. We then compare these models empirically on real data. We conclude with a discussion of future research directions for computerized assessments.},
  copyright = {All rights reserved},
  keywords = {adaptive testing,cognitive diagnosis models,EIAH,inbook,item response theory,knowledge space theory,latent knowledge extraction,q-matrix},
  file = {files/9050/Vie et al. - 2017 - A Review of Recent Advances in Adaptive Assessment.pdf}
}

@inproceedings{vieAdaptiveTestingUsing2016,
  title = {Adaptive {{Testing Using}} a {{General Diagnostic Model}}},
  booktitle = {11th {{European Conference}} on {{Technology Enhanced Learning}}, {{EC-TEL}} 2016},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Bruillard, Eric and Bourda, Yolaine},
  year = {2016},
  month = sep,
  series = {Lecture Notes in Computer Science},
  volume = {9891},
  pages = {331--339},
  publisher = {Springer International Publishing},
  address = {Lyon, France},
  doi = {doi:10.1007/978-3-319-45153-4_25},
  urldate = {2021-08-07},
  abstract = {In online learning platforms such as MOOCs, computerized assessment needs to be optimized in order to prevent boredom and dropout of learners. Indeed, they should spend as little time as possible in tests and still receive valuable feedback. It is actually possible to reduce the number of questions for the same accuracy with computerized adaptive testing (CAT): asking the next question according to the past performance of the examinee. CAT algorithms are divided in two categories: summative CATs, that measure the level of examinees, and formative CATs, that provide feedback to the examinees at the end of the test by specifying which knowledge components need further work. In this paper, we formalize the problem of test-size reduction by predicting student performance, and propose a new hybrid CAT algorithm GenMA based on the general diagnostic model, that is both summative and formative. Using real datasets, we compare our model to popular CAT models and show that GenMA achieves better accuracy while using fewer questions than the existing models.},
  copyright = {All rights reserved},
  keywords = {conf,EIAH},
  file = {files/9053/Vie et al. - 2016 - Adaptive Testing Using a General Diagnostic Model.pdf;files/9052/hal-01376944.html}
}

@inproceedings{meguebliPersonalizingInformationRetrieval2016,
  title = {Personalizing {{Information Retrieval Using}} an {{Extension}} of a {{Dung Argumentation}}},
  booktitle = {2016 {{IEEE Intl Conference}} on {{Computational Science}} and {{Engineering}} ({{CSE}}) and {{IEEE Intl Conference}} on {{Embedded}} and {{Ubiquitous Computing}} ({{EUC}}) and 15th {{Intl Symposium}} on {{Distributed Computing}} and {{Applications}} for {{Business Engineering}} ({{DCABES}})},
  author = {Meguebli, Youssef and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2016},
  month = aug,
  pages = {681--686},
  doi = {10/gmfpf5},
  abstract = {In this paper, we propose an architecture for personalizing information retrieval (IR), exploiting the interactions between the user and the social network. We use an extension of a Dung argumentation framework to show how the precision of the personalized information retrieval system could be improved. We use also social media and search history to define the user-profile which is represented by a restriction of a Description Logic.},
  keywords = {Blogs,conf,Conferences,Dung argumentation framework,EIAH,History,Indexes,Information retrieval,IR,opinions engineering,Query processing,social media,Social network services,User-profile model,VAE},
  file = {files/9056/Meguebli et al. - 2016 - Personalizing Information Retrieval Using an Exten.pdf;files/9055/7982323.html}
}

@inproceedings{hajriQueryingRepositoriesOER2015,
  title = {Querying {{Repositories}} of {{OER Descriptions}}: {{The Challenge}} of {{Educational Metadata Schemas Diversity}}},
  shorttitle = {Querying {{Repositories}} of {{OER Descriptions}}},
  booktitle = {Design for {{Teaching}} and {{Learning}} in a {{Networked World}} - 10th {{European Conference}} on {{Technology Enhanced Learning}}, {{EC-TEL}} 2015},
  author = {Hajri, Hiba and Bourda, Yolaine and Popineau, Fabrice},
  year = {2015},
  month = sep,
  series = {Design for {{Teaching}} and {{Learning}} in a {{Networked World}} - 10th {{European Conference}} on {{Technology Enhanced Learning}}, {{EC-TEL}} 2015},
  volume = {LNCS},
  pages = {582--586},
  publisher = {Springer},
  address = {Toledo, Spain},
  doi = {10/gmfpf6},
  urldate = {2021-08-07},
  copyright = {All rights reserved},
  keywords = {conf,EIAH,Invalid DOI,Linked Education,Linked Open Data,Metadata Schemas,VAE},
  file = {files/9059/Hajri et al. - 2015 - Querying Repositories of OER Descriptions The Cha.pdf;files/9058/hal-01275267.html}
}

@inproceedings{viePredictionPerformanceQuestions2015,
  title = {{Pr{\'e}diction de performance sur des questions dichotomiques: comparaison de mod{\`e}les pour des tests adaptatifs {\`a} grande {\'e}chelle}},
  shorttitle = {{Pr{\'e}diction de performance sur des questions dichotomiques}},
  booktitle = {{Atelier {\'E}valuation des Apprentissages et Environnements Informatiques, EIAH 2015}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Grill, Jean-Bastien and Bruillard, Eric and Bourda, Yolaine},
  year = {2015},
  month = jun,
  publisher = {International Educational Data Mining Society (IEDMS)},
  address = {Agadir, Morocco},
  urldate = {2021-08-07},
  abstract = {Les tests adaptatifs sont un moyen d'{\'e}valuation qui a r{\'e}cemment gagn{\'e} en popularit{\'e}. Ils s{\'e}lectionnent la prochaine question {\`a} poser {\`a} un examin{\'e} de mani{\`e}re {\`a} estimer son niveau efficacement, en fonction de ses r{\'e}ponses aux questions pr{\'e}c{\'e}dentes. Les syst{\`e}mes de tests adaptatifs se sont d'abord appuy{\'e}s sur la th{\'e}orie de la r{\'e}ponse {\`a} l'item (TRI) afin de fournir une mesure efficace des traits latents dans des {\'e}valuations pouvant {\^e}tre {\`a} grande {\'e}chelle. Plus r{\'e}cemment, dans l'optique de fournir un retour utile {\`a} l'examin{\'e}, d'autres mod{\`e}les ont {\'e}t{\'e} {\'e}tudi{\'e}s dans la th{\'e}orie du diagnostic cognitif. L'un d'eux est le mod{\`e}le qmatrice, qui {\'e}tablit un lien entre questions du test et comp{\'e}tences de l'examin{\'e}. Dans cet article, nous d{\'e}finissons un protocole bas{\'e} sur la pr{\'e}diction de performance pour {\'e}valuer deux mod{\`e}les de tests adaptatifs : qmatrice et le mod{\`e}le de Rasch issu de la TRI. Les r{\'e}sultats obtenus sur trois jeux de donn{\'e}es r{\'e}elles de diff{\'e}rente taille et nature montrent que selon les caract{\'e}ristiques du test, l'un ou l'autre mod{\`e}le pr{\'e}dit le mieux la performance de l'examin{\'e}.},
  langid = {french},
  keywords = {conf,EIAH,poster},
  file = {files/9062/Vie et al. - 2015 - Prédiction de performance sur des questions dichot.pdf;files/9061/hal-01275277.html}
}

@phdthesis{meguebliLeveragingUserGeneratedContent2015,
  title = {Leveraging {{User-Generated Content}} for {{Enhancing}} and {{Personalizing News Recommendation}}.},
  author = {Meguebli, Youssef},
  year = {2015},
  month = mar,
  urldate = {2021-08-07},
  abstract = {In this thesis, we have investigated how to exploit user-generated-content for personalized news recommendation purpose. The intuition behind this line of research is that the opinions provided by users, on news websites, represent a strong indicator about their profiles. We have addressed this problem by proposing three main contributions. Firstly, we have proposed a profile model that accurately describes both users' interests and news article contents. The profile model was tested on three different applications ranging from identifying the political orientation of users to the context of news recommendation and the diversification of the list of recommended news articles. Results show that our profile model give much better results compared to state-of-the-art models. Secondly, we have investigated the problem of noise on opinions and how we can retrieve only relevant opinions in response to a given query.The proposed opinion ranking strategy is based on users' debates features. We have used a variation of PageRank technique to define the score of each opinion. Results show that our approach outperforms two recent proposed opinions ranking strategies, particularly for controversial topics. Thirdly, we have investigated different ways of leveraging opinions on news article contents including all opinions, topk opinions based on opinion ranking strategy, and a set of diverse opinion. To extract a list of diverse opinions, we have employed a variation of an existing opinion diversification model. Results show that diverse opinions give the best performance over other leveraging strategies.},
  langid = {english},
  school = {CentraleSup{\'e}lec},
  keywords = {Thesis},
  file = {files/9065/Meguebli - 2015 - Leveraging User-Generated Content for Enhancing an.pdf;files/9066/tel-01323014.html}
}

@inproceedings{viePredictingPerformanceDichotomous2015,
  title = {Predicting {{Performance}} on {{Dichotomous Questions}}: {{Comparing Models}} for {{Large-Scale Adaptive Testing}}},
  shorttitle = {Predicting {{Performance}} over {{Dichotomous Questions}}},
  booktitle = {Proceedings of the 8th International Conference on Educational Data Mining, {{EDM}} 2015, Madrid, Spain, June 26-29, 2015},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Grill, Jean-Bastien and Bruillard, Eric and Bourda, Yolaine},
  year = {2015},
  month = jun,
  pages = {618--619},
  publisher = {International Educational Data Mining Society (IEDMS)},
  urldate = {2021-08-07},
  abstract = {Computerized adaptive testing (CAT) is a mode of testing which has gained increasing popularity over the past years. It selects the next question to ask to the examinee in order to evaluate her level efficiently, by using her answers to the previous questions. Traditionally, CAT systems have been relying on item response theory (IRT) in order to provide an effective measure of latent abilities in possibly large-scale assessments. More recently, from the perspective of providing useful feedback to examinees, other models have been studied for cognitive diagnosis. One of them is the q-matrix model, which draws a link between questions and examinee knowledge components. In this paper, we define a protocol based on performance prediction to evaluate adaptive testing algorithms. We use it to evaluate q-matrices in the context of assessments and compare their behavior to item response theory. Results computed on three real datasets of growing size and of various nature suggest that tests of different type need different models.},
  langid = {english},
  keywords = {conf,EIAH,poster},
  file = {files/9071/Vie et al. - 2015 - Predicting Performance on Dichotomous Questions C.pdf;files/9069/hal-01275280.html}
}

@inproceedings{meguebliHowHiddenAspects2014,
  title = {How {{Hidden Aspects Can Improve Recommendation}}?},
  booktitle = {6th {{International Conference}}, {{SocInfo}} 2014},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2014},
  month = nov,
  series = {Social {{Informatics}}},
  volume = {8851},
  pages = {269--278},
  publisher = {Springer},
  address = {Barcelone, Spain},
  doi = {10/gmfpj3},
  abstract = {Nowadays, more and more people are using online news platforms as their main source of information about daily life events. Users of such platforms discuss around topics providing new insights and sometimes revealing hidden aspects about topics. The valuable information provided by users needs to be exploited to improve the accuracy of news recommendation and thus keep users always motivated to provide comments. However, exploiting user generated content is very challenging due its noisy nature. In this paper, we address this problem by proposing a novel news recommendation system that (1) enrich the profile of news article with user generated content, (2) deal with noisy contents by proposing a ranking model for users' comments, and (3) propose a diversification model for comments to remove redundancies and provide a wide coverage of topic aspects. The results show that our approach outperforms baseline approaches achieving high accuracy.},
  copyright = {All rights reserved},
  isbn = {978-3-319-13733-9},
  keywords = {conf,Invalid DOI,IR},
  file = {files/9074/Meguebli et al. - 2014 - How Hidden Aspects Can Improve Recommendation.pdf;files/9078/hal-01105283.html}
}

@inproceedings{meguebliExploitingSocialDebates2014,
  title = {Exploiting {{Social Debates}} for {{Opinion Ranking}}},
  booktitle = {{{KDIR}} 2014 - Proceedings of the International Conference on Knowledge Discovery and Information Retrieval, Rome, Italy},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2014},
  month = oct,
  pages = {250--260},
  publisher = {SciTePress},
  address = {Rome, Italy},
  doi = {10.5220/0005081702500260},
  abstract = {The number of opinions in news media platforms is increasing dramatically with daily news hits, and people spending more and more time to discuss topics and share experiences. Such user generated content represents a promising source for improving the effectiveness of news articles recommendation and retrieval. However, the corpus of opinions is often large and noisy making it hard to find prominent content. In this paper, we tackle this problem by proposing a novel scoring model that ranks opinions based on their relevance and prominence. We define the prominence of an opinion using its relationships with other opinions. To this end, we (1) create a directed graph of opinions where each link represents the sentiment an opinion expresses about another opinion (2) propose a new variation of the PageRank algorithm that boosts the scores of opinions along links with positive sentiments and decreases them along links with negative sentiments. We have tested the effectiveness of our model through extensive experiments using three datasets crawled from CNN, Independent, and The Telegraph Web sites . The experiments show that our scoring model achieves high quality results.},
  keywords = {conf,IR},
  file = {files/9080/Meguebli et al. - 2014 - Exploiting Social Debates for Opinion Ranking.pdf}
}

@inproceedings{hayComplementaritesRepresentationsVectorielles2018,
  title = {{Compl{\'e}mentarit{\'e}s de repr{\'e}sentations vectorielles pour la similarit{\'e} s{\'e}mantique}},
  booktitle = {{18e Journees Francophones Extraction et Gestion de Connaissances (EGC 2018)}},
  author = {Hay, Julien and Van De Cruys, Tim and Muller, Philippe and Doan, Biech Lien and Popineau, Fabrice and Benamsili, Lyes},
  year = {2018},
  month = jan,
  volume = {E-34},
  pages = {179--190},
  publisher = {{\'E}ditions RNTI},
  address = {Paris, France},
  urldate = {2021-08-07},
  abstract = {La t{\^a}che de similarit{\'e} s{\'e}mantique textuelle consiste {\`a} exprimer automatiquement un nombre refl{\'e}tant la similarit{\'e} s{\'e}mantique de deux fragments de texte. Chaque ann{\'e}e depuis 2012, les campagnes de SemEval d{\'e}roulent cette t{\^a}che de similarit{\'e} s{\'e}mantique textuelle. Cet article pr{\'e}sente une m{\'e}thode associant diff{\'e}rentes repr{\'e}sentations vectorielles de phrases dans l'objectif d'am{\'e}liorer les r{\'e}sultats obtenus en similarit{\'e} s{\'e}mantique. Notre hypoth{\`e}se est que diff{\'e}rentes repr{\'e}sentations permettraient de repr{\'e}senter diff{\'e}rents aspects s{\'e}mantiques, et par extension, d'am{\'e}liorer les similarit{\'e}s calcul{\'e}es, la principale difficult{\'e} {\'e}tant de s{\'e}lectionner les repr{\'e}sentations les plus compl{\'e}mentaires pour cette t{\^a}che. Notre syst{\`e}me se base sur le syst{\`e}me vainqueur de la campagne de 2015 ainsi que sur notre m{\'e}thode de s{\'e}lection par compl{\'e}mentarit{\'e}. Les r{\'e}sultats obtenus viennent confirmer l'int{\'e}r{\^e}t de cette m{\'e}thode lorsqu'ils sont compar{\'e}s aux r{\'e}sultats de la campagne de 2016.},
  langid = {french},
  keywords = {confnat,IR,semantique,Similarite},
  file = {files/9040/Hay et al. - 2018 - Complémentarités de représentations vectorielles p.pdf}
}

@inproceedings{meguebliStoriesYouTwoStage2014,
  title = {Stories {{Around You A Two-Stage Personalized News Recommendation}}},
  booktitle = {{{KDIR}} 2014 - Proceedings of the International Conference on Knowledge Discovery and Information Retrieval},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2014},
  month = oct,
  pages = {473--479},
  publisher = {SciTePress},
  address = {Rome, Italy},
  doi = {10/gg5vx3},
  abstract = {With the tremendous growth of published news articles, a key issue is how to help users find diverse and interesting news stories. To this end, it is crucial to understand and build accurate profiles for both users and news articles. In this paper, we define a user profile based on (1) the set of entities she/he talked about it in her/his comments and (2) the set of key-concepts related to those entities on which the user has expressed an opinion or a viewpoint. The same information is extracted from the content of each news article to create its profile. In a first step, we matched those profiles using a new similarity measure. We use also the news articles profiles to diversify the list of recommended stories in a second step. A first evaluation involving the activities of 150 real users in four news web sites, namely The Independent, The Telegraph, CNN and Aljazeera has shown the effectiveness of our approach compared to recent works.},
  keywords = {conf,IR},
  file = {files/9087/Meguebli et al. - 2014 - Stories Around You A Two-Stage Personalized News R.pdf;files/9085/MeguebliKDP14a.html}
}

@inproceedings{meguebliNovelArchitectureSmart2012,
  title = {A {{Novel Architecture}} for a {{Smart Information Retrieval System Based}} on {{Opinions Engineering}}},
  booktitle = {Proceedings of the Sixth Symposium on Human-Computer Interaction and Information Retrieval {{HCIR}}'12},
  author = {Meguebli, Youssef and Doan, Bich-Li{\^e}n and Popineau, Fabrice and Bourda, Yolaine},
  year = {2012},
  month = oct,
  pages = {4 pages},
  address = {Cambridge, United States},
  urldate = {2021-08-07},
  abstract = {In this paper, we present a novel architecture for personalized information retrieval (IR) and a simple scenario that illustrate the contribution of this architecture compared to current personalized IR. We use an extension of a Dung argumentation framework in order to improve the precision of our personalized information retrieval. We use also social media and search history to define the user-profile.},
  langid = {english},
  keywords = {conf,IR},
  file = {files/9097/Meguebli et al. - 2012 - A Novel Architecture for a Smart Information Retri.pdf;files/9092/8944523ac418f56ab7eaa1459157a8109e8fe346.html;files/9096/hal-00765342.html}
}

@inproceedings{dubusSituationCalculusPersonalized2011,
  title = {Situation Calculus and Personalized Web Systems},
  booktitle = {2011 11th {{International Conference}} on {{Intelligent Systems Design}} and {{Applications}}},
  author = {Dubus, Georges and Popineau, Fabrice and Bourda, Yolaine},
  year = {2011},
  month = nov,
  pages = {569--574},
  publisher = {IEEE},
  address = {C{\'o}rdoba, Spain},
  doi = {10/fzrtsq},
  abstract = {Personalized systems are a response to the increasing number of resources on the Internet, but can be difficult to create. In order to facilitate the design and creation of such personalized systems, we aim at formalizing them. The situation calculus is a logical framework that has often been proposed to model web applications and even personalized ones. However, the details of its use are much more rarely explained. In this paper we will show that it is needed to carefully consider which variant of the situation calculus to choose. We will precisely show why we want to use the so-called guarded action theories. We explain why and how it fits into an architecture. We introduce two scenarios of personalized applications to illustrate this choice.},
  copyright = {All rights reserved},
  keywords = {Adaptation models,adaptive systems,Adaptive systems,Calculus,Computer architecture,conf,EIAH,Intelligent systems,Noise measurement,personalization,Sensors,situation calculus,VAE,web application},
  file = {files/9100/Dubus et al. - 2011 - Situation calculus and personalized web systems.pdf;files/9099/6121716.html}
}

@inproceedings{dubusFormalApproachPersonalization2011,
  title = {A {{Formal Approach}} to {{Personalization}}},
  booktitle = {2011 {{IEEE}} 23rd {{International Conference}} on {{Tools}} with {{Artificial Intelligence}}},
  author = {Dubus, Georges and Popineau, Fabrice and Bourda, Yolaine},
  year = {2011},
  month = nov,
  pages = {233--238},
  publisher = {IEEE Computer Society},
  address = {Boca Raton, FL, USA},
  doi = {10/fzhff2},
  abstract = {Personalized systems are a response to the increasing number of resources on the Internet. In order to facilitate their design and creation, we aim at formalizing them. In this paper, we consider the relationship between a personalized application and its non-personalized counterpart. We argue that a personalized application is a formal extension of a non-personalized one. We aim at characterizing the syntactic differences between the expression of the personalized and non-personalized versions of the application. Situation calculus is our framework to formalize applications. We introduce two scenarios of non-personalized application that we personalize to illustrate our approach.},
  copyright = {All rights reserved},
  keywords = {Adaptation models,adaptive systems,Adaptive systems,Calculus,conf,EIAH,Games,personalization,Robot sensing systems,situation calculus,VAE,weaving,Weaving,web application},
  file = {files/9104/Dubus et al. - 2011 - A Formal Approach to Personalization.pdf;files/9105/6103333.html}
}

@inproceedings{zemirlineMESAMProtegePlugin2009,
  title = {{{MESAM}}: {{A Prot{\'e}g{\'e} Plug-in}} for the {{Specialization}} of {{Models}}},
  shorttitle = {{{MESAM}}},
  booktitle = {11th {{International Prot{\'e}g{\'e} Conference}}},
  author = {Zemirline, Nadjet and Bourda, Yolaine and Reynaud, Chantal and Popineau, Fabrice},
  year = {2009},
  month = jun,
  pages = {3 pages},
  address = {Amsterdam, Netherlands},
  urldate = {2021-08-07},
  abstract = {Nowadays, several efforts are focused on re-using generic platforms to create new systems, in order to make the design process easier and faster. Often, the designer has his own models and resources and would like to reuse the generic system over his resources. That means, he has to integrate his models and resources in the system, and then to directly reuse the generic system. But many problems occur. One of them is that the designer needs to translate his models into the specific format that understood by the system and to use the vocabulary specific to that system. Furthermore, he also needs to translate all the instantiations of his models (i.e. the resources and their metadata). We think that this task is tedious and time-consuming and we want to avoid it. Our objective is to allow the designer to reuse his models (his vocabulary) and his models' instantiations without any change of format or vocabulary. For example, a generic Adaptive Hypermedia System (AHS) is made of a generic adaptation model relying on generic user and domain models. The designer would like to integrate his models and instances in the generic models in order to reuse the generic adaptation engine. Specific systems can be obtained by specializing the generic models. However, this specialization process is not always easy to perform. It has to be supported to make the design process easier and faster. This paper focuses on assisting designers to specialize generic models using their own models. We aim to automate this process which has been so far entirely manual. Our objectives are twofold: to create a support for defining mappings between elements in generic models and elements in the designer's personal models and to help creating consistent and relevant models integrating the generic and specific ones and taking into account the mappings between them. The proposed approach relies on OWL1, a W3C standard and SWRL2, a W3C proposal.},
  keywords = {conf,EIAH,VAE},
  file = {files/9107/Zemirline et al. - 2009 - MESAM A Protégé Plug-in for the Specialization of.pdf}
}

@book{schaaEuroTeX20052005,
  title = {{{EuroTeX}} 2005},
  author = {Schaa, Volker RW and Popineau, Fabrice and Andr{\'e}, Jacques and Hagen, Hans and Flipo, Daniel and Jackowski, Bogus{\l}aw and Bzyl, W{\l}odzimierz and Sojka, Petr and Bilotta, Giuseppe and Grathwohl, Steve and Raichle, Bernd},
  year = {2005},
  month = mar,
  series = {{{TUGBoat}}},
  edition = {TeX Users Group},
  volume = {85},
  address = {Abbaye des Pr{\'e}montr{\'e}s, Pont-{\`a}-Mousson, France},
  langid = {english},
  keywords = {conf,TeX},
  file = {files/9113/Schaa et al. - 2005 - EuroTeX 2005.pdf;files/9115/Schaa et al. - 2005 - EuroTeX 2005.pdf}
}

@inproceedings{jacquiotGEAHSGenericEducational2004,
  title = {{{GEAHS}}: {{A Generic Educational Adaptive Hypermedia System}}},
  shorttitle = {{{GEAHS}}},
  booktitle = {{{EdMedia}} + {{Innovate Learning}}},
  author = {Jacquiot, Cedric and Bourda, Yolaine and Popineau, Fabrice},
  year = {2004},
  pages = {571--578},
  publisher = {Association for the Advancement of Computing in Education (AACE)},
  urldate = {2021-08-07},
  abstract = {GEAHS is a platform designed to ease the development of Adaptive Educational Hypermedia. In this document, we explain the underlying principles of this platform. Genericity is achieved thanks to an adaptation engine based on conceptual graphs, situation calculus and RDF. We are currently working on a graphical tool to build an AEH system designed on top of our engine. This paper describes the main aspects of our system, as well as the use we make of standards and recommendations.},
  isbn = {978-1-880094-53-2},
  langid = {english},
  keywords = {conf,EIAH,VAE},
  file = {files/8978/Jacquiot et al. - 2004 - GEAHS A Generic Educational Adaptive Hypermedia S.pdf;files/9117/hal-00263749.html;files/9124/12989.html}
}

@inproceedings{jacquiotReusabilityGEAHS2004,
  title = {Reusability in {{GEAHS}}},
  booktitle = {Engineering Advanced Web Applications: {{Proceedings}} of Workshops in Connection with the 4th International Conference on Web Engineering ({{ICWE}} 2004), Munich, Germany, 28-30 July, 2004},
  author = {Jacquiot, C{\'e}dric and Bourda, Yolaine and Popineau, Fabrice},
  editor = {Matera, Maristella and Comai, Sara},
  year = {2004},
  pages = {199--209},
  publisher = {Rinton Press},
  address = {Munich, Germany},
  abstract = {GEAHS (Generic Educational Adaptive Hypermedia System) is a platform designed to ease the development of Adaptive Educational Hypermedia, using standard formalisms. In this document, we explain the underlying principles of this platform. Genericity is achieved thanks to an adaptation engine based on situation calculus and RDF. This paper describes the main aspects of our system, as well as the use we make of situation calculus to create a more reusable adaptive hypermedia system.},
  langid = {english},
  keywords = {conf,EIAH,VAE},
  file = {files/9120/Jacquiot et al. - 2004 - Reusability in GEAHS.pdf;files/9122/hal-00263858.html}
}

@inproceedings{jacquiotGEAHSGenericEducational2004a,
  title = {{{GEAHS}}: {{A Generic Educational Adaptive Hypermedia System Based}} on {{Situation Calculus}}},
  booktitle = {Adaptive Hypermedia and Adaptive Web-Based Systems, Third International Conference, {{AH}} 2004, Eindhoven, the Netherlands, August 23-26, 2004, Proceedings},
  author = {Jacquiot, C{\'e}dric and Bourda, Yolaine and Popineau, Fabrice},
  editor = {Bra, Paul De and Nejdl, Wolfgang},
  year = {2004},
  series = {Lecture Notes in Computer Science},
  volume = {3137},
  pages = {413--416},
  publisher = {Springer},
  doi = {10.1007/978-3-540-27780-4_63},
  abstract = {GEAHS is a platform designed to ease the development of Adaptive Educational Hypermedia, using standard formalisms. In this document, we explain the underlying principles of this platform. Genericity is achieved thanks to an adaptation engine based on situation calculus and RDF. This paper describes the main aspects of our system, as well as the use we make of situation calculus to create a simpler, more reusable adaptive hypermedia system.},
  isbn = {978-3-540-22895-0},
  langid = {english},
  keywords = {conf,EIAH,VAE},
  file = {files/9130/Jacquiot et al. - 2004 - GEAHS A Generic Educational Adaptive Hypermedia S.pdf}
}

@inproceedings{popineauGeneratingAdaptiveHypermedia2003,
  title = {Generating Adaptive Hypermedia with {{Golog}} and Conceptual Graphs},
  booktitle = {Proceedings 3rd {{IEEE International Conference}} on {{Advanced Technologies}}},
  author = {Popineau, F. and Bourda, Y. and Doan, B.-L.},
  year = {2003},
  month = jul,
  pages = {463--466},
  publisher = {IEEE Computer Society},
  address = {Athens, Greece},
  doi = {10/cq9bcv},
  abstract = {We present an adaptive hypermedia architecture based on Golog and conceptual graphs. We propose a conceptual graph model for the description of the hypermedia structure and the use of Golog, a logic programming language, for the generation of the personalized hypermedia. This approach has been validated by a prototype and two examples based on different domains.},
  copyright = {All rights reserved},
  keywords = {Calculus,conf,Education,EIAH,Engines,Logic programming,poster,Prototypes,Resource description framework,Robots,Semantic Web,Testing,VAE,Writing},
  file = {files/9136/Popineau et al. - 2003 - Generating adaptive hypermedia with Golog and conc.pdf;files/9135/1215186.html}
}

@article{popineauDirectionsTEXLiveSystem2001,
  title = {Directions for the {{TEXLive}} System},
  author = {Popineau, Fabrice},
  year = {2001},
  journal = {MAPS},
  number = {26},
  pages = {151--161},
  abstract = {This paper is about the current status of the TEXLive software. The first part of the paper will address the structured description of its content and how the Windows setup program can use it. The past experiments with the Windows installer have revealed that the problem was harder than expected. The new TEXLive 6 description files will allow a more effective way to use the setup program. Some further enhancements are even scheduled. The second part of the paper will address a set of possible extensions to the Web2C/Kpathsea pair (read it as a call for code contributions!). Some aspects of its use were not foreseen when it was devised and it may be time for an enhancement.},
  langid = {english},
  keywords = {conf,journal,TeX},
  file = {files/9139/Popineau - 2001 - Directions for the TEXLive system.pdf}
}

@article{popineauMETAPOSTPratique2001,
  title = {{METAPOST pratique}},
  author = {Popineau, Fabrice},
  year = {2001},
  journal = {Cahiers GUTenberg},
  number = {41},
  pages = {167--175},
  issn = {1140-9304},
  doi = {10/ghfbvj},
  urldate = {2021-08-07},
  abstract = {In this article, I will explain how to pratically use METAPOST. This program is very different from usual drawing programs, but it fits very well in a TEX based typesetting system.},
  langid = {french},
  keywords = {journal,TeX},
  file = {files/9141/Popineau - 2001 - METAPOST pratique.pdf}
}

@article{popineauAffichezVosDocuments2000,
  title = {{Affichez vos documents LaTeX sur le Web avec TeX4ht}},
  author = {Popineau, Fabrice},
  year = {2000},
  journal = {Cahiers GUTenberg},
  number = {37-38},
  pages = {5--43},
  issn = {1140-9304},
  doi = {10/ghfbvh},
  urldate = {2021-08-07},
  abstract = {Eitan Gurari is TEX4ht's author, a clever tool which allows TEX and LATEX documents to be translated to html and xml. I'd like to show here that TEX4ht is of simple use, powerful and extensible. Let's have a look at its features.},
  langid = {french},
  keywords = {journal,TeX},
  file = {files/9143/Popineau - 2000 - Affichez vos documents LaTeX sur le Web avec TeX4h.pdf}
}

@article{popineauFpTEXTeTEXbasedDistribution1999,
  title = {{{fpTEX}}: {{A teTEX-based Distribution}} for {{Windows}}},
  author = {Popineau, Fabrice},
  year = {1999},
  journal = {TUGBoat},
  volume = {20},
  number = {3},
  pages = {290--297},
  abstract = {This paper deals with the ins and outs of porting the widely used teTEX distribution to the Windows environment. The choices made and difficulties experienced are related, a brief description of this huge distribution is given and the future work is sketched out.},
  langid = {english},
  keywords = {conf,TeX},
  file = {files/9145/Popineau - 1999 - fpTEX A teTEX-based Distribution for Windows.pdf}
}

@article{popineauFpTeXTeTeXPour1999,
  title = {{fpTeX : teTeX pour Win32}},
  shorttitle = {{fpTeX}},
  author = {Popineau, Fabrice},
  year = {1999},
  journal = {Cahiers GUTenberg},
  number = {32},
  pages = {47--61},
  issn = {1140-9304},
  doi = {10/ghfbvk},
  urldate = {2021-08-07},
  langid = {french},
  keywords = {conf,TeX},
  file = {files/9147/Popineau - 1999 - fpTeX  teTeX pour Win32.pdf}
}

@article{groupedetravailtwg-tdsTDSStructureRepertoires2004,
  title = {{TDS : une structure de r{\'e}pertoires pour les fichiers TeX}},
  author = {{Groupe de Travail TWG-TDS} and Popineau, Fabrice},
  translator = {Charpentier, Jean-C{\^o}me},
  year = {2004},
  journal = {Cahiers GUTenberg},
  number = {44--45},
  pages = {83--114},
  langid = {french},
  keywords = {journal,TeX},
  file = {files/9150/Groupe de Travail TWG-TDS et Popineau - 2004 - TDS  une structure de répertoires pour les fichie.pdf}
}

@misc{rahtzOccultSecretsTEXLive2003,
  title = {The {{Occult Secrets}} of {{TEXLive}}},
  author = {Rahtz, Sebastian and Popineau, Fabrice},
  year = {2003},
  month = aug,
  address = {Hawaii},
  langid = {english},
  keywords = {poster,TeX},
  file = {files/9154/Rahtz et Popineau - 2003 - The Occult Secrets of TEXLive.pdf}
}

@misc{popineauLuaTeXUnicode2007,
  title = {{{LuaTeX}} et {{Unicode}}},
  author = {Popineau, Fabrice},
  year = {2007},
  month = oct,
  keywords = {conf,TeX},
  file = {files/9156/Popineau - 2007 - LuaTeX et Unicode.pdf}
}

@inproceedings{choffinDAS3HModelingStudent2019,
  title = {{{DAS3H}}: {{Modeling Student Learning}} and {{Forgetting}} for {{Optimally Scheduling Distributed Practice}} of {{Skills}}},
  booktitle = {Proceedings of the 12th International Conference on Educational Data Mining, {{EDM}} 2019, Montr{\'e}al, Canada, July 2-5, 2019},
  author = {Choffin, Beno{\^i}t and Popineau, Fabrice and Bourda, Yolaine and Vie, Jill-J{\^e}nn},
  editor = {Desmarais, Michel C. and Lynch, Collin F. and Merceron, Agathe and Nkambou, Roger},
  year = {2019},
  publisher = {International Educational Data Mining Society (IEDMS)},
  address = {Montr{\'e}al, Canada},
  abstract = {Spaced repetition is among the most studied learning strategies in the cognitive science literature. It consists in temporally distributing exposure to an information so as to improve long-term memorization. Providing students with an adaptive and personalized distributed practice schedule would benefit more than just a generic scheduler. However, the applicability of such adaptive schedulers seems to be limited to pure memorization, e.g. flashcards or foreign language learning. In this article, we first frame the research problem of optimizing an adaptive and personalized spaced repetition scheduler when memorization concerns the application of underlying multiple skills. To this end, we choose to rely on a student model for inferring knowledge state and memory dynamics on any skill or combination of skills. We argue that no knowledge tracing model takes both memory decay and multiple skill tagging into account for predicting student performance. As a consequence, we propose a new student learning and forgetting model suited to our research problem: DAS3H builds on the additive factor models and includes a representation of the temporal distribution of past practice on the skills involved by an item. In particular, DAS3H allows the learning and forgetting curves to differ from one skill to another. Finally, we provide empirical evidence on three real-world educational datasets that DAS3H outperforms other state-of-the-art EDM models. These results suggest that incorporating both item-skill relationships and forgetting effect improves over student models that consider one or the other.},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,conf,EIAH,Statistics - Applications,Statistics - Machine Learning},
  file = {files/9029/Choffin et al. - 2019 - DAS3H Modeling Student Learning and Forgetting fo.pdf;files/5307/1905.html}
}

@article{vieAutomatedTestAssembly2018,
  title = {Automated {{Test Assembly}} for {{Handling Learner Cold-Start}} in {{Large-Scale Assessments}}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Bruillard, Eric and Bourda, Yolaine},
  year = {2018},
  journal = {Int. J. Artif. Intell. Educ.},
  volume = {28},
  number = {4},
  pages = {616--631},
  doi = {10/gdvnnj},
  keywords = {EIAH,journal},
  file = {files/8973/Vie et al. - 2018 - Automated Test Assembly for Handling Learner Cold-.pdf}
}

@phdthesis{jacquiotModelisationLogiqueGenerique2006,
  type = {{Th{\`e}se de doctorat}},
  title = {{Mod{\'e}lisation logique et g{\'e}n{\'e}rique des syst{\`e}mes d'hyperm{\'e}dias adaptatifs}},
  author = {Jacquiot, C{\'e}dric},
  year = {2006},
  month = jan,
  urldate = {2021-08-07},
  abstract = {Les hyperm{\'e}dias adaptatifs, comme tous les syst{\`e}mes {\`a} base de connaissances, peuvent {\^e}tre divis{\'e}s en deux parties : une partie statique, permettant la repr{\'e}sentation de donn{\'e}es relatives aux domaines {\`a} traiter, et une partie dynamique, consacr{\'e}e au traitement des donn{\'e}es par diff{\'e}rents proc{\'e}d{\'e}s. Les mod{\`e}les de donn{\'e}es existants sont souvent difficiles {\`a} r{\'e}utiliser car ils sont soit tr{\`e}s sp{\'e}cifiques {\`a} une application particuli{\`e}re, soit tr{\`e}s g{\'e}n{\'e}raux et, dans ce cas, il est rarement possible de les rendre plus sp{\'e}cifiques pour un domaine d'application particulier. Les mod{\`e}les d'adaptation existants se limitent souvent {\`a} des langages de r{\`e}gles, qui ne font pas de distinction entre les diff{\'e}rentes sortes de donn{\'e}es. Cette th{\`e}se propose des mod{\`e}les g{\'e}n{\'e}riques de donn{\'e}es, d{\'e}crits sous forme de diagrammes de classe UML, permettant par sp{\'e}cialisation la cr{\'e}ation de mod{\`e}les sp{\'e}cifiques {\`a} un domaine d'application. Elle pr{\'e}sente {\'e}galement un mod{\`e}le d'adaptation enti{\`e}rement d{\'e}crit en calcul des pr{\'e}dicats du premier ordre, bas{\'e} sur la logique situationnelle, et muni d'un langage de r{\`e}gles constitu{\'e} de plusieurs niveaux, prenant en compte les diff{\'e}rents types de donn{\'e}es {\`a} des niveaux diff{\'e}rents du langage. Ce langage introduit, en outre, une forme de m{\'e}ta-adaptation, par s{\'e}lection de strat{\'e}gies de parcours du domaine. Cette th{\`e}se introduit la notion de parcours par tron{\c c}ons, qui offre une solution interm{\'e}diaire, entre le parcours libre et le parcours guid{\'e}. L'ensemble des mod{\`e}les est utilis{\'e} pour proposer une application dans le domaine du e-learning.},
  collaborator = {Reynaud, Chantal and Bourda, Yolaine and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {Paris 11},
  keywords = {E-learning,Meta-adaptation,Systeme de deduction,Thesis,VAE},
  annotation = {Prix de Th{\`e}se de la Fondation Jean-Luc Lagard{\`e}re},
  file = {files/10005/Jacquiot - 2006 - Modélisation logique et générique des systèmes d'h.pdf}
}

@phdthesis{dubusTransformationProgrammesLogiques2014,
  type = {{Th{\`e}se de doctorat}},
  title = {{Transformation de programmes logiques : application {\`a} la personnalisation et {\`a} la personnification d'agents.}},
  shorttitle = {{Transformation de programmes logiques}},
  author = {Dubus, Georges},
  year = {2014},
  month = sep,
  urldate = {2021-08-07},
  abstract = {Cette th{\`e}se s'int{\'e}resse {\`a} la personnalisation et {\`a} la personnification d'agents intelligents dans le cadre d'applications web. Les techniques de personnalisation et de personnification sont de plus en plusutilis{\'e}es pour mieux r{\'e}pondre aux besoins des utilisateurs. La plupart de ces techniques reposent sur des outils de raisonnement issus de l'intelligence artificielle. Cependant, ces techniques sont habituellement utilis{\'e}s de mani{\`e}re ad-hoc pour chaque application. L'approche de cette th{\`e}se est de consid{\'e}rer la personnalisation et la personnification comme deux instances d'alt{\'e}ration de comportement, et {\`a} {\'e}tudier l'alt{\'e}ration du comportements d'agents rationnels. Les principales contributions sont WAIG, un formalisme bas{\'e} sur le langage Golog adapt{\'e} {\`a} l'expression d'applications web, et PAGE, un cadre formel pour la manipulation et l'alt{\'e}ration de programmes agents Golog, permettant la transformation automatique d'agent selon un crit{\`e}re donn{\'e}. Ces contributions sont illustr{\'e}s par plusieurs sc{\'e}narios concrets issus des domaines de la personnalisation et de la personnification.},
  collaborator = {Bourda, Yolaine and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {Sup{\'e}lec},
  keywords = {AI,IA,Intelligence artificielle,Logical programing,Personalization,Personification,Personnalisation,Personnification,Programmation logique,Thesis,VAE},
  file = {files/9165/Dubus - 2014 - Transformation de programmes logiques  applicatio.pdf}
}

@phdthesis{hajriPersonnalisationMOOCPar2018,
  type = {{Th{\`e}se de doctorat}},
  title = {{Personnalisation des MOOC par la r{\'e}utilisation de Ressources {\'E}ducatives Libres}},
  author = {Hajri, Hiba},
  year = {2018},
  month = jun,
  urldate = {2021-08-07},
  abstract = {La personnalisation de l'apprentissage dans les environnements informatiques pour l'apprentissage humain (EIAH) est un sujet de recherche qui est trait{\'e} depuis de nombreuses ann{\'e}es. Avec l'arriv{\'e}e des cours en ligne ouverts et massifs (MOOC), la question de la personnalisation se pose de fa{\c c}on encore plus cruciale et de nouveaux d{\'e}fis se pr{\'e}sentent aux chercheurs. En effet, le m{\^e}me MOOC peut {\^e}tre suivi par des milliers d'apprenants ayant des profils h{\'e}t{\'e}rog{\`e}nes (connaissances, niveaux {\'e}ducatif, objectifs, etc). Il devient donc n{\'e}cessaire de tenir compte de cette h{\'e}t{\'e}rog{\'e}n{\'e}it{\'e} en pr{\'e}sentant aux apprenants des contenus {\'e}ducatifs adapt{\'e}s {\`a} leurs profils afin qu'ils tirent parti au mieux du MOOC.D'un autre c{\^o}t{\'e}, de plus en plus de ressources {\'e}ducatives libres (REL) sont partag{\'e}es sur le web. Il est important de pouvoir r{\'e}utiliser ces REL dans un contexte diff{\'e}rent de celui pour lequel elles ont {\'e}t{\'e} cr{\'e}{\'e}es. En effet, produire des REL de qualit{\'e} est une activit{\'e} co{\^u}teuse en temps et la rentabilisation des REL passe par leur r{\'e}utilisation.Pour faciliter la d{\'e}couverte des REL, des sch{\'e}mas de m{\'e}tadonn{\'e}es sont utilis{\'e}s pour d{\'e}crire les REL.Cependant, l'utilisation de ces sch{\'e}mas a amen{\'e} {\`a} des entrep{\^o}ts isol{\'e}s de descriptions h{\'e}t{\'e}rog{\`e}nes et qui ne sont pas interop{\'e}rables. Afin de r{\'e}gler ce probl{\`e}me, une solution adopt{\'e}e dans la litt{\'e}rature consiste {\`a} appliquer les principes des donn{\'e}es ouvertes et li{\'e}es (LOD) aux descriptions des REL.Dans le cadre de cette th{\`e}se, nous nous int{\'e}ressons {\`a} la personnalisation des MOOC et {\`a} la r{\'e}utilisation des REL.Nous proposons un syst{\`e}me de recommandation qui fournit {\`a} un apprenant en train de suivre un MOOC des ressources externes qui sont des REL adapt{\'e}es {\`a} son profil, tout en respectant les sp{\'e}cificit{\'e}s du MOOC suivi.Pour s{\'e}lectionner les REL, nous nous int{\'e}ressons {\`a} celles qui poss{\`e}dent des descriptions ins{\'e}r{\'e}es dans les LOD, stock{\'e}es dans des entrep{\^o}ts accessibles sur le web et offrant des moyens d'acc{\`e}s standardis{\'e}s. Notre syst{\`e}me de recommandation est impl{\'e}ment{\'e} dans une plateforme de MOOC, Open edX et il est {\'e}valu{\'e} en utilisant une plateforme de micro-t{\^a}ches.},
  collaborator = {Bourda, Yolaine and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {Universit{\'e} Paris-Saclay (ComUE)},
  keywords = {Cours en ligne ouverts a tous,Donnees ouvertes,Donnees ouvertes et liees,Education et informatique,Linked open data,Mooc,Open educational resources,Personalization,Personnalisation,Ressources educatives libres,Technologie educative,Thesis,VAE},
  file = {files/9169/Hajri - 2018 - Personnalisation des MOOC par la réutilisation de .pdf}
}

@phdthesis{vieModelesTestsAdaptatifs2016,
  type = {{Th{\`e}se de doctorat}},
  title = {{Mod{\`e}les de tests adaptatifs pour le diagnostic de connaissances dans un cadre d'apprentissage {\`a} grande {\'e}chelle}},
  author = {Vie, Jill-J{\^e}nn},
  year = {2016},
  month = dec,
  urldate = {2021-08-07},
  abstract = {Cette th{\`e}se porte sur les tests adaptatifs dans les environnements d'apprentissage. Elle s'inscrit dans les contextes de fouille de donn{\'e}es {\'e}ducatives et d'analytique de l'apprentissage, o{\`u} l'on s'int{\'e}resse {\`a} utiliser les donn{\'e}es laiss{\'e}es par les apprenants dans des environnements {\'e}ducatifs pour optimiser l'apprentissage au sens large.L'{\'e}valuation par ordinateur permet de stocker les r{\'e}ponses des apprenants facilement, afin de les analyser et d'am{\'e}liorer les {\'e}valuations futures. Dans cette th{\`e}se, nous nous int{\'e}ressons {\`a} un certain type de test par ordinateur, les tests adaptatifs. Ceux-ci permettent de poser une question {\`a} un apprenant, de traiter sa r{\'e}ponse {\`a} la vol{\'e}e, et de choisir la question suivante {\`a} lui poser en fonction de ses r{\'e}ponses pr{\'e}c{\'e}dentes. Ce processus r{\'e}duit le nombre de questions {\`a} poser {\`a} un apprenant tout en conservant une mesure pr{\'e}cise de son niveau. Les tests adaptatifs sont aujourd'hui impl{\'e}ment{\'e}s pour des tests standardis{\'e}s tels que le GMAT ou le GRE, administr{\'e}s {\`a} des centaines de milliers d'{\'e}tudiants. Toutefois, les mod{\`e}les de tests adaptatifs traditionnels se contentent de noter les apprenants, ce qui est utile pour l'institution qui {\'e}value, mais pas pour leur apprentissage. C'est pourquoi des mod{\`e}les plus formatifs ont {\'e}t{\'e} propos{\'e}s, permettant de faire un retour plus riche {\`a} l'apprenant {\`a} l'issue du test pour qu'il puisse comprendre ses lacunes et y rem{\'e}dier. On parle alors de diagnostic adaptatif.Dans cette th{\`e}se, nous avons r{\'e}pertori{\'e} des mod{\`e}les de tests adaptatifs issus de diff{\'e}rents pans de la litt{\'e}rature. Nous les avons compar{\'e}s de fa{\c c}on qualitative et quantitative. Nous avons ainsi propos{\'e} un protocole exp{\'e}rimental, que nous avons impl{\'e}ment{\'e} pour comparer les principaux mod{\`e}les de tests adaptatifs sur plusieurs jeux de donn{\'e}es r{\'e}elles. Cela nous a amen{\'e}s {\`a} proposer un mod{\`e}le hybride de diagnostic de connaissances adaptatif, meilleur que les mod{\`e}les de tests formatifs existants sur tous les jeux de donn{\'e}es test{\'e}s. Enfin, nous avons {\'e}labor{\'e} une strat{\'e}gie pour poser plusieursquestions au tout d{\'e}but du test afin de r{\'e}aliser une meilleure premi{\`e}re estimation des connaissances de l'apprenant. Ce syst{\`e}me peut {\^e}tre appliqu{\'e} {\`a} la g{\'e}n{\'e}ration automatique de feuilles d'exercices, par exemple sur un cours en ligne ouvert et massif (MOOC).},
  collaborator = {Bourda, Yolaine and Bruillard, {\'E}ric and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {Universit{\'e} Paris-Saclay (ComUE)},
  keywords = {Adaptive testing,Analytique de l'apprentissage,Cognitive diagnosis,Cours en ligne ouverts a tous,Cours en ligne ouverts et massifs (MOOC),Diagnostic de connaissances,Exploration de donnees,Formation en ligne,Item response theory,Learning analytics,Massive open online courses (MOOCs),Q-Matrice,Q-Matrix,Systemes adaptatifs (informatique),Technologie educative,Tests adaptatifs,Theorie de la reponse a l'item,Thesis},
  file = {files/9173/Vie - 2016 - Modèles de tests adaptatifs pour le diagnostic de .pdf}
}

@phdthesis{choffinAlgorithmesEspacementAdaptatif2021,
  type = {{Th{\`e}se de doctorat}},
  title = {{Algorithmes d'espacement adaptatif de l'apprentissage pour l'optimisation de la ma{\^i}trise {\`a} long terme de composantes de connaissance}},
  author = {Choffin, Beno{\^i}t},
  year = {2021},
  month = jan,
  urldate = {2021-08-07},
  abstract = {Entre acqu{\'e}rir de nouvelles connaissances et revoir les anciennes pour en att{\'e}nuer l'oubli, les apprenants peuvent avoir du mal {\`a} organiser efficacement leur temps d'apprentissage. Les algorithmes d'espacement adaptatif de l'apprentissage, tels SuperMemo, permettent d'aider les apprenants {\`a} r{\'e}soudre cet arbitrage. Ces algorithmes planifient les r{\'e}visions successives d'une m{\^e}me connaissance de mani{\`e}re optimale et personnalis{\'e}e en tenant compte des besoins de chaque apprenant. Compar{\'e} {\`a} un espacement temporel entre les r{\'e}visions identique pour tous les individus, plusieurs exp{\'e}riences montrent que l'espacement adaptatif maintient un plus haut degr{\'e} d'ancrage en m{\'e}moire {\`a} long terme des informations apprises.Jusqu'ici, la recherche sur l'espacement adaptatif de l'apprentissage s'est concentr{\'e}e sur la m{\'e}morisation pure de connaissances simples, repr{\'e}sent{\'e}es souvent par le biais de flashcards. Or, plusieurs {\'e}tudes en psychologie cognitive montrent que les b{\'e}n{\'e}fices de l'espacement de l'apprentissage sur la m{\'e}morisation {\`a} long terme s'{\'e}tendent aussi {\`a} des connaissances plus complexes, telles que l'apprentissage de concepts et de proc{\'e}dures en math{\'e}matiques. Dans cette th{\`e}se, nous avons donc cherch{\'e} {\`a} d{\'e}velopper des algorithmes d'espacement adaptatif et personnalis{\'e} de l'apprentissage de composantes de connaissance (CC).Dans un premier temps, nous proposons un nouveau mod{\`e}le statistique de l'apprentissage et l'oubli de CC, appel{\'e} DAS3H, et montrons empiriquement qu'il poss{\`e}de de meilleures performances pr{\'e}dictives que plusieurs mod{\`e}les de l'apprenant en fouille de donn{\'e}es {\'e}ducatives. Ensuite, nous d{\'e}veloppons plusieurs heuristiques d'espacement adaptatif pour la ma{\^i}trise {\`a} long terme de CC et comparons leurs performances sur des donn{\'e}es simul{\'e}es. Deux de ces heuristiques reposent sur le mod{\`e}le DAS3H pour s{\'e}lectionner la CC {\`a} faire r{\'e}viser {\`a} un instant donn{\'e}. Nous proposons en outre une nouvelle proc{\'e}dure gloutonne pour s{\'e}lectionner le sous-ensemble de CC le plus prometteur au lieu de la meilleure CC {\`a} faire r{\'e}viser. Enfin, dans le dernier chapitre de cette th{\`e}se, nous d{\'e}veloppons AC4S, un algorithme d'apprentissage par renforcement profond pour l'espacement adaptatif de l'apprentissage de CC. Nous comparons cette approche fond{\'e}e sur les donn{\'e}es {\`a} nos m{\'e}thodes heuristiques, pr{\'e}sent{\'e}es pr{\'e}c{\'e}demment.},
  collaborator = {Bourda, Yolaine and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {universit{\'e} Paris-Saclay},
  keywords = {Adaptive spacing,Apprentissage par renforcement profond,Apprentissage profond,Calcul adaptatif,Composantes de connaissance (CC),Deep reinforcement learning,Educational data mining,Espacement adaptatif de l'apprentissage,Exploration de donnees,Fouille de donnees educatives,Knowledge components (KCs),Planification de revisions,Review scheduling,Thesis},
  file = {files/9177/Choffin - 2021 - Algorithmes d’espacement adaptatif de l’apprentiss.pdf}
}

@book{russellIntelligenceArtificielle2nde2006,
  title = {{Intelligence artificielle 2nde {\'e}dition}},
  author = {Russell, Stuart and Norvig, Peter},
  translator = {Miclet, Laurent and Popineau, Fabrice and Baland, Marie-C{\'e}cile},
  year = {2006},
  month = sep,
  publisher = {Pearson},
  address = {Paris},
  abstract = {Il aborde:- Tous les aspects de la discipline : logique, probabilits et mathmatiques du continu, perception, raison-nement, apprentissage et action. - Les diffrentes mthodes utiles la prise de dcision lors de la ralisation de projets. - Lapplication de ces mthodes en fonction des diffrentes possibilits de reprsentation, notamment lors de la construction de plans. - Les diffrents domaines dapplication : langage crit et parl, perception visuelle, robotiqueLintrt de ce manuel est de prsenter lIA travers le concept dagents intelligents (systmes qui dcident de ce qu'il convient de faire). Il dcrit: - La perception de lenvironnement par lagent intelligent pour dterminer et analyser ce quil s'y passe (par la vision, le toucher, l'oue ou le langage). - La transformation de la perception en actions concrtes. Dans cette optique, la robotique et la vision sont traites dans le cadre de leur contribution l'obtention de buts, et les auteurs insistent sur l'importance de l'environnement. Ainsi, certains agents doivent rsoudre des problmes combinatoires (jeux, labyrinthes, satisfaction de contraintes), dautres raisonnent (logique, dmonstration), dautres encore apprennent. Prs de 400 exercices sont proposs. Ils vont des exercices de rflexion aux exercices de programmation, en passant par lapprofondissement des mthodes dcrites.},
  isbn = {978-2-7440-7150-8},
  langid = {french},
  keywords = {artificial intelligence,otherpub}
}

@book{russelIntelligenceArtificielle3e2010,
  title = {{Intelligence artificielle 3e {\'e}dition : Avec plus de 500 exercices}},
  shorttitle = {{Intelligence artificielle 3e {\'e}dition}},
  author = {Russel, Stuart and Norvig, Peter},
  translator = {Popineau, Fabrice},
  year = {2010},
  month = dec,
  publisher = {Pearson},
  address = {Paris},
  abstract = {{\'E}crit par les experts de renomm{\'e}e mondiale, ce livre est la r{\'e}f{\'e}rence incontournable en mati{\`e}re d'intelligence artificielle (IA) dont il pr{\'e}sente et analyse tous les concepts : logique, probabilit{\'e}s, math{\'e}matiques discr{\`e}tes et du continu, perception, raisonnement, apprentissage, prise de d{\'e}cision et action. Sa sp{\'e}cificit{\'e} est de pr{\'e}senter l'IA {\`a} travers le concept des agents intelligents. Les auteurs exposent comment un syst{\`e}me r{\'e}ussit {\`a} percevoir son environnement de mani{\`e}re {\`a} analyser ce qu'il s'y passe, et comment il transforme la perception qu'il a de son environnement en actions concr{\`e}tes. Parmi les sujets couverts : - les contributions historiques des math{\'e}matiques, de la th{\'e}orie des jeux, de l'{\'e}conomie, de la th{\'e}orie des probabilit{\'e}s, de la psychologie, de la linguistique et des neurosciences; - les m{\'e}thodes qui permettent de prendre des d{\'e}cisions lors de l'{\'e}tablissement d'un projet, en tenant compte des {\'e}tapes {\`a} venir; - les diff{\'e}rentes mani{\`e}res de repr{\'e}senter formellement les connaissances relatives au monde qui nous entoure ainsi que le raisonnement logique fond{\'e} sur ces connaissances; - les m{\'e}thodes de raisonnement qui permettent d'{\'e}tablir des plans et donc de proposer des actions {\`a} entreprendre; - la prise de d{\'e}cisions en environnement incertain : r{\'e}seaux bay{\'e}siens et algorithmes tels que l'{\'e}limination de variables et MCMC (Markov Chain Monte-Carlo); - les m{\'e}thodes employ{\'e}es pour g{\'e}n{\'e}rer les connaissances exig{\'e}es par les composants de prise de d{\'e}cision : les algorithmes de boosting, l'algorithme EM (expectation-minimization), l'apprentissage {\`a} base d'exemples et les m{\'e}thodes {\`a} noyaux (machines {\`a} vecteurs support); - les implications philosophiques et {\'e}thiques de l'IA. Chaque chapitre est illustr{\'e} par de nombreux exemples et s'ach{\`e}ve par des activit{\'e}s, qui vont des exercices de r{\'e}flexion {\`a} des exercices de programmation, en passant par l'approfondissement des m{\'e}thodes d{\'e}crites, soit plus de 500 activit{\'e}s au total. Cette 3e {\'e}dition tient compte des derniers d{\'e}veloppements de la mati{\`e}re, concernant notamment les repr{\'e}sentations qu'un agent peut utiliser (atomique, factoris{\'e}e, structur{\'e}e), les environnements partiellement observables et non d{\'e}terministes, les planifications contingente et hi{\'e}rarchique, les mod{\`e}les probabilistes du premier ordre, l'apprentissage automatique, la recherche et l'extraction d'information sur le web et l'apprentissage {\`a} partir de tr{\`e}s grandes bases de donn{\'e}es.},
  isbn = {978-2-7440-7455-4},
  langid = {french},
  keywords = {artificial intelligence,otherpub}
}

@book{russelIntelligenceArtificielle4e2021,
  title = {{Intelligence artificielle 4e {\'e}dition}},
  author = {Russel, Stuart and Norvig, Peter},
  editor = {Popineau, Fabrice},
  translator = {Popineau, Fabrice and Miclet, Laurent and {Claire Cadet}},
  year = {2021},
  edition = {4},
  publisher = {Pearson},
  address = {Paris},
  abstract = {La bible en intelligence artificielle. Cet ouvrage est LE manuel de r{\'e}f{\'e}rence en intelligence artificielle. C'est le seul ouvrage {\`a} couvrir de fa{\c c}on aussi compl{\`e}te et moderne tout le champ th{\'e}orique et pratique de l'intelligence artificielle. C'est aussi le seul ouvrage {\`a} proposer une vision unifi{\'e}e de l'intelligence artificielle, centr{\'e}e autour de la notion d'agent intelligent. Les diff{\'e}rents champs disciplinaires autour de l'IA sont abord{\'e}s avec un tr{\`e}s grand nombre de renvois entre les sections, ce qui constitue une richesse inestimable de l'ouvrage qui expose les connexions entre des domaines qui sont le plus souvent pr{\'e}sent{\'e}s comme ind{\'e}pendants. La 4e {\'e}dition informe les lecteurs sur les derni{\`e}res technologies, pr{\'e}sente les concepts de mani{\`e}re plus unifi{\'e}e et couvre de mani{\`e}re nouvelle ou {\'e}largie l'apprentissage automatique, l'apprentissage profond, l'apprentissage par transfert, les syst{\`e}mes multi-agents, la robotique, le traitement du langage naturel, la causalit{\'e}, la programmation probabiliste, le respect de la vie priv{\'e}e, l'{\'e}quit{\'e} et la s{\'e}curit{\'e}.},
  isbn = {978-2-326-00221-0},
  langid = {french},
  keywords = {artificial intelligence,otherpub}
}

@inproceedings{popineauWorkshopElicitingAdaptive2018,
  title = {Workshop Eliciting {{Adaptive Sequences}} for {{Learning}} ({{WeASeL}}) 2018},
  booktitle = {Proceedings of the 1st {{International Workshop}} Eliciting {{Adaptive Sequences}} for {{Learning}} Co-Located with the 14th {{International Conference}} on {{Intelligent Tutoring Systems}} ({{ITS}} 2018)},
  author = {Popineau, Fabrice and Valko, Michal and Vie, Jill-J{\^e}nn},
  editor = {Guin, Nathalie and Kumar, Amruth N.},
  year = {2018},
  series = {{{CEUR}} Workshop Proceedings},
  volume = {2354},
  pages = {141--143},
  publisher = {CEUR-WS.org},
  keywords = {conf,EIAH}
}

@book{popineauLogiqueRaisonnementArtificiel1993,
  title = {{Logique du Raisonnement Artificiel}},
  author = {Popineau, Fabrice},
  year = {1993},
  publisher = {Sup{\'e}lec},
  langid = {french},
  keywords = {poly}
}

@book{popineauModelisationOrienteeObjet1997,
  title = {{Mod{\'e}lisation Orient{\'e}e Objet}},
  author = {Popineau, Fabrice},
  year = {1997},
  publisher = {Sup{\'e}lec},
  langid = {french},
  keywords = {poly}
}

@book{popineauANSICommonLisp2005,
  title = {{ANSI Common Lisp}},
  author = {Popineau, Fabrice},
  year = {2005},
  publisher = {Sup{\'e}lec},
  langid = {french},
  keywords = {LISP,poly}
}

@book{popineauElementsInformatiqueTheorique2005,
  title = {{{\'E}l{\'e}ments d'Informatique Th{\'e}orique}},
  author = {Popineau, Fabrice},
  year = {2005},
  publisher = {Sup{\'e}lec},
  langid = {french},
  keywords = {poly}
}

@book{popineauAlgorithmesNotesCours2016,
  title = {{Algorithmes : notes de cours}},
  author = {Popineau, Fabrice},
  year = {2016},
  publisher = {CentraleSup{\'e}lec},
  langid = {french},
  keywords = {poly}
}

@article{choffinExtendingAdaptiveSpacing2021,
  title = {Extending {{Adaptive Spacing Heuristics}} to {{Multi-Skill Items}}},
  author = {Choffin, Beno{\^i}t and Popineau, Fabrice and Bourda, Yolaine},
  year = {2021},
  month = oct,
  journal = {Journal of Educational Data Mining},
  volume = {13},
  number = {3},
  pages = {69--102},
  issn = {2157-2100},
  doi = {10/gm9xv3},
  urldate = {2021-11-01},
  abstract = {Adaptive spacing algorithms are powerful tools for helping learners manage their study time efficiently. By personalizing the temporal distribution of retrieval practice of a given piece of knowledge, they improve learners' long-term memory retention compared to fixed review schedules. However, such algorithms are generally designed for the pure memorization of single items, such as vocabulary words. Yet, the spacing effect has been shown to extend to more complex knowledge, such as the practice of mathematical skills. In this article, we extend three adaptive spacing heuristics from the literature for selecting the best skill to review at any timestamp given a student's past study history. In real-world educational settings, items generally involve multiple skills at the same time. Thus, we also propose a multi-skill version for two of these heuristics: instead of selecting one single skill, they select with a greedy procedure the most promising subset of skills to review. To compare these five heuristics, we develop a synthetic experimental framework that simulates student learning and forgetting trajectories with a student model. We run multiple synthetic experiments on large cohorts of 500 simulated students and publicly release the code for these experiments. Our results highlight the strengths and weaknesses of each heuristic in terms of performance, robustness, and complexity. Finally, we find evidence that selecting the best subset of skills yields better retention compared to selecting the single best skill to review.},
  copyright = {Copyright (c) 2021 Beno{\^i}t Choffin, Fabrice Popineau, Yolaine Bourda},
  langid = {english},
  keywords = {EIAH,journal},
  file = {files/9765/Choffin et al. - 2021 - Extending Adaptive Spacing Heuristics to Multi-Ski.pdf;files/9766/510.html}
}

@phdthesis{hayApprentissageRepresentationStyle2021,
  type = {{Th{\`e}se de doctorat}},
  title = {{Apprentissage de la repr{\'e}sentation du style {\'e}crit, application {\`a} la recommandation d'articles d'actualit{\'e}}},
  author = {Hay, Julien},
  year = {2021},
  abstract = {La mod{\'e}lisation des utilisateurs est une {\'e}tape essentielle lorsqu'il s'agit de recommander des produits et proposer des services automatiquement. Les r{\'e}seaux sociaux sont une ressource riche et abondante de donn{\'e}es utilisateur (p. ex. liens partag{\'e}s, messages post{\'e}s) permettant de mod{\'e}liser leurs int{\'e}r{\^e}ts et pr{\'e}f{\'e}rences. Dans cette th{\`e}se, nous proposons d'exploiter les articles d'actualit{\'e} partag{\'e}s sur les r{\'e}seaux sociaux afin d'enrichir les mod{\`e}les existants avec une nouvelle caract{\'e}ristique textuelle : le style {\'e}crit. Cette th{\`e}se, {\`a} l'intersection des domaines du traitement automatique du langage naturel et des syst{\`e}mes de recommandation, porte sur l'apprentissage de la repr{\'e}sentation du style et de son application {\`a} la recommandation d'articles d'actualit{\'e}. Dans un premier temps, nous proposons une nouvelle m{\'e}thode d'apprentissage de la repr{\'e}sentation du texte visant {\`a} projeter tout document dans un espace stylom{\'e}trique de r{\'e}f{\'e}rence. L'hypoth{\`e}se test{\'e}e est qu'un tel espace peut {\^e}tre g{\'e}n{\'e}ralis{\'e} par un ensemble suffisamment large d'auteurs de r{\'e}f{\'e}rence, et que les projections vectorielles des {\'e}crits d'un auteur << nouveau >> seront proches, d'un point de vue stylistique, des {\'e}crits d'un sous-ensemble consistant de ces auteurs de r{\'e}f{\'e}rence. Dans un second temps, nous proposons d'exploiter la repr{\'e}sentation stylom{\'e}trique du texte pour la recommandation d'articles d'actualit{\'e} en la combinant {\`a} d'autres repr{\'e}sentations (p. ex. th{\'e}matique, lexicale, s{\'e}mantique). Nous cherchons {\`a} identifier les caract{\'e}ristiques les plus compl{\'e}mentaires pouvant permettre une recommandation d'articles plus pertinente et de meilleure qualit{\'e}. L'hypoth{\`e}se ayant motiv{\'e} ces travaux est que les choix de lecture des individus sont non seulement influenc{\'e}s par le fond (p. ex. le th{\`e}me des articles d'actualit{\'e}, les entit{\'e}s mentionn{\'e}es), mais aussi par la forme (c.-{\`a}-d. le style pouvant, par exemple, {\^e}tre descriptif, satirique, compos{\'e} d'anecdotes personnelles, d'interviews). Les exp{\'e}rimentations effectu{\'e}es montrent que non seulement le style {\'e}crit joue un r{\^o}le dans les pr{\'e}f{\'e}rences de lecture des individus, mais aussi que, lorsqu'il est combin{\'e} {\`a} d'autres caract{\'e}ristiques textuelles, permet d'augmenter la pr{\'e}cision et la qualit{\'e} des recommandations en termes de diversit{\'e}, de nouveaut{\'e} et de s{\'e}rendipit{\'e}.},
  langid = {french},
  school = {Universit{\'e} Paris-Saclay},
  keywords = {Thesis},
  file = {files/9951/Hay - 2021 - Apprentissage de la représentation du style écrit,.pdf}
}

@techreport{dincaConstructionSiteWeb2000,
  type = {{Stage de fin d'{\'e}tudes}},
  title = {{Construction d'un Site Web Adaptatif}},
  author = {Dinca, Claudiu},
  year = {2000},
  month = sep,
  institution = {Universitatea Politehnica Bucuresti},
  langid = {french},
  keywords = {Master,VAE}
}

@techreport{arfireGraphicalKnowledgeRepresentation2006,
  type = {Stage de Fin d'{\'e}tudes},
  title = {Graphical {{Knowledge Representation}}},
  author = {Arfire, Doru},
  year = {2006},
  month = jun,
  institution = {Universitatea Politehnica Bucuresti},
  langid = {english},
  keywords = {Master,VAE}
}

@techreport{hawesPersonnalisationPersonnificationTuteurs2015,
  type = {{Stage de fin d'{\'e}tudes}},
  title = {{Personnalisation et Personnification des Tuteurs Intelligents}},
  author = {Hawes, Hiba},
  year = {2015},
  month = sep,
  institution = {Universit{\'e} de la Manouba, {\'E}cole Nationale des Sciences de l'Informatique},
  langid = {french},
  keywords = {Master,VAE}
}

@inproceedings{FRATANI_RM2021,
  title = {Ranking Geological Cross-Sections for Database Querying},
  booktitle = {2021 {{RING}} Meeting},
  author = {Fratani, Amandine and Viseur, Sophie and Popineau, Fabrice and Henry, Pierre and Ghattas, Badih and Oppenheim, Georges and Dhont, Damien and Gout, Claude},
  year = {2021},
  publisher = {ASGA},
  abstract = {Geological cross-sections are convenient supports for synthesizing geological knowledge of given geological subsurface structures. They contain information about the geological time of the formations and their architecture. Querying a database of case study reports or papers with geological cross-sections could be then a convenient way to find geological analogues. Image-content query is used to achieve this kind of query. It is often performed using deep-learning, but these techniques require numerous pairs of original images and associated human-tagged images in order to obtain satisfying results after the training phase. Alternative approaches rely on image similarity measures based on textures, colours or shapes contained in the images. In this paper, we propose such a method for ranking geological cross-sections using two kinds of similarity measures: (i) the presence and proportion of formations from similar geological times; (ii) the global geological architecture. This approach combines the use of a colour dictionary and different correlation measures. Noddy is a software allowing synthetic geological cross-sections to be generated using a series of geological events (faulting, tilting, folding, etc.). A database of 100,000 geological cross-sections was generated using Noddy. In each cross-section, the layers are colored following the standard ICS color codes. Results of cross-section rankings are shown from this database and discussed.},
  keywords = {conf,THINK},
  file = {files/18641/ring-meeting-papers.html}
}

@inproceedings{thimonierTracInADMeasuringInfluence2022,
  title = {{{TracInAD}}: {{Measuring Influence}} for {{Anomaly Detection}}},
  shorttitle = {{{TracInAD}}},
  booktitle = {2022 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Thimonier, Hugo and Popineau, Fabrice and Rimmel, Arpad and Doan, Bich-Lien and Daniel, Fabrice},
  year = {2022},
  month = jul,
  pages = {1--6},
  publisher = {IEEE},
  address = {Padua, Italy},
  doi = {10.1109/IJCNN55064.2022.9892058},
  urldate = {2023-04-10},
  isbn = {978-1-72818-671-9},
  keywords = {conf,Lusis},
  file = {files/20183/Thimonier et al. - 2022 - TracInAD Measuring Influence for Anomaly Detectio.pdf}
}

@inproceedings{velayBenchmarkingRobustnessDeep2023,
  title = {Benchmarking {{Robustness}} of {{Deep Reinforcement Learning}} Approaches to {{Online Portfolio Management}}},
  booktitle = {2023 {{International Conference}} on {{Innovations}} in {{Intelligent Systems}} and {{Applications}} ({{INISTA}})},
  author = {Velay, Marc and Doan, Bich-Li{\^e}n and Rimmel, Arpad and Popineau, Fabrice and Daniel, Fabrice},
  year = {2023},
  month = sep,
  pages = {1--6},
  publisher = {IEEE},
  address = {Hammamet, Tunisia},
  doi = {10.1109/INISTA59065.2023.10310402},
  urldate = {2024-01-26},
  isbn = {9798350338904},
  keywords = {conf,Lusis},
  file = {files/21692/Velay et al. - 2023 - Benchmarking Robustness of Deep Reinforcement Lear.pdf}
}

@inproceedings{thimonierIndividualInputDeep2023,
  title = {Beyond {{Individual Input}} for {{Deep Anomaly Detection}} on {{Tabular Data}}},
  author = {Thimonier, Hugo and Popineau, Fabrice and Rimmel, Arpad and Doan, Bich-Li{\^e}n},
  year = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2305.15121},
  urldate = {2024-01-26},
  abstract = {Anomaly detection is vital in many domains, such as finance, healthcare, and cybersecurity. In this paper, we propose a novel deep anomaly detection method for tabular data that leverages Non-Parametric Transformers (NPTs), a model initially proposed for supervised tasks, to capture both feature-feature and sample-sample dependencies. In a reconstruction-based framework, we train the NPT to reconstruct masked features of normal samples. In a non-parametric fashion, we leverage the whole training set during inference and use the model's ability to reconstruct the masked features to generate an anomaly score. To the best of our knowledge, this is the first work to successfully combine feature-feature and sample-sample dependencies for anomaly detection on tabular datasets. Through extensive experiments on 31 benchmark tabular datasets, we demonstrate that our method achieves state-of-the-art performance, outperforming existing methods by 2.4\% and 1.2\% in terms of F1-score and AUROC, respectively. Our ablation study provides evidence that modeling both types of dependencies is crucial for anomaly detection on tabular data.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {conf,FOS: Computer and information sciences,Lusis,Machine Learning (cs.LG)},
  file = {files/21696/Thimonier et al. - 2023 - Beyond Individual Input for Deep Anomaly Detection.pdf}
}

@inproceedings{thimonierComparativeEvaluationAnomaly2023,
  title = {Comparative {{Evaluation}} of {{Anomaly Detection Methods}} for {{Fraud Detection}} in {{Online Credit Card Payments}}},
  author = {Thimonier, Hugo and Popineau, Fabrice and Rimmel, Arpad and Doan, Bich-Li{\^e}n and Daniel, Fabrice},
  year = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2312.13896},
  urldate = {2024-01-26},
  abstract = {This study explores the application of anomaly detection (AD) methods in imbalanced learning tasks, focusing on fraud detection using real online credit card payment data. We assess the performance of several recent AD methods and compare their effectiveness against standard supervised learning methods. Offering evidence of distribution shift within our dataset, we analyze its impact on the tested models' performances. Our findings reveal that LightGBM exhibits significantly superior performance across all evaluated metrics but suffers more from distribution shifts than AD methods. Furthermore, our investigation reveals that LightGBM also captures the majority of frauds detected by AD methods. This observation challenges the potential benefits of ensemble methods to combine supervised, and AD approaches to enhance performance. In summary, this research provides practical insights into the utility of these techniques in real-world scenarios, showing LightGBM's superiority in fraud detection while highlighting challenges related to distribution shifts.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {conf,FOS: Computer and information sciences,FOS: Economics and business,Lusis,Machine Learning (cs.LG),Statistical Finance (q-fin.ST)},
  file = {files/21697/Thimonier et al. - 2023 - Comparative Evaluation of Anomaly Detection Method.pdf}
}

@misc{thimonierRetrievalAugmentedDeep2024,
  title = {Retrieval {{Augmented Deep Anomaly Detection}} for {{Tabular Data}}},
  author = {Thimonier, Hugo and Popineau, Fabrice and Rimmel, Arpad and Doan, Bich-Li{\^e}n},
  year = {2024},
  month = jul,
  eprint = {2401.17052},
  primaryclass = {cs},
  doi = {10.1145/3627673.3679559},
  urldate = {2024-08-20},
  abstract = {Deep learning for tabular data has garnered increasing attention in recent years, yet employing deep models for structured data remains challenging. While these models excel with unstructured data, their efficacy with structured data has been limited. Recent research has introduced retrieval-augmented models to address this gap, demonstrating promising results in supervised tasks such as classification and regression. In this work, we investigate using retrieval-augmented models for anomaly detection on tabular data. We propose a reconstruction-based approach in which a transformer model learns to reconstruct masked features of {\textbackslash}textit\{normal\} samples. We test the effectiveness of KNN-based and attention-based modules to select relevant samples to help in the reconstruction process of the target sample. Our experiments on a benchmark of 31 tabular datasets reveal that augmenting this reconstruction-based anomaly detection (AD) method with sample-sample dependencies via retrieval modules significantly boosts performance. The present work supports the idea that retrieval module are useful to augment any deep AD method to enhance anomaly detection on tabular data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Lusis},
  file = {files/22440/Thimonier et al. - 2024 - Retrieval Augmented Deep Anomaly Detection for Tabular Data.pdf;files/22441/2401.html}
}
