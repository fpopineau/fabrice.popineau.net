
@techreport{arfireGraphicalKnowledgeRepresentation2006,
  type = {Stage de Fin d'\'etudes},
  title = {Graphical {{Knowledge Representation}}},
  author = {Arfire, Doru},
  year = {2006},
  month = jun,
  institution = {{Universitatea Politehnica Bucuresti}},
  langid = {english},
  keywords = {\#nosource,Master,VAE}
}

@inproceedings{bourdaTuteursIntelligentsBoucler2018,
  title = {{Tuteurs intelligents : boucler la boucle}},
  booktitle = {{PFIA 2018 - Journ\'ee \guillemotleft{} IA pour l'\'education \guillemotright}},
  author = {Bourda, Yolaine and Chaudet, Claude and Choffin, Beno{\^i}t and Parmentier, Jeanne and Popineau, Fabrice and Vie, Jill-J{\^e}nn},
  year = {2018},
  month = jul,
  pages = {4},
  url = {https://hal.archives-ouvertes.fr/hal-02197685},
  langid = {french},
  keywords = {⛔ No DOI found,EIAH,poster,VAE},
  file = {C\:\\Home\\Zotero\\storage\\J47LPRIP\\Bourda et al. - 2018 - Tuteurs intelligents  boucler la boucle.pdf}
}

@article{chaixXEmTeXIntegratedPlatform2003,
  title = {{{XEmTeX}}: {{An}} Integrated Platform for High Quality Scientific Typesetting},
  author = {Chaix, Marie-Louise and Popineau, Fabrice},
  year = {2003},
  month = jul,
  keywords = {\#nosource,⛔ No DOI found,poster,TeX}
}

@article{chaixXEmTeXProject2003,
  title = {The {{XEmTeX}} Project},
  author = {Chaix, Marie-Louise and Popineau, Fabrice},
  year = {2003},
  month = jun,
  journal = {TUGBoat},
  volume = {24},
  number = {3},
  pages = {415--419},
  keywords = {⛔ No DOI found,conf,TeX},
  file = {C\:\\Home\\Zotero\\storage\\W3CI5SQF\\Chaix et Popineau - 2003 - The XEmTeX project.pdf}
}

@phdthesis{choffinAlgorithmesEspacementAdaptatif2021,
  type = {{Th\`ese de doctorat}},
  title = {{Algorithmes d'espacement adaptatif de l'apprentissage pour l'optimisation de la ma\^itrise \`a long terme de composantes de connaissance}},
  author = {Choffin, Beno{\^i}t},
  year = {2021},
  month = jan,
  url = {https://theses.fr/2021UPASG001},
  urldate = {2021-08-07},
  abstract = {Entre acqu\'erir de nouvelles connaissances et revoir les anciennes pour en att\'enuer l'oubli, les apprenants peuvent avoir du mal \`a organiser efficacement leur temps d'apprentissage. Les algorithmes d'espacement adaptatif de l'apprentissage, tels SuperMemo, permettent d'aider les apprenants \`a r\'esoudre cet arbitrage. Ces algorithmes planifient les r\'evisions successives d'une m\^eme connaissance de mani\`ere optimale et personnalis\'ee en tenant compte des besoins de chaque apprenant. Compar\'e \`a un espacement temporel entre les r\'evisions identique pour tous les individus, plusieurs exp\'eriences montrent que l'espacement adaptatif maintient un plus haut degr\'e d'ancrage en m\'emoire \`a long terme des informations apprises.Jusqu'ici, la recherche sur l'espacement adaptatif de l'apprentissage s'est concentr\'ee sur la m\'emorisation pure de connaissances simples, repr\'esent\'ees souvent par le biais de flashcards. Or, plusieurs \'etudes en psychologie cognitive montrent que les b\'en\'efices de l'espacement de l'apprentissage sur la m\'emorisation \`a long terme s'\'etendent aussi \`a des connaissances plus complexes, telles que l'apprentissage de concepts et de proc\'edures en math\'ematiques. Dans cette th\`ese, nous avons donc cherch\'e \`a d\'evelopper des algorithmes d'espacement adaptatif et personnalis\'e de l'apprentissage de composantes de connaissance (CC).Dans un premier temps, nous proposons un nouveau mod\`ele statistique de l'apprentissage et l'oubli de CC, appel\'e DAS3H, et montrons empiriquement qu'il poss\`ede de meilleures performances pr\'edictives que plusieurs mod\`eles de l'apprenant en fouille de donn\'ees \'educatives. Ensuite, nous d\'eveloppons plusieurs heuristiques d'espacement adaptatif pour la ma\^itrise \`a long terme de CC et comparons leurs performances sur des donn\'ees simul\'ees. Deux de ces heuristiques reposent sur le mod\`ele DAS3H pour s\'electionner la CC \`a faire r\'eviser \`a un instant donn\'e. Nous proposons en outre une nouvelle proc\'edure gloutonne pour s\'electionner le sous-ensemble de CC le plus prometteur au lieu de la meilleure CC \`a faire r\'eviser. Enfin, dans le dernier chapitre de cette th\`ese, nous d\'eveloppons AC4S, un algorithme d'apprentissage par renforcement profond pour l'espacement adaptatif de l'apprentissage de CC. Nous comparons cette approche fond\'ee sur les donn\'ees \`a nos m\'ethodes heuristiques, pr\'esent\'ees pr\'ec\'edemment.},
  collaborator = {Bourda, Yolaine and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {universit\'e Paris-Saclay},
  keywords = {Adaptive spacing,Apprentissage par renforcement profond,Apprentissage profond,Calcul adaptatif,Composantes de connaissance (CC),Deep reinforcement learning,Educational data mining,Espacement adaptatif de l’apprentissage,Exploration de données,Fouille de données éducatives,Knowledge components (KCs),Planification de révisions,Review scheduling,Thesis},
  file = {C\:\\Home\\Zotero\\storage\\2CDT8RBL\\Choffin - 2021 - Algorithmes d’espacement adaptatif de l’apprentiss.pdf}
}

@inproceedings{choffinDAS3HModelingStudent2019a,
  title = {{{DAS3H}}: {{Modeling Student Learning}} and {{Forgetting}} for {{Optimally Scheduling Distributed Practice}} of {{Skills}}},
  booktitle = {Proceedings of the 12th International Conference on Educational Data Mining, {{EDM}} 2019, Montr\'eal, Canada, July 2-5, 2019},
  author = {Choffin, Beno{\^i}t and Popineau, Fabrice and Bourda, Yolaine and Vie, Jill-J{\^e}nn},
  editor = {Desmarais, Michel C. and Lynch, Collin F. and Merceron, Agathe and Nkambou, Roger},
  year = {2019},
  publisher = {{International Educational Data Mining Society (IEDMS)}},
  address = {{Montr\'eal, Canada}},
  url = {http://arxiv.org/abs/1905.06873},
  abstract = {Spaced repetition is among the most studied learning strategies in the cognitive science literature. It consists in temporally distributing exposure to an information so as to improve long-term memorization. Providing students with an adaptive and personalized distributed practice schedule would benefit more than just a generic scheduler. However, the applicability of such adaptive schedulers seems to be limited to pure memorization, e.g. flashcards or foreign language learning. In this article, we first frame the research problem of optimizing an adaptive and personalized spaced repetition scheduler when memorization concerns the application of underlying multiple skills. To this end, we choose to rely on a student model for inferring knowledge state and memory dynamics on any skill or combination of skills. We argue that no knowledge tracing model takes both memory decay and multiple skill tagging into account for predicting student performance. As a consequence, we propose a new student learning and forgetting model suited to our research problem: DAS3H builds on the additive factor models and includes a representation of the temporal distribution of past practice on the skills involved by an item. In particular, DAS3H allows the learning and forgetting curves to differ from one skill to another. Finally, we provide empirical evidence on three real-world educational datasets that DAS3H outperforms other state-of-the-art EDM models. These results suggest that incorporating both item-skill relationships and forgetting effect improves over student models that consider one or the other.},
  langid = {english},
  keywords = {\#nosource,⛔ No DOI found,Computer Science - Artificial Intelligence,Computer Science - Computers and Society,conf,EIAH,Statistics - Applications,Statistics - Machine Learning},
  file = {C\:\\Home\\Zotero\\storage\\S683VCRR\\Choffin et al. - 2019 - DAS3H Modeling Student Learning and Forgetting fo.pdf}
}

@inproceedings{choffinEvaluatingDAS3HEdNet2021,
  title = {Evaluating {{DAS3H}} on the {{EdNet Dataset}}},
  booktitle = {{{AAAI}} 2021 - {{The}} 35th {{Conference}} on {{Artificial Intelligence}} / {{Imagining Post-COVID Education}} with {{AI}}},
  author = {Choffin, Beno{\^i}t and Popineau, Fabrice and Bourda, Yolaine and Vie, Jill-J{\^e}nn},
  year = {2021},
  pages = {8},
  url = {https://hal.archives-ouvertes.fr/hal-03175874/document},
  abstract = {The EdNet dataset is a massive English language dataset that poses unique challenges for student performance prediction. In this paper, we describe and comment the results of our award-winning model DAS3H in the context of knowledge tracing in EdNet.},
  langid = {english},
  keywords = {⛔ No DOI found,conf,EIAH},
  file = {C\:\\Home\\Zotero\\storage\\DGVB3RWT\\Choffin et al. - 2021 - Evaluating DAS3H on the EdNet Dataset.pdf}
}

@article{choffinExtendingAdaptiveSpacing2021,
  title = {Extending {{Adaptive Spacing Heuristics}} to {{Multi-Skill Items}}},
  author = {Choffin, Beno{\^i}t and Popineau, Fabrice and Bourda, Yolaine},
  year = {2021},
  month = oct,
  journal = {Journal of Educational Data Mining},
  volume = {13},
  number = {3},
  pages = {69--102},
  issn = {2157-2100},
  doi = {10/gm9xv3},
  url = {https://jedm.educationaldatamining.org},
  urldate = {2021-11-01},
  abstract = {Adaptive spacing algorithms are powerful tools for helping learners manage their study time efficiently. By personalizing the temporal distribution of retrieval practice of a given piece of knowledge, they improve learners' long-term memory retention compared to fixed review schedules. However, such algorithms are generally designed for the pure memorization of single items, such as vocabulary words. Yet, the spacing effect has been shown to extend to more complex knowledge, such as the practice of mathematical skills. In this article, we extend three adaptive spacing heuristics from the literature for selecting the best skill to review at any timestamp given a student's past study history. In real-world educational settings, items generally involve multiple skills at the same time. Thus, we also propose a multi-skill version for two of these heuristics: instead of selecting one single skill, they select with a greedy procedure the most promising subset of skills to review. To compare these five heuristics, we develop a synthetic experimental framework that simulates student learning and forgetting trajectories with a student model. We run multiple synthetic experiments on large cohorts of 500 simulated students and publicly release the code for these experiments. Our results highlight the strengths and weaknesses of each heuristic in terms of performance, robustness, and complexity. Finally, we find evidence that selecting the best subset of skills yields better retention compared to selecting the single best skill to review.},
  copyright = {Copyright (c) 2021 Beno\^it Choffin, Fabrice Popineau, Yolaine Bourda},
  langid = {english},
  keywords = {⛔ No DOI found,EIAH,journal},
  file = {C\:\\Home\\Zotero\\storage\\58EUU4SB\\Choffin et al. - 2021 - Extending Adaptive Spacing Heuristics to Multi-Ski.pdf}
}

@article{choffinModellingStudentLearning2020,
  title = {Modelling Student Learning and Forgetting for Optimally Scheduling Skill Review},
  author = {Choffin, Beno{\^i}t and Popineau, Fabrice and Bourda, Yolaine},
  year = {2020},
  journal = {ERCIM News},
  volume = {2020},
  number = {120},
  url = {https://ercim-news.ercim.eu/en120/special/modelling-student-learning-and-forgetting-for-optimally-scheduling-skill-review},
  keywords = {⛔ No DOI found,artificial intelligence in education,EIAH,learning analytics,other,otherpub},
  file = {C\:\\Home\\Zotero\\storage\\VIQL6TCR\\Choffin et al. - 2020 - Modelling student learning and forgetting for opti.pdf}
}

@techreport{dincaConstructionSiteWeb2000,
  type = {{Stage de fin d'\'etudes}},
  title = {{Construction d'un Site Web Adaptatif}},
  author = {Dinca, Claudiu},
  year = {2000},
  month = sep,
  institution = {{Universitatea Politehnica Bucuresti}},
  langid = {french},
  keywords = {\#nosource,Master,VAE}
}

@inproceedings{dubusFormalApproachPersonalization2011,
  title = {A {{Formal Approach}} to {{Personalization}}},
  booktitle = {2011 {{IEEE}} 23rd {{International Conference}} on {{Tools}} with {{Artificial Intelligence}}},
  author = {Dubus, Georges and Popineau, Fabrice and Bourda, Yolaine},
  year = {2011},
  month = nov,
  pages = {233--238},
  publisher = {{IEEE Computer Society}},
  address = {{Boca Raton, FL, USA}},
  doi = {10/fzhff2},
  abstract = {Personalized systems are a response to the increasing number of resources on the Internet. In order to facilitate their design and creation, we aim at formalizing them. In this paper, we consider the relationship between a personalized application and its non-personalized counterpart. We argue that a personalized application is a formal extension of a non-personalized one. We aim at characterizing the syntactic differences between the expression of the personalized and non-personalized versions of the application. Situation calculus is our framework to formalize applications. We introduce two scenarios of non-personalized application that we personalize to illustrate our approach.},
  copyright = {All rights reserved},
  keywords = {\#nosource,⛔ No DOI found,Adaptation models,adaptive systems,Adaptive systems,Calculus,conf,EIAH,Games,personalization,Robot sensing systems,situation calculus,VAE,weaving,Weaving,web application},
  file = {C\:\\Home\\Zotero\\storage\\B8NMUMT2\\Dubus et al. - 2011 - A Formal Approach to Personalization.pdf}
}

@inproceedings{dubusParametricReasoningAgents2013,
  title = {Parametric {{Reasoning Agents Extend}} the {{Control}} over {{Standard Behaviors}}},
  booktitle = {2013 {{IEEE}}/{{WIC}}/{{ACM International Joint Conferences}} on {{Web Intelligence}} ({{WI}}) and {{Intelligent Agent Technologies}} ({{IAT}})},
  author = {Dubus, Georges and Popineau, Fabrice and Bourda, Yolaine and Sansonnet, Jean-Paul},
  year = {2013},
  month = nov,
  volume = {2},
  pages = {163--170},
  publisher = {{IEEE}},
  address = {{Atlanta, GA, USA}},
  doi = {10.1109/WI-IAT.2013.105},
  url = {http://ieeexplore.ieee.org/document/6690785/},
  urldate = {2019-12-21},
  abstract = {In this paper, we study how to extend the control over the behavioral space of logically specified agents so as they can take into account parameters issuing from constraints and/or preferences that are external to their core reasoning process. Our approach is supported by the proposition of a set of generic transformations to apply to the original agent program that is expressed in IndiGolog, a variant of the Golog language. Several of these transformations exploit the non-determinism present in IndiGolog programs. We also propose an automatic process to apply all those transformations on the basis of a set of parameters. Three case-studies show the significance of the approach in situations where agents are in interaction with human users.},
  isbn = {978-0-7695-5145-6},
  langid = {english},
  keywords = {\#nosource,conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\ENLB8RJL\\Dubus et al. - 2013 - Parametric Reasoning Agents Extend the Control ove.pdf}
}

@inproceedings{dubusSituationCalculusPersonalized2011,
  title = {Situation Calculus and Personalized Web Systems},
  booktitle = {2011 11th {{International Conference}} on {{Intelligent Systems Design}} and {{Applications}}},
  author = {Dubus, Georges and Popineau, Fabrice and Bourda, Yolaine},
  year = {2011},
  month = nov,
  pages = {569--574},
  publisher = {{IEEE}},
  address = {{C\'ordoba, Spain}},
  doi = {10/fzrtsq},
  abstract = {Personalized systems are a response to the increasing number of resources on the Internet, but can be difficult to create. In order to facilitate the design and creation of such personalized systems, we aim at formalizing them. The situation calculus is a logical framework that has often been proposed to model web applications and even personalized ones. However, the details of its use are much more rarely explained. In this paper we will show that it is needed to carefully consider which variant of the situation calculus to choose. We will precisely show why we want to use the so-called guarded action theories. We explain why and how it fits into an architecture. We introduce two scenarios of personalized applications to illustrate this choice.},
  copyright = {All rights reserved},
  keywords = {\#nosource,Adaptation models,adaptive systems,Adaptive systems,Calculus,Computer architecture,conf,EIAH,Intelligent systems,Noise measurement,personalization,Sensors,situation calculus,VAE,web application},
  file = {C\:\\Home\\Zotero\\storage\\2Z8ZQDBS\\Dubus et al. - 2011 - Situation calculus and personalized web systems.pdf}
}

@phdthesis{dubusTransformationProgrammesLogiques2014,
  type = {{Th\`ese de doctorat}},
  title = {{Transformation de programmes logiques : application \`a la personnalisation et \`a la personnification d'agents.}},
  shorttitle = {{Transformation de programmes logiques}},
  author = {Dubus, Georges},
  year = {2014},
  month = sep,
  url = {https://theses.fr/2014SUPL0017},
  urldate = {2021-08-07},
  abstract = {Cette th\`ese s'int\'eresse \`a la personnalisation et \`a la personnification d'agents intelligents dans le cadre d'applications web. Les techniques de personnalisation et de personnification sont de plus en plusutilis\'ees pour mieux r\'epondre aux besoins des utilisateurs. La plupart de ces techniques reposent sur des outils de raisonnement issus de l'intelligence artificielle. Cependant, ces techniques sont habituellement utilis\'es de mani\`ere ad-hoc pour chaque application. L'approche de cette th\`ese est de consid\'erer la personnalisation et la personnification comme deux instances d'alt\'eration de comportement, et \`a \'etudier l'alt\'eration du comportements d'agents rationnels. Les principales contributions sont WAIG, un formalisme bas\'e sur le langage Golog adapt\'e \`a l'expression d'applications web, et PAGE, un cadre formel pour la manipulation et l'alt\'eration de programmes agents Golog, permettant la transformation automatique d'agent selon un crit\`ere donn\'e. Ces contributions sont illustr\'es par plusieurs sc\'enarios concrets issus des domaines de la personnalisation et de la personnification.},
  collaborator = {Bourda, Yolaine and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {Sup\'elec},
  keywords = {AI,IA,Intelligence artificielle,Logical programing,Personalization,Personification,Personnalisation,Personnification,Programmation logique,Thesis,VAE},
  file = {C\:\\Home\\Zotero\\storage\\UX9VHQ2A\\Dubus - 2014 - Transformation de programmes logiques  applicatio.pdf}
}

@inproceedings{FRATANI_RM2021,
  title = {Ranking Geological Cross-Sections for Database Querying},
  booktitle = {2021 {{RING}} Meeting},
  author = {Fratani, Amandine and Viseur, Sophie and Popineau, Fabrice and Henry, Pierre and Ghattas, Badih and Oppenheim, Georges and Dhont, Damien and Gout, Claude},
  year = {2021},
  publisher = {{ASGA}},
  url = {https://www.ring-team.org/research-publications/ring-meeting-papers?view=pub&id=5051},
  abstract = {Geological cross-sections are convenient supports for synthesizing geological knowledge of given geological subsurface structures. They contain information about the geological time of the formations and their architecture. Querying a database of case study reports or papers with geological cross-sections could be then a convenient way to find geological analogues. Image-content query is used to achieve this kind of query. It is often performed using deep-learning, but these techniques require numerous pairs of original images and associated human-tagged images in order to obtain satisfying results after the training phase. Alternative approaches rely on image similarity measures based on textures, colours or shapes contained in the images. In this paper, we propose such a method for ranking geological cross-sections using two kinds of similarity measures: (i) the presence and proportion of formations from similar geological times; (ii) the global geological architecture. This approach combines the use of a colour dictionary and different correlation measures. Noddy is a software allowing synthetic geological cross-sections to be generated using a series of geological events (faulting, tilting, folding, etc.). A database of 100,000 geological cross-sections was generated using Noddy. In each cross-section, the layers are colored following the standard ICS color codes. Results of cross-section rankings are shown from this database and discussed.}
}

@article{groupedetravailtwg-tdsTDSStructureRepertoires2004,
  title = {{TDS : une structure de r\'epertoires pour les fichiers TeX}},
  author = {{Groupe de Travail TWG-TDS} and Popineau, Fabrice},
  translator = {Charpentier, Jean-C{\^o}me},
  year = {2004},
  journal = {Cahiers GUTenberg},
  number = {44\textendash 45},
  pages = {83--114},
  langid = {french},
  keywords = {\#nosource,⛔ No DOI found,journal,TeX},
  file = {C\:\\Home\\Zotero\\storage\\UEGTY7BN\\Groupe de Travail TWG-TDS et Popineau - 2004 - TDS  une structure de répertoires pour les fichie.pdf}
}

@inproceedings{hajriMORSSystemRecommending2017,
  title = {{{MORS}}: {{A System}} for {{Recommending OERs}} in a {{MOOC}}},
  shorttitle = {{{MORS}}},
  booktitle = {2017 {{IEEE}} 17th {{International Conference}} on {{Advanced Learning Technologies}} ({{ICALT}})},
  author = {Hajri, Hiba and Bourda, Yolaine and Popineau, Fabrice},
  year = {2017},
  month = jul,
  pages = {50--52},
  doi = {10/ghfbvb},
  abstract = {Personalization in the field of Technology Enhanced Learning (TEL) is a topic that received a lot of concern by researchers. At the same time, there is a growing amount of Open Educational Resources (OER) indexed according to the W3C standards. Relevant OERs can usefully complement the contents delivered to a learner during an online course. Computing the best OERs to offer to the learner at each point of his course is an aspect of personalization that we address in this paper. We designed our MORS system to solve this problem in the context of Massive Open Online Courses (MOOC). Our MORS system described in this paper, is based on a learner profile, on metadata describing the course and on a carefully crafted process to query the SparQL endpoints for OERs.},
  copyright = {All rights reserved},
  keywords = {\#nosource,Computational modeling,Computer architecture,conf,Data mining,Education,EIAH,learner profile,learning,Metadata,MOOC,OER,Personalization,recommendation,Recommender systems,VAE,Videos},
  file = {C\:\\Home\\Zotero\\storage\\UAD7M3EJ\\Hajri et al. - 2017 - MORS A System for Recommending OERs in a MOOC.pdf}
}

@incollection{hajriPersonalizedRecommendationOpen2018,
  title = {Personalized {{Recommendation}} of {{Open Educational Resources}} in {{MOOCs}}},
  booktitle = {Computer {{Supported Education}} - 10th {{International Conference}}, {{CSEDU}} 2018, {{Funchal}}, {{Madeira}}, {{Portugal}}, {{March}} 15-17, 2018, {{Revised Selected Papers}}},
  author = {Hajri, Hiba and Bourda, Yolaine and Popineau, Fabrice},
  editor = {McLaren, Bruce M. and Reilly, Rob and Zvacek, Susan and Uhomoibhi, James},
  year = {2018},
  series = {Communications in {{Computer}} and {{Information Science}}},
  volume = {1022},
  pages = {166--190},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-21151-6_9},
  url = {http://link.springer.com/10.1007/978-3-030-21151-6_9},
  urldate = {2021-08-07},
  abstract = {Today Online Learning Environments (OLE) like MOOCs and LMS are very commonly used and a huge number of students with very different profiles and backgrounds follow the same online courses. Still, personalized experience for attendees is not widely spread on the platforms hosting these courses. At the same time, there is a growing number of open educational resources (OER) that can helpfully enrich the content of online courses and even be chosen to match one-by-one the student tastes. Recommender systems may support personalization in OLE by providing each learner with learning objects carefully selected to help reaching their learning objectives. This kind of recommendation is more specific to compute than usual recommendations like consumer products: the recommendation depends not only on the learner profile, but also on the content of the course, because the recommendation needs to fit precisely with the course format at any point. In this article, we introduce MOORS, a MOOC-based OER recommender system that can be plugged in an OLE to dynamically provide recommendations of OER to learners on the basis of their profiles and the profile of the MOOC. We also describe the process for calculating recommendations from OER metadata, assuming these metadata follow the Linked Opend Data (LOD) principles. Our implementation has been done in Open edX, an open source MOOC platform widely used, however the same approach could be implemented in any OLE as long as the learners profiles and the course profile can be extracted. Finally, we discuss a life-size evaluation of our recommender system.},
  isbn = {978-3-030-21150-9},
  langid = {english},
  keywords = {⚠️ Invalid DOI,conf,EIAH,inbook,VAE},
  file = {C\:\\Home\\Zotero\\storage\\CIFIKXIR\\Hajri et al. - 2018 - Personalized Recommendation of Open Educational Re.pdf}
}

@phdthesis{hajriPersonnalisationMOOCPar2018,
  type = {{Th\`ese de doctorat}},
  title = {{Personnalisation des MOOC par la r\'eutilisation de Ressources \'Educatives Libres}},
  author = {Hajri, Hiba},
  year = {2018},
  month = jun,
  url = {https://theses.fr/2018SACLC046},
  urldate = {2021-08-07},
  abstract = {La personnalisation de l'apprentissage dans les environnements informatiques pour l'apprentissage humain (EIAH) est un sujet de recherche qui est trait\'e depuis de nombreuses ann\'ees. Avec l'arriv\'ee des cours en ligne ouverts et massifs (MOOC), la question de la personnalisation se pose de fa\c{c}on encore plus cruciale et de nouveaux d\'efis se pr\'esentent aux chercheurs. En effet, le m\^eme MOOC peut \^etre suivi par des milliers d'apprenants ayant des profils h\'et\'erog\`enes (connaissances, niveaux \'educatif, objectifs, etc). Il devient donc n\'ecessaire de tenir compte de cette h\'et\'erog\'en\'eit\'e en pr\'esentant aux apprenants des contenus \'educatifs adapt\'es \`a leurs profils afin qu'ils tirent parti au mieux du MOOC.D'un autre c\^ot\'e, de plus en plus de ressources \'educatives libres (REL) sont partag\'ees sur le web. Il est important de pouvoir r\'eutiliser ces REL dans un contexte diff\'erent de celui pour lequel elles ont \'et\'e cr\'e\'ees. En effet, produire des REL de qualit\'e est une activit\'e co\^uteuse en temps et la rentabilisation des REL passe par leur r\'eutilisation.Pour faciliter la d\'ecouverte des REL, des sch\'emas de m\'etadonn\'ees sont utilis\'es pour d\'ecrire les REL.Cependant, l'utilisation de ces sch\'emas a amen\'e \`a des entrep\^ots isol\'es de descriptions h\'et\'erog\`enes et qui ne sont pas interop\'erables. Afin de r\'egler ce probl\`eme, une solution adopt\'ee dans la litt\'erature consiste \`a appliquer les principes des donn\'ees ouvertes et li\'ees (LOD) aux descriptions des REL.Dans le cadre de cette th\`ese, nous nous int\'eressons \`a la personnalisation des MOOC et \`a la r\'eutilisation des REL.Nous proposons un syst\`eme de recommandation qui fournit \`a un apprenant en train de suivre un MOOC des ressources externes qui sont des REL adapt\'ees \`a son profil, tout en respectant les sp\'ecificit\'es du MOOC suivi.Pour s\'electionner les REL, nous nous int\'eressons \`a celles qui poss\`edent des descriptions ins\'er\'ees dans les LOD, stock\'ees dans des entrep\^ots accessibles sur le web et offrant des moyens d'acc\`es standardis\'es. Notre syst\`eme de recommandation est impl\'ement\'e dans une plateforme de MOOC, Open edX et il est \'evalu\'e en utilisant une plateforme de micro-t\^aches.},
  collaborator = {Bourda, Yolaine and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {Universit\'e Paris-Saclay (ComUE)},
  keywords = {Cours en ligne ouverts à tous,Données ouvertes,Données ouvertes et liées,Éducation et informatique,Linked open data,Mooc,Open educational resources,Personalization,Personnalisation,Ressources éducatives libres,Technologie éducative,Thesis,VAE},
  file = {C\:\\Home\\Zotero\\storage\\BWSG39KT\\Hajri - 2018 - Personnalisation des MOOC par la réutilisation de .pdf}
}

@inproceedings{hajriQueryingRepositoriesOER2015,
  title = {Querying {{Repositories}} of {{OER Descriptions}}: {{The Challenge}} of {{Educational Metadata Schemas Diversity}}},
  shorttitle = {Querying {{Repositories}} of {{OER Descriptions}}},
  booktitle = {Design for {{Teaching}} and {{Learning}} in a {{Networked World}} - 10th {{European Conference}} on {{Technology Enhanced Learning}}, {{EC-TEL}} 2015},
  author = {Hajri, Hiba and Bourda, Yolaine and Popineau, Fabrice},
  year = {2015},
  month = sep,
  series = {Design for {{Teaching}} and {{Learning}} in a {{Networked World}} - 10th {{European Conference}} on {{Technology Enhanced Learning}}, {{EC-TEL}} 2015},
  volume = {LNCS},
  pages = {582--586},
  publisher = {{Springer}},
  address = {{Toledo, Spain}},
  doi = {10/gmfpf6},
  url = {https://hal.archives-ouvertes.fr/hal-01275267},
  urldate = {2021-08-07},
  copyright = {All rights reserved},
  keywords = {\#nosource,⚠️ Invalid DOI,conf,EIAH,Linked Education,Linked Open Data,Metadata Schemas,VAE},
  file = {C\:\\Home\\Zotero\\storage\\XIGSXT5C\\Hajri et al. - 2015 - Querying Repositories of OER Descriptions The Cha.pdf}
}

@inproceedings{hajriSystemRecommendOpen2018,
  title = {A {{System}} to {{Recommend Open Educational Resources}} during an {{Online Course}}:},
  shorttitle = {A {{System}} to {{Recommend Open Educational Resources}} during an {{Online Course}}},
  booktitle = {Proceedings of the 10th {{International Conference}} on {{Computer Supported Education}}},
  author = {Hajri, Hiba and Bourda, Yolaine and Popineau, Fabrice},
  year = {2018},
  month = mar,
  pages = {99--109},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {{Funchal, Madeira, Portugal}},
  doi = {10/gmfn5w},
  url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006697000990109},
  urldate = {2021-08-07},
  copyright = {All rights reserved},
  isbn = {978-989-758-291-2},
  langid = {english},
  keywords = {\#nosource,conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\D5LZHZZI\\Hajri et al. - 2018 - A System to Recommend Open Educational Resources d.pdf}
}

@techreport{hawesPersonnalisationPersonnificationTuteurs2015,
  type = {{Stage de fin d'\'etudes}},
  title = {{Personnalisation et Personnification des Tuteurs Intelligents}},
  author = {Hawes, Hiba},
  year = {2015},
  month = sep,
  institution = {{Universit\'e de la Manouba, \'Ecole Nationale des Sciences de l'Informatique}},
  langid = {french},
  keywords = {\#nosource,Master,VAE}
}

@phdthesis{hayApprentissageRepresentationStyle2021,
  type = {{Th\`ese de doctorat}},
  title = {{Apprentissage de la repr\'esentation du style \'ecrit, application \`a la recommandation d'articles d'actualit\'e}},
  author = {Hay, Julien},
  year = {2021},
  url = {https://tel.archives-ouvertes.fr/tel-03420487},
  abstract = {La mod\'elisation des utilisateurs est une \'etape essentielle lorsqu'il s'agit de recommander des produits et proposer des services automatiquement. Les r\'eseaux sociaux sont une ressource riche et abondante de donn\'ees utilisateur (p. ex. liens partag\'es, messages post\'es) permettant de mod\'eliser leurs int\'er\^ets et pr\'ef\'erences. Dans cette th\`ese, nous proposons d'exploiter les articles d'actualit\'e partag\'es sur les r\'eseaux sociaux afin d'enrichir les mod\`eles existants avec une nouvelle caract\'eristique textuelle : le style \'ecrit. Cette th\`ese, \`a l'intersection des domaines du traitement automatique du langage naturel et des syst\`emes de recommandation, porte sur l'apprentissage de la repr\'esentation du style et de son application \`a la recommandation d'articles d'actualit\'e. Dans un premier temps, nous proposons une nouvelle m\'ethode d'apprentissage de la repr\'esentation du texte visant \`a projeter tout document dans un espace stylom\'etrique de r\'ef\'erence. L'hypoth\`ese test\'ee est qu'un tel espace peut \^etre g\'en\'eralis\'e par un ensemble suffisamment large d'auteurs de r\'ef\'erence, et que les projections vectorielles des \'ecrits d'un auteur \guillemotleft{} nouveau \guillemotright{} seront proches, d'un point de vue stylistique, des \'ecrits d'un sous-ensemble consistant de ces auteurs de r\'ef\'erence. Dans un second temps, nous proposons d'exploiter la repr\'esentation stylom\'etrique du texte pour la recommandation d'articles d'actualit\'e en la combinant \`a d'autres repr\'esentations (p. ex. th\'ematique, lexicale, s\'emantique). Nous cherchons \`a identifier les caract\'eristiques les plus compl\'ementaires pouvant permettre une recommandation d'articles plus pertinente et de meilleure qualit\'e. L'hypoth\`ese ayant motiv\'e ces travaux est que les choix de lecture des individus sont non seulement influenc\'es par le fond (p. ex. le th\`eme des articles d'actualit\'e, les entit\'es mentionn\'ees), mais aussi par la forme (c.-\`a-d. le style pouvant, par exemple, \^etre descriptif, satirique, compos\'e d'anecdotes personnelles, d'interviews). Les exp\'erimentations effectu\'ees montrent que non seulement le style \'ecrit joue un r\^ole dans les pr\'ef\'erences de lecture des individus, mais aussi que, lorsqu'il est combin\'e \`a d'autres caract\'eristiques textuelles, permet d'augmenter la pr\'ecision et la qualit\'e des recommandations en termes de diversit\'e, de nouveaut\'e et de s\'erendipit\'e.},
  langid = {french},
  school = {Universit\'e Paris-Saclay},
  keywords = {Thesis},
  file = {C\:\\Home\\Zotero\\storage\\XZGBJP9T\\Hay - 2021 - Apprentissage de la représentation du style écrit,.pdf}
}

@incollection{hayAutomaticallySelectingComplementary2018,
  title = {Automatically {{Selecting Complementary Vector Representations}} for {{Semantic Textual Similarity}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Management}}: {{Volume}} 8},
  author = {Hay, Julien and {Van de Cruys}, Tim and Muller, Philippe and Doan, Bich-Li{\^e}n and Popineau, Fabrice and Hay, Julien and Van De Cruys, Tim and Muller, Philippe and Doan, Bich-Lien and Popineau, Fabrice and Ouassim, Ait-Elhara},
  editor = {Pinaud, Bruno and Guillet, Fabrice and Gandon, Fabien and Largeron, Christine},
  year = {2018},
  series = {Studies in {{Computational Intelligence}}},
  volume = {834},
  pages = {45--60},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-030-18129-1_3},
  abstract = {The goal of the Semantic Textual Similarity task is to automatically quantify the semantic similarity of two text snippets. Since 2012, the task has been organized on a yearly basis as a part of the SemEval evaluation campaign. This paperHay, Julien~presentsVan de Cruys, Tim~a method that aims to combine differentMuller, Philippe~sentence-based vector representations in order to improve the computation of semantic similarity values. Our hypothesis is that such a combinationDoan, Bich-Li\^en~of different representations allows us to pinpoint different semantic aspects, which improves the accuracy ofPopineau, Fabrice~similarity computations. The method's main difficulty lies in the selection of the most complementaryAit-Elhara, Ouassim\textasciitilde{} representations, for which we present an optimization method. Our final system is based on the winning system of the 2015 evaluation campaign, augmented with the complementary vector representations selected by our optimization method. We also present evaluation results on the dataset of the 2016 campaign, which confirms the benefit of our method.},
  copyright = {All rights reserved},
  isbn = {978-3-030-18129-1},
  keywords = {⚠️ Invalid DOI,⛔ No DOI found,inbook,IR},
  file = {C\:\\Home\\Zotero\\storage\\BF3TTFPE\\Hay et al. - 2018 - Automatically selecting complementary vector repre.pdf}
}

@inproceedings{hayComplementaritesRepresentationsVectorielles2018,
  title = {{Compl\'ementarit\'es de repr\'esentations vectorielles pour la similarit\'e s\'emantique}},
  booktitle = {{18e Journees Francophones Extraction et Gestion de Connaissances (EGC 2018)}},
  author = {Hay, Julien and Van De Cruys, Tim and Muller, Philippe and Doan, Biech Lien and Popineau, Fabrice and Benamsili, Lyes},
  year = {2018},
  month = jan,
  volume = {E-34},
  pages = {179--190},
  publisher = {{\'Editions RNTI}},
  address = {{Paris, France}},
  url = {https://hal.archives-ouvertes.fr/hal-02283159},
  urldate = {2021-08-07},
  abstract = {La t\^ache de similarit\'e s\'emantique textuelle consiste \`a exprimer automatiquement un nombre refl\'etant la similarit\'e s\'emantique de deux fragments de texte. Chaque ann\'ee depuis 2012, les campagnes de SemEval d\'eroulent cette t\^ache de similarit\'e s\'emantique textuelle. Cet article pr\'esente une m\'ethode associant diff\'erentes repr\'esentations vectorielles de phrases dans l'objectif d'am\'eliorer les r\'esultats obtenus en similarit\'e s\'emantique. Notre hypoth\`ese est que diff\'erentes repr\'esentations permettraient de repr\'esenter diff\'erents aspects s\'emantiques, et par extension, d'am\'eliorer les similarit\'es calcul\'ees, la principale difficult\'e \'etant de s\'electionner les repr\'esentations les plus compl\'ementaires pour cette t\^ache. Notre syst\`eme se base sur le syst\`eme vainqueur de la campagne de 2015 ainsi que sur notre m\'ethode de s\'election par compl\'ementarit\'e. Les r\'esultats obtenus viennent confirmer l'int\'er\^et de cette m\'ethode lorsqu'ils sont compar\'es aux r\'esultats de la campagne de 2016.},
  langid = {french},
  keywords = {⛔ No DOI found,confnat,IR,sémantique,Similarité},
  file = {C\:\\Home\\Zotero\\storage\\XPI8A2PV\\Hay et al. - 2018 - Complémentarités de représentations vectorielles p.pdf}
}

@inproceedings{hayFilteringReferenceCorpus2021,
  title = {Filtering a {{Reference Corpus}} to {{Generalize Stylometric Representations}}},
  booktitle = {12th {{International Conference}} on {{Knowledge Discovery}} and {{Information Retrieval}}},
  author = {Hay, Julien and Doan, Bich-Li{\^e}n and Popineau, Fabrice and Elhara, Ouassim},
  year = {2021},
  month = mar,
  pages = {259--268},
  url = {https://www.scitepress.org/Link.aspx?doi=10.5220/0010138802590268},
  urldate = {2021-03-16},
  abstract = {Digital Library},
  copyright = {All rights reserved},
  isbn = {978-989-758-474-9},
  keywords = {\#nosource,conf,IR},
  annotation = {ZSCC: NoCitationData[s0]},
  file = {C\:\\Home\\Zotero\\storage\\WUTFEJ84\\Hay et al. - 2021 - Filtering a Reference Corpus to Generalize Stylome.pdf}
}

@inproceedings{hayRepresentationLearningWriting2020,
  title = {Representation Learning of Writing Style},
  booktitle = {Proceedings of the {{Sixth Workshop}} on {{Noisy User-generated Text}} ({{W-NUT}} 2020)},
  author = {Hay, Julien and Doan, Bich-Lien and Popineau, Fabrice and Ait Elhara, Ouassim},
  year = {2020},
  month = nov,
  pages = {232--243},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2020.wnut-1.30},
  url = {https://www.aclweb.org/anthology/2020.wnut-1.30},
  urldate = {2021-03-16},
  abstract = {In this paper, we introduce a new method of representation learning that aims to embed documents in a stylometric space. Previous studies in the field of authorship analysis focused on feature engineering techniques in order to represent document styles and to enhance model performance in specific tasks. Instead, we directly embed documents in a stylometric space by relying on a reference set of authors and the intra-author consistency property which is one of two components in our definition of writing style. The main intuition of this paper is that we can define a general stylometric space from a set of reference authors such that, in this space, the coordinates of different documents will be close when the documents are by the same author, and spread away when they are by different authors, even for documents by authors who are not in the set of reference authors. The method we propose allows for the clustering of documents based on stylistic clues reflecting the authorship of documents. For the empirical validation of the method, we train a deep neural network model to predict authors of a large reference dataset consisting of news and blog articles. Albeit the learning process is supervised, it does not require a dedicated labeling of the data but it relies only on the metadata of the articles which are available in huge amounts. We evaluate the model on multiple datasets, on both the authorship clustering and the authorship attribution tasks.},
  keywords = {\#nosource,conf,IR},
  annotation = {ZSCC: 0000000},
  file = {C\:\\Home\\Zotero\\storage\\JRR8KQYB\\Hay et al. - 2020 - Representation learning of writing style.pdf}
}

@inproceedings{jacquiotGEAHSGenericEducational2004,
  title = {{{GEAHS}}: {{A Generic Educational Adaptive Hypermedia System}}},
  shorttitle = {{{GEAHS}}},
  booktitle = {{{EdMedia}} + {{Innovate Learning}}},
  author = {Jacquiot, Cedric and Bourda, Yolaine and Popineau, Fabrice},
  year = {2004},
  pages = {571--578},
  publisher = {{Association for the Advancement of Computing in Education (AACE)}},
  url = {https://www.learntechlib.org/primary/p/12989/},
  urldate = {2021-08-07},
  abstract = {GEAHS is a platform designed to ease the development of Adaptive Educational Hypermedia. In this document, we explain the underlying principles of this platform. Genericity is achieved thanks to an adaptation engine based on conceptual graphs, situation calculus and RDF. We are currently working on a graphical tool to build an AEH system designed on top of our engine. This paper describes the main aspects of our system, as well as the use we make of standards and recommendations.},
  isbn = {978-1-880094-53-2},
  langid = {english},
  keywords = {conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\8A92IERR\\Jacquiot et al. - 2004 - GEAHS A Generic Educational Adaptive Hypermedia S.pdf}
}

@inproceedings{jacquiotGEAHSGenericEducational2004a,
  title = {{{GEAHS}}: {{A Generic Educational Adaptive Hypermedia System Based}} on {{Situation Calculus}}},
  booktitle = {Adaptive Hypermedia and Adaptive Web-Based Systems, Third International Conference, {{AH}} 2004, Eindhoven, the Netherlands, August 23-26, 2004, Proceedings},
  author = {Jacquiot, C{\'e}dric and Bourda, Yolaine and Popineau, Fabrice},
  editor = {Bra, Paul De and Nejdl, Wolfgang},
  year = {2004},
  series = {Lecture Notes in Computer Science},
  volume = {3137},
  pages = {413--416},
  publisher = {{Springer}},
  doi = {10.1007/978-3-540-27780-4_63},
  url = {https://doi.org/10.1007/978-3-540-27780-4_63},
  abstract = {GEAHS is a platform designed to ease the development of Adaptive Educational Hypermedia, using standard formalisms. In this document, we explain the underlying principles of this platform. Genericity is achieved thanks to an adaptation engine based on situation calculus and RDF. This paper describes the main aspects of our system, as well as the use we make of situation calculus to create a simpler, more reusable adaptive hypermedia system.},
  isbn = {978-3-540-22895-0},
  langid = {english},
  keywords = {conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\5B6AFP7H\\Jacquiot et al. - 2004 - GEAHS A Generic Educational Adaptive Hypermedia S.pdf}
}

@inproceedings{jacquiotGLAMGenericLayered2006,
  title = {{{GLAM}}: {{A}} Generic Layered Adaptation Model for Adaptive Hypermedia Systems},
  booktitle = {Adaptive Hypermedia and Adaptive Web-Based Systems, 4th International Conference, {{AH}} 2006, Dublin, Ireland, June 21-23, 2006, Proceedings},
  author = {Jacquiot, C{\'e}dric and Bourda, Yolaine and Popineau, Fabrice and Delteil, Alexandre and Reynaud, Chantal},
  editor = {V. Wade, H. Ashman and Smyth, B.},
  year = {2006},
  month = jun,
  series = {{{LNCS}}},
  volume = {4018},
  pages = {131--140},
  publisher = {{Springer-Verlag}},
  copyright = {All rights reserved},
  keywords = {\#nosource,⚠️ Invalid DOI,conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\R8HA2IHU\\Jacquiot et al. - 2006 - GLAM A generic layered adaptation model for adapt.pdf}
}

@phdthesis{jacquiotModelisationLogiqueGenerique2006,
  type = {{Th\`ese de doctorat}},
  title = {{Mod\'elisation logique et g\'en\'erique des syst\`emes d'hyperm\'edias adaptatifs}},
  author = {Jacquiot, C{\'e}dric},
  year = {2006},
  month = jan,
  url = {https://theses.fr/2006PA112269},
  urldate = {2021-08-07},
  abstract = {Les hyperm\'edias adaptatifs, comme tous les syst\`emes \`a base de connaissances, peuvent \^etre divis\'es en deux parties : une partie statique, permettant la repr\'esentation de donn\'ees relatives aux domaines \`a traiter, et une partie dynamique, consacr\'ee au traitement des donn\'ees par diff\'erents proc\'ed\'es. Les mod\`eles de donn\'ees existants sont souvent difficiles \`a r\'eutiliser car ils sont soit tr\`es sp\'ecifiques \`a une application particuli\`ere, soit tr\`es g\'en\'eraux et, dans ce cas, il est rarement possible de les rendre plus sp\'ecifiques pour un domaine d'application particulier. Les mod\`eles d'adaptation existants se limitent souvent \`a des langages de r\`egles, qui ne font pas de distinction entre les diff\'erentes sortes de donn\'ees. Cette th\`ese propose des mod\`eles g\'en\'eriques de donn\'ees, d\'ecrits sous forme de diagrammes de classe UML, permettant par sp\'ecialisation la cr\'eation de mod\`eles sp\'ecifiques \`a un domaine d'application. Elle pr\'esente \'egalement un mod\`ele d'adaptation enti\`erement d\'ecrit en calcul des pr\'edicats du premier ordre, bas\'e sur la logique situationnelle, et muni d'un langage de r\`egles constitu\'e de plusieurs niveaux, prenant en compte les diff\'erents types de donn\'ees \`a des niveaux diff\'erents du langage. Ce langage introduit, en outre, une forme de m\'eta-adaptation, par s\'election de strat\'egies de parcours du domaine. Cette th\`ese introduit la notion de parcours par tron\c{c}ons, qui offre une solution interm\'ediaire, entre le parcours libre et le parcours guid\'e. L'ensemble des mod\`eles est utilis\'e pour proposer une application dans le domaine du e-learning.},
  collaborator = {Reynaud, Chantal and Bourda, Yolaine and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {Paris 11},
  keywords = {E-learning,Méta-adaptation,Système de déduction,Thesis,VAE},
  annotation = {Prix de Th\`ese de la Fondation Jean-Luc Lagard\`ere},
  file = {C\:\\Home\\Zotero\\storage\\JBCJAEN6\\Jacquiot - 2006 - Modélisation logique et générique des systèmes d'h.pdf}
}

@inproceedings{jacquiotReusabilityGEAHS2004,
  title = {Reusability in {{GEAHS}}},
  booktitle = {Engineering Advanced Web Applications: {{Proceedings}} of Workshops in Connection with the 4th International Conference on Web Engineering ({{ICWE}} 2004), Munich, Germany, 28-30 July, 2004},
  author = {Jacquiot, C{\'e}dric and Bourda, Yolaine and Popineau, Fabrice},
  editor = {Matera, Maristella and Comai, Sara},
  year = {2004},
  pages = {199--209},
  publisher = {{Rinton Press}},
  address = {{Munich, Germany}},
  url = {https://hal-supelec.archives-ouvertes.fr/hal-00263858},
  abstract = {GEAHS (Generic Educational Adaptive Hypermedia System) is a platform designed to ease the development of Adaptive Educational Hypermedia, using standard formalisms. In this document, we explain the underlying principles of this platform. Genericity is achieved thanks to an adaptation engine based on situation calculus and RDF. This paper describes the main aspects of our system, as well as the use we make of situation calculus to create a more reusable adaptive hypermedia system.},
  langid = {english},
  keywords = {\#nosource,⛔ No DOI found,conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\BVBGYSCY\\Jacquiot et al. - 2004 - Reusability in GEAHS.pdf}
}

@inproceedings{jacquiotSEWAGOGenericAdaptive2003,
  title = {{{SEWAGO}} : {{A}} Generic Adaptive Educational Hypermedia System.},
  booktitle = {{{HYPERTEXT}} '03: {{Proceedings}} of the Fourteenth {{ACM}} Conference on {{Hypertext}} and {{Hypermedia}}},
  author = {Jacquiot, C{\'e}dric and Bourda, Yolaine and Popineau, Fabrice},
  year = {2003},
  month = aug,
  address = {{Nottingham, UK}},
  abstract = {In this document, we explain the main principles and architecture of SEWAGO (SEveral WAys to GO), a generic adaptive educational hypermedia system we are working on. More precisely, SEWAGO is a platform for creating adaptive educational hypermedias, using the strictest and most reusable architecture. This system is based on first order logic and situation calculus (through a modified version of GoLog).},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {\#nosource,⛔ No DOI found,EIAH,poster,VAE},
  file = {C\:\\Home\\Zotero\\storage\\I3W6KWR9\\Jacquiot et al. - 2003 - SEWAGO  A generic adaptive educational hypermedia.pdf}
}

@article{meguebliBetterNewsArticle2017,
  title = {Towards Better News Article Recommendation: {{With}} the Help of User Comments},
  shorttitle = {Towards Better News Article Recommendation},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2017},
  month = nov,
  journal = {World Wide Web},
  volume = {20},
  number = {6},
  pages = {1293--1312},
  issn = {1386-145X, 1573-1413},
  doi = {10.1007/s11280-017-0436-2},
  url = {http://link.springer.com/10.1007/s11280-017-0436-2},
  urldate = {2021-08-07},
  abstract = {News media platforms publish articles about daily events letting their users comment on them, and forming interesting discussions in almost real-time. To keep users always active and interested, media platforms need an effective recommender system to bring up new articles that match user interests. In this article, we show that we can improve the quality of recommendation by exploiting valuable information provided by user comments. This information reveals aspects not directly tackled by the news article on which they have been posted. We call such aspects latent aspects. We demonstrate how these latent aspects can make a crucial difference in the accuracy of future recommendation. The challenge in detecting them is due to the noisy nature of user comments. To support our claim, we propose a novel news recommendation system that (1) enriches the description of news articles by latent aspects extracted from user comments, (2) deals with noisy comments by proposing a model for user comments ranking, and (3) proposes a diversification model to remove redundancies and provide a wide coverage of aspects. We have tested our approach using large collections of real user activities in four news Web sites, namely The INDEPENDENT, The Telegraph, CNN and Al-Jazeera. The results show that our approach outperforms baseline approaches achieving a significantly higher accuracy.},
  langid = {english},
  keywords = {\#nosource,IR,journal},
  file = {C\:\\Home\\Zotero\\storage\\XXXAZGDL\\Meguebli et al. - 2017 - Towards better news article recommendation With t.pdf}
}

@inproceedings{meguebliBuildingRichUser2014,
  title = {Building Rich User Profiles for Personalized News Recommendation},
  booktitle = {Posters, Demos, Late-Breaking Results and Workshop Proceedings of the 22nd Conference on User Modeling, Adaptation, and Personalization Co-Located with the 22nd Conference on User Modeling, Adaptation, and Personalization ({{UMAP2014}})},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2014},
  month = jul,
  pages = {33--40},
  address = {{Aalborg, Denmark}},
  copyright = {All rights reserved},
  keywords = {\#nosource,⛔ No DOI found,conf,IR,VAE},
  file = {C\:\\Home\\Zotero\\storage\\LTUD82RG\\Meguebli et al. - 2014 - Building rich user profiles for personalized news .pdf}
}

@inproceedings{meguebliExploitingSocialDebates2014,
  title = {Exploiting {{Social Debates}} for {{Opinion Ranking}}},
  booktitle = {{{KDIR}} 2014 - Proceedings of the International Conference on Knowledge Discovery and Information Retrieval, Rome, Italy},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2014},
  month = oct,
  pages = {250--260},
  publisher = {{SciTePress}},
  address = {{Rome, Italy}},
  doi = {10.5220/0005081702500260},
  abstract = {The number of opinions in news media platforms is increasing dramatically with daily news hits, and people spending more and more time to discuss topics and share experiences. Such user generated content represents a promising source for improving the effectiveness of news articles recommendation and retrieval. However, the corpus of opinions is often large and noisy making it hard to find prominent content. In this paper, we tackle this problem by proposing a novel scoring model that ranks opinions based on their relevance and prominence. We define the prominence of an opinion using its relationships with other opinions. To this end, we (1) create a directed graph of opinions where each link represents the sentiment an opinion expresses about another opinion (2) propose a new variation of the PageRank algorithm that boosts the scores of opinions along links with positive sentiments and decreases them along links with negative sentiments. We have tested the effectiveness of our model through extensive experiments using three datasets crawled from CNN, Independent, and The Telegraph Web sites . The experiments show that our scoring model achieves high quality results.},
  keywords = {\#nosource,conf,IR},
  file = {C\:\\Home\\Zotero\\storage\\MR992UI3\\Meguebli et al. - 2014 - Exploiting Social Debates for Opinion Ranking.pdf}
}

@inproceedings{meguebliHowHiddenAspects2014,
  title = {How {{Hidden Aspects Can Improve Recommendation}}?},
  booktitle = {6th {{International Conference}}, {{SocInfo}} 2014},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2014},
  month = nov,
  series = {Social {{Informatics}}},
  volume = {8851},
  pages = {269--278},
  publisher = {{Springer}},
  address = {{Barcelone, Spain}},
  doi = {10/gmfpj3},
  url = {https://hal-supelec.archives-ouvertes.fr/hal-01105283},
  abstract = {Nowadays, more and more people are using online news platforms as their main source of information about daily life events. Users of such platforms discuss around topics providing new insights and sometimes revealing hidden aspects about topics. The valuable information provided by users needs to be exploited to improve the accuracy of news recommendation and thus keep users always motivated to provide comments. However, exploiting user generated content is very challenging due its noisy nature. In this paper, we address this problem by proposing a novel news recommendation system that (1) enrich the profile of news article with user generated content, (2) deal with noisy contents by proposing a ranking model for users' comments, and (3) propose a diversification model for comments to remove redundancies and provide a wide coverage of topic aspects. The results show that our approach outperforms baseline approaches achieving high accuracy.},
  copyright = {All rights reserved},
  isbn = {978-3-319-13733-9},
  keywords = {\#nosource,⚠️ Invalid DOI,conf,IR},
  file = {C\:\\Home\\Zotero\\storage\\6859DP2I\\Meguebli et al. - 2014 - How Hidden Aspects Can Improve Recommendation.pdf}
}

@phdthesis{meguebliLeveragingUserGeneratedContent2015,
  title = {Leveraging {{User-Generated Content}} for {{Enhancing}} and {{Personalizing News Recommendation}}.},
  author = {Meguebli, Youssef},
  year = {2015},
  month = mar,
  url = {https://tel.archives-ouvertes.fr/tel-01323014},
  urldate = {2021-08-07},
  abstract = {In this thesis, we have investigated how to exploit user-generated-content for personalized news recommendation purpose. The intuition behind this line of research is that the opinions provided by users, on news websites, represent a strong indicator about their profiles. We have addressed this problem by proposing three main contributions. Firstly, we have proposed a profile model that accurately describes both users' interests and news article contents. The profile model was tested on three different applications ranging from identifying the political orientation of users to the context of news recommendation and the diversification of the list of recommended news articles. Results show that our profile model give much better results compared to state-of-the-art models. Secondly, we have investigated the problem of noise on opinions and how we can retrieve only relevant opinions in response to a given query.The proposed opinion ranking strategy is based on users' debates features. We have used a variation of PageRank technique to define the score of each opinion. Results show that our approach outperforms two recent proposed opinions ranking strategies, particularly for controversial topics. Thirdly, we have investigated different ways of leveraging opinions on news article contents including all opinions, topk opinions based on opinion ranking strategy, and a set of diverse opinion. To extract a list of diverse opinions, we have employed a variation of an existing opinion diversification model. Results show that diverse opinions give the best performance over other leveraging strategies.},
  langid = {english},
  school = {CentraleSup\'elec},
  keywords = {Thesis},
  file = {C\:\\Home\\Zotero\\storage\\4DJZQF58\\Meguebli - 2015 - Leveraging User-Generated Content for Enhancing an.pdf}
}

@inproceedings{meguebliNovelArchitectureSmart2012,
  title = {A {{Novel Architecture}} for a {{Smart Information Retrieval System Based}} on {{Opinions Engineering}}},
  booktitle = {Proceedings of the Sixth Symposium on Human-Computer Interaction and Information Retrieval {{HCIR}}'12},
  author = {Meguebli, Youssef and Doan, Bich-Li{\^e}n and Popineau, Fabrice and Bourda, Yolaine},
  year = {2012},
  month = oct,
  pages = {4 pages},
  address = {{Cambridge, United States}},
  url = {https://hal-supelec.archives-ouvertes.fr/hal-00765342},
  urldate = {2021-08-07},
  abstract = {In this paper, we present a novel architecture for personalized information retrieval (IR) and a simple scenario that illustrate the contribution of this architecture compared to current personalized IR. We use an extension of a Dung argumentation framework in order to improve the precision of our personalized information retrieval. We use also social media and search history to define the user-profile.},
  langid = {english},
  keywords = {⛔ No DOI found,conf,IR},
  file = {C\:\\Home\\Zotero\\storage\\GGEY4D5Q\\Meguebli et al. - 2012 - A Novel Architecture for a Smart Information Retri.pdf}
}

@inproceedings{meguebliPersonalizingInformationRetrieval2016,
  title = {Personalizing {{Information Retrieval Using}} an {{Extension}} of a {{Dung Argumentation}}},
  booktitle = {2016 {{IEEE Intl Conference}} on {{Computational Science}} and {{Engineering}} ({{CSE}}) and {{IEEE Intl Conference}} on {{Embedded}} and {{Ubiquitous Computing}} ({{EUC}}) and 15th {{Intl Symposium}} on {{Distributed Computing}} and {{Applications}} for {{Business Engineering}} ({{DCABES}})},
  author = {Meguebli, Youssef and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2016},
  month = aug,
  pages = {681--686},
  doi = {10/gmfpf5},
  url = {https://ieeexplore.ieee.org/document/7982323},
  abstract = {In this paper, we propose an architecture for personalizing information retrieval (IR), exploiting the interactions between the user and the social network. We use an extension of a Dung argumentation framework to show how the precision of the personalized information retrieval system could be improved. We use also social media and search history to define the user-profile which is represented by a restriction of a Description Logic.},
  keywords = {\#nosource,Blogs,conf,Conferences,Dung argumentation framework,EIAH,History,Indexes,Information retrieval,IR,opinions engineering,Query processing,social media,Social network services,User-profile model,VAE},
  file = {C\:\\Home\\Zotero\\storage\\6XPXIEXA\\Meguebli et al. - 2016 - Personalizing Information Retrieval Using an Exten.pdf}
}

@inproceedings{meguebliStoriesYouTwoStage2014,
  title = {Stories {{Around You A Two-Stage Personalized News Recommendation}}},
  booktitle = {{{KDIR}} 2014 - Proceedings of the International Conference on Knowledge Discovery and Information Retrieval},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  year = {2014},
  month = oct,
  pages = {473--479},
  publisher = {{SciTePress}},
  address = {{Rome, Italy}},
  doi = {10/gg5vx3},
  abstract = {With the tremendous growth of published news articles, a key issue is how to help users find diverse and interesting news stories. To this end, it is crucial to understand and build accurate profiles for both users and news articles. In this paper, we define a user profile based on (1) the set of entities she/he talked about it in her/his comments and (2) the set of key-concepts related to those entities on which the user has expressed an opinion or a viewpoint. The same information is extracted from the content of each news article to create its profile. In a first step, we matched those profiles using a new similarity measure. We use also the news articles profiles to diversify the list of recommended stories in a second step. A first evaluation involving the activities of 150 real users in four news web sites, namely The Independent, The Telegraph, CNN and Aljazeera has shown the effectiveness of our approach compared to recent works.},
  keywords = {\#nosource,conf,IR},
  file = {C\:\\Home\\Zotero\\storage\\R974AL8G\\Meguebli et al. - 2014 - Stories Around You A Two-Stage Personalized News R.pdf}
}

@inproceedings{meguebliUnsupervisedApproachIdentifying2014,
  title = {Unsupervised Approach for Identifying Users' Political Orientations},
  booktitle = {Advances in Information Retrieval - 36th European Conference on {{IR}} Research, {{ECIR}} 2014, Amsterdam, the Netherlands, April 13-16, 2014. {{Proceedings}}},
  author = {Meguebli, Youssef and Kacimi, Mouna and Doan, Bich-Li{\^e}n and Popineau, Fabrice},
  editor = {{de Rijke}, Maarten and Kenter, Tom and {de Vries}, Arjen P. and Zhai, ChengXiang and {de Jong}, Franciska and Radinsky, Kira and Hofmann, Katja},
  year = {2014},
  series = {Lecture Notes in Computer Science},
  volume = {8416},
  pages = {507--512},
  publisher = {{Springer}},
  doi = {10/ghfbvc},
  copyright = {All rights reserved},
  keywords = {\#nosource,⚠️ Invalid DOI,conf,IR},
  file = {C\:\\Home\\Zotero\\storage\\EWLA7G5X\\Meguebli et al. - 2014 - Unsupervised approach for identifying users' polit.pdf}
}

@book{norvigIntelligenceArtificielle4e2021,
  title = {{Intelligence artificielle 4e \'edition}},
  author = {Norvig, Peter and Russell, Stuart},
  editor = {Popineau, Fabrice},
  translator = {Popineau, Fabrice and Miclet, Laurent and {Claire Cadet}},
  year = {2021},
  edition = {Fourth},
  publisher = {{Pearson}},
  address = {{Paris}},
  abstract = {La bible en intelligence artificielle. Cet ouvrage est LE manuel de r\'ef\'erence en intelligence artificielle. C'est le seul ouvrage \`a couvrir de fa\c{c}on aussi compl\`ete et moderne tout le champ th\'eorique et pratique de l'intelligence artificielle. C'est aussi le seul ouvrage \`a proposer une vision unifi\'ee de l'intelligence artificielle, centr\'ee autour de la notion d'agent intelligent. Les diff\'erents champs disciplinaires autour de l'IA sont abord\'es avec un tr\`es grand nombre de renvois entre les sections, ce qui constitue une richesse inestimable de l'ouvrage qui expose les connexions entre des domaines qui sont le plus souvent pr\'esent\'es comme ind\'ependants. La 4e \'edition informe les lecteurs sur les derni\`eres technologies, pr\'esente les concepts de mani\`ere plus unifi\'ee et couvre de mani\`ere nouvelle ou \'elargie l'apprentissage automatique, l'apprentissage profond, l'apprentissage par transfert, les syst\`emes multi-agents, la robotique, le traitement du langage naturel, la causalit\'e, la programmation probabiliste, le respect de la vie priv\'ee, l'\'equit\'e et la s\'ecurit\'e.},
  isbn = {978-2-326-00221-0},
  langid = {french},
  keywords = {\#nosource,artificial intelligence,otherpub}
}

@article{popineauAffichezVosDocuments2000,
  title = {{Affichez vos documents LaTeX sur le Web avec TeX4ht}},
  author = {Popineau, Fabrice},
  year = {2000},
  journal = {Cahiers GUTenberg},
  number = {37-38},
  pages = {5--43},
  issn = {1140-9304},
  doi = {10/ghfbvh},
  url = {http://cahiers.gutenberg.eu.org/fitem?id=CG_2000___37-38_5_0},
  urldate = {2021-08-07},
  abstract = {Eitan Gurari is TEX4ht's author, a clever tool which allows TEX and LATEX documents to be translated to html and xml. I'd like to show here that TEX4ht is of simple use, powerful and extensible. Let's have a look at its features.},
  langid = {french},
  keywords = {journal,TeX},
  file = {C\:\\Home\\Zotero\\storage\\783D4VCS\\Popineau - 2000 - Affichez vos documents LaTeX sur le Web avec TeX4h.pdf}
}

@book{popineauAlgorithmesNotesCours2016,
  title = {{Algorithmes : notes de cours}},
  author = {Popineau, Fabrice},
  year = {2016},
  publisher = {{CentraleSup\'elec}},
  langid = {french},
  keywords = {\#nosource,poly}
}

@book{popineauANSICommonLisp2005,
  title = {{ANSI Common Lisp}},
  author = {Popineau, Fabrice},
  year = {2005},
  publisher = {{Sup\'elec}},
  langid = {french},
  keywords = {\#nosource,LISP,poly}
}

@article{popineauDirectionsTEXLiveSystem2001,
  title = {Directions for the {{TEXLive}} System},
  author = {Popineau, Fabrice},
  year = {2001},
  journal = {MAPS},
  number = {26},
  pages = {151--161},
  abstract = {This paper is about the current status of the TEXLive software. The first part of the paper will address the structured description of its content and how the Windows setup program can use it. The past experiments with the Windows installer have revealed that the problem was harder than expected. The new TEXLive 6 description files will allow a more effective way to use the setup program. Some further enhancements are even scheduled. The second part of the paper will address a set of possible extensions to the Web2C/Kpathsea pair (read it as a call for code contributions!). Some aspects of its use were not foreseen when it was devised and it may be time for an enhancement.},
  langid = {english},
  keywords = {⛔ No DOI found,conf,journal,TeX},
  file = {C\:\\Home\\Zotero\\storage\\E67ACJQI\\Popineau - 2001 - Directions for the TEXLive system.pdf}
}

@book{popineauElementsInformatiqueTheorique2005,
  title = {{\'El\'ements d'Informatique Th\'eorique}},
  author = {Popineau, Fabrice},
  year = {2005},
  publisher = {{Sup\'elec}},
  langid = {french},
  keywords = {\#nosource,poly}
}

@article{popineauFpTEXTeTEXbasedDistribution1999,
  title = {{{fpTEX}}: {{A teTEX-based Distribution}} for {{Windows}}},
  author = {Popineau, Fabrice},
  year = {1999},
  journal = {TUGBoat},
  volume = {20},
  number = {3},
  pages = {290--297},
  abstract = {This paper deals with the ins and outs of porting the widely used teTEX distribution to the Windows environment. The choices made and difficulties experienced are related, a brief description of this huge distribution is given and the future work is sketched out.},
  langid = {english},
  keywords = {⛔ No DOI found,conf,TeX},
  file = {C\:\\Home\\Zotero\\storage\\HYZ5S9LV\\Popineau - 1999 - fpTEX A teTEX-based Distribution for Windows.pdf}
}

@article{popineauFpTeXTeTeXPour1999,
  title = {{fpTeX : teTeX pour Win32}},
  shorttitle = {{fpTeX}},
  author = {Popineau, Fabrice},
  year = {1999},
  journal = {Cahiers GUTenberg},
  number = {32},
  pages = {47--61},
  issn = {1140-9304},
  doi = {10/ghfbvk},
  url = {http://cahiers.gutenberg.eu.org/fitem?id=CG_1999___32_47_0},
  urldate = {2021-08-07},
  langid = {french},
  keywords = {conf,TeX},
  file = {C\:\\Home\\Zotero\\storage\\CQJED26K\\Popineau - 1999 - fpTeX  teTeX pour Win32.pdf}
}

@inproceedings{popineauGeneratingAdaptiveHypermedia2003,
  title = {Generating Adaptive Hypermedia with {{Golog}} and Conceptual Graphs},
  booktitle = {Proceedings 3rd {{IEEE International Conference}} on {{Advanced Technologies}}},
  author = {Popineau, F. and Bourda, Y. and Doan, B.-L.},
  year = {2003},
  month = jul,
  pages = {463--466},
  publisher = {{IEEE Computer Society}},
  address = {{Athens, Greece}},
  doi = {10/cq9bcv},
  abstract = {We present an adaptive hypermedia architecture based on Golog and conceptual graphs. We propose a conceptual graph model for the description of the hypermedia structure and the use of Golog, a logic programming language, for the generation of the personalized hypermedia. This approach has been validated by a prototype and two examples based on different domains.},
  copyright = {All rights reserved},
  keywords = {\#nosource,Calculus,conf,Education,EIAH,Engines,Logic programming,poster,Prototypes,Resource description framework,Robots,Semantic Web,Testing,VAE,Writing},
  file = {C\:\\Home\\Zotero\\storage\\RRHE247T\\Popineau et al. - 2003 - Generating adaptive hypermedia with Golog and conc.pdf}
}

@article{popineauInformacjaNtTeXLive2001,
  title = {Informacja Nt. {{TeXLive}} 6 (Information about {{TeXlive}} 6)},
  author = {Popineau, Fabrice and Wawrykiewicz, Stanislaw},
  year = {2001},
  month = apr,
  keywords = {\#nosource,⛔ No DOI found,poster,TeX}
}

@book{popineauLogiqueRaisonnementArtificiel1993,
  title = {{Logique du Raisonnement Artificiel}},
  author = {Popineau, Fabrice},
  year = {1993},
  publisher = {{Sup\'elec}},
  langid = {french},
  keywords = {\#nosource,poly}
}

@misc{popineauLuaTeXUnicode2007,
  title = {{{LuaTeX}} et {{Unicode}}},
  author = {Popineau, Fabrice},
  year = {2007},
  month = oct,
  keywords = {conf,TeX},
  file = {C\:\\Home\\Zotero\\storage\\LQBKDS9R\\Popineau - 2007 - LuaTeX et Unicode.pdf}
}

@article{popineauMETAPOSTPratique2001,
  title = {{METAPOST pratique}},
  author = {Popineau, Fabrice},
  year = {2001},
  journal = {Cahiers GUTenberg},
  number = {41},
  pages = {167--175},
  issn = {1140-9304},
  doi = {10/ghfbvj},
  url = {http://cahiers.gutenberg.eu.org/fitem?id=CG_2001___41_167_0},
  urldate = {2021-08-07},
  abstract = {In this article, I will explain how to pratically use METAPOST. This program is very different from usual drawing programs, but it fits very well in a TEX based typesetting system.},
  langid = {french},
  keywords = {\#nosource,journal,TeX},
  file = {C\:\\Home\\Zotero\\storage\\6WTEMH8I\\Popineau - 2001 - METAPOST pratique.pdf}
}

@book{popineauModelisationOrienteeObjet1997,
  title = {{Mod\'elisation Orient\'ee Objet}},
  author = {Popineau, Fabrice},
  year = {1997},
  publisher = {{Sup\'elec}},
  langid = {french},
  keywords = {\#nosource,poly}
}

@inproceedings{popineauPersonalizationPersonificationConstructive2014,
  title = {Personalization and Personification: {{A}} Constructive Approach Based on Parametric Agents},
  booktitle = {Intelligent Virtual Agents - 14th International Conference, {{IVA}} 2014},
  author = {Popineau, Fabrice and Dubus, Georges and Bourda, Yolaine},
  editor = {Bickmore, Timothy W. and Marsella, Stacy and Sidner, Candace L.},
  year = {2014},
  month = aug,
  series = {Lecture Notes in Computer Science},
  volume = {8637},
  pages = {339--344},
  publisher = {{Springer}},
  address = {{Boston, MA, USA}},
  doi = {10.1007/978-3-319-09767-1\_44},
  url = {https://doi.org/10.1007/978-3-319-09767-1_44},
  copyright = {All rights reserved},
  keywords = {\#nosource,⚠️ Invalid DOI,conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\Y6YX7PEG\\Popineau et al. - 2014 - Personalization and personification A constructiv.pdf}
}

@article{popineauRapiditeSouplesseAvec1997,
  title = {Rapidit\'e et Souplesse Avec Le Moteur {{Web2C-7}}},
  author = {Popineau, Fabrice},
  year = {1997},
  journal = {Cahiers GUTenberg},
  number = {26},
  pages = {96--108},
  doi = {10/ghfbvg},
  keywords = {\#nosource,conf,TeX},
  file = {C\:\\Home\\Zotero\\storage\\C3QXI4XT\\Popineau - 1997 - Rapidité et souplesse avec le moteur Web2C-7.pdf}
}

@article{popineauStatusFutureTeXLive2002,
  title = {Status and Future of {{TeXLive}}},
  author = {Popineau, Fabrice},
  year = {2002},
  month = feb,
  keywords = {\#nosource,⛔ No DOI found,poster,TeX}
}

@article{popineauTeXLiveWindowsWhat2002,
  title = {{{TeXLive}} under {{Windows}}: What's New with the 7\textsuperscript{t}\textsuperscript{h} Edition?},
  author = {Popineau, Fabrice},
  year = {2002},
  month = sep,
  journal = {TUGBoat},
  volume = {23},
  number = {1},
  pages = {74--79},
  abstract = {The 7th edition of TEX Live under Windows has some new features that are explained in this paper. Especially notable are two experiments to extend Kpathsea beyond its original abilities: \textbullet{} sharing Kpathsea data-structures between several processes for faster processing, \textbullet{} allow url's in client programs as well as filenames whenever they ask Kpathsea to open a file. Additional points about the TeXSetup.exe program and the evolution of other parts of the distribution will also be discussed.},
  langid = {english},
  keywords = {⛔ No DOI found,conf,TeX},
  file = {C\:\\Home\\Zotero\\storage\\NSP8DW9S\\Popineau - 2002 - TeXLive under Windows what's new with the 7ᵗʰ edi.pdf}
}

@misc{popineauUKTUGSpecialWin321999,
  title = {{{UK-TUG}} Special Win32 Meeting},
  author = {Popineau, Fabrice},
  year = {1999},
  month = may,
  keywords = {\#nosource,⛔ No DOI found,conf,TeX},
  file = {C\:\\Home\\Zotero\\storage\\K6XD56DU\\Popineau - 1999 - UK-TUG special win32 meeting.pdf}
}

@article{popineauWindviUserManual1998,
  title = {Windvi User's Manual},
  author = {Popineau, Fabrice},
  year = {1998},
  journal = {MAPS},
  volume = {20},
  pages = {146--149},
  keywords = {\#nosource,⛔ No DOI found,journal,TeX},
  file = {C\:\\Home\\Zotero\\storage\\BGS7A4QJ\\Popineau - 1998 - Windvi user’s manual.pdf}
}

@inproceedings{popineauWorkshopElicitingAdaptive2018,
  title = {Workshop Eliciting {{Adaptive Sequences}} for {{Learning}} ({{WeASeL}}) 2018},
  booktitle = {Proceedings of the 1st {{International Workshop}} Eliciting {{Adaptive Sequences}} for {{Learning}} Co-Located with the 14th {{International Conference}} on {{Intelligent Tutoring Systems}} ({{ITS}} 2018)},
  author = {Popineau, Fabrice and Valko, Michal and Vie, Jill-J{\^e}nn},
  editor = {Guin, Nathalie and Kumar, Amruth N.},
  year = {2018},
  series = {{{CEUR}} Workshop Proceedings},
  volume = {2354},
  pages = {141--143},
  publisher = {{CEUR-WS.org}},
  url = {http://ceur-ws.org/Vol-2354/w4preface.pdf},
  keywords = {\#nosource,⛔ No DOI found,conf,EIAH}
}

@misc{rahtzOccultSecretsTEXLive2003,
  title = {The {{Occult Secrets}} of {{TEXLive}}},
  author = {Rahtz, Sebastian and Popineau, Fabrice},
  year = {2003},
  month = aug,
  address = {{Hawaii}},
  langid = {english},
  keywords = {⛔ No DOI found,poster,TeX},
  file = {C\:\\Home\\Zotero\\storage\\H27NM9U8\\Rahtz et Popineau - 2003 - The Occult Secrets of TEXLive.pdf}
}

@book{russelIntelligenceArtificielle3e2010,
  title = {{Intelligence artificielle 3e \'edition : Avec plus de 500 exercices}},
  shorttitle = {{Intelligence artificielle 3e \'edition}},
  author = {Russel, Stuart and Norvig, Peter},
  translator = {Popineau, Fabrice},
  year = {2010},
  month = dec,
  publisher = {{PEARSON}},
  address = {{Paris}},
  abstract = {\'Ecrit par les experts de renomm\'ee mondiale, ce livre est la r\'ef\'erence incontournable en mati\`ere d'intelligence artificielle (IA) dont il pr\'esente et analyse tous les concepts : logique, probabilit\'es, math\'ematiques discr\`etes et du continu, perception, raisonnement, apprentissage, prise de d\'ecision et action. Sa sp\'ecificit\'e est de pr\'esenter l'IA \`a travers le concept des agents intelligents. Les auteurs exposent comment un syst\`eme r\'eussit \`a percevoir son environnement de mani\`ere \`a analyser ce qu'il s'y passe, et comment il transforme la perception qu'il a de son environnement en actions concr\`etes. Parmi les sujets couverts : - les contributions historiques des math\'ematiques, de la th\'eorie des jeux, de l'\'economie, de la th\'eorie des probabilit\'es, de la psychologie, de la linguistique et des neurosciences; - les m\'ethodes qui permettent de prendre des d\'ecisions lors de l'\'etablissement d'un projet, en tenant compte des \'etapes \`a venir; - les diff\'erentes mani\`eres de repr\'esenter formellement les connaissances relatives au monde qui nous entoure ainsi que le raisonnement logique fond\'e sur ces connaissances; - les m\'ethodes de raisonnement qui permettent d'\'etablir des plans et donc de proposer des actions \`a entreprendre; - la prise de d\'ecisions en environnement incertain : r\'eseaux bay\'esiens et algorithmes tels que l'\'elimination de variables et MCMC (Markov Chain Monte-Carlo); - les m\'ethodes employ\'ees pour g\'en\'erer les connaissances exig\'ees par les composants de prise de d\'ecision : les algorithmes de boosting, l'algorithme EM (expectation-minimization), l'apprentissage \`a base d'exemples et les m\'ethodes \`a noyaux (machines \`a vecteurs support); - les implications philosophiques et \'ethiques de l'IA. Chaque chapitre est illustr\'e par de nombreux exemples et s'ach\`eve par des activit\'es, qui vont des exercices de r\'eflexion \`a des exercices de programmation, en passant par l'approfondissement des m\'ethodes d\'ecrites, soit plus de 500 activit\'es au total. Cette 3e \'edition tient compte des derniers d\'eveloppements de la mati\`ere, concernant notamment les repr\'esentations qu'un agent peut utiliser (atomique, factoris\'ee, structur\'ee), les environnements partiellement observables et non d\'eterministes, les planifications contingente et hi\'erarchique, les mod\`eles probabilistes du premier ordre, l'apprentissage automatique, la recherche et l'extraction d'information sur le web et l'apprentissage \`a partir de tr\`es grandes bases de donn\'ees.},
  isbn = {978-2-7440-7455-4},
  langid = {french},
  keywords = {\#nosource,artificial intelligence,otherpub}
}

@book{russellIntelligenceArtificielle2nde2006,
  title = {{Intelligence artificielle 2nde \'edition}},
  author = {Russell, Stuart and Norvig, Peter},
  translator = {Miclet, Laurent and Popineau, Fabrice and Baland, Marie-C{\'e}cile},
  year = {2006},
  month = sep,
  publisher = {{PEARSON}},
  address = {{Paris}},
  abstract = {Il aborde:- Tous les aspects de la discipline : logique, probabilits et mathmatiques du continu, perception, raison-nement, apprentissage et action. - Les diffrentes mthodes utiles la prise de dcision lors de la ralisation de projets. - Lapplication de ces mthodes en fonction des diffrentes possibilits de reprsentation, notamment lors de la construction de plans. - Les diffrents domaines dapplication : langage crit et parl, perception visuelle, robotiqueLintrt de ce manuel est de prsenter lIA travers le concept dagents intelligents (systmes qui dcident de ce qu'il convient de faire). Il dcrit: - La perception de lenvironnement par lagent intelligent pour dterminer et analyser ce quil s'y passe (par la vision, le toucher, l'oue ou le langage). - La transformation de la perception en actions concrtes. Dans cette optique, la robotique et la vision sont traites dans le cadre de leur contribution l'obtention de buts, et les auteurs insistent sur l'importance de l'environnement. Ainsi, certains agents doivent rsoudre des problmes combinatoires (jeux, labyrinthes, satisfaction de contraintes), dautres raisonnent (logique, dmonstration), dautres encore apprennent. Prs de 400 exercices sont proposs. Ils vont des exercices de rflexion aux exercices de programmation, en passant par lapprofondissement des mthodes dcrites.},
  isbn = {978-2-7440-7150-8},
  langid = {french},
  keywords = {\#nosource,artificial intelligence,otherpub}
}

@book{schaaEuroTeX20052005,
  title = {{{EuroTeX}} 2005},
  author = {Schaa, Volker RW and Popineau, Fabrice and Andr{\'e}, Jacques and Hagen, Hans and Flipo, Daniel and Jackowski, Bogus{\l}aw and Bzyl, W{\l}odzimierz and Sojka, Petr and Bilotta, Giuseppe and Grathwohl, Steve and Raichle, Bernd},
  year = {2005},
  month = mar,
  series = {{{TUGBoat}}},
  edition = {TeX Users Group},
  volume = {85},
  address = {{Abbaye des Pr\'emontr\'es, Pont-\`a-Mousson, France}},
  langid = {english},
  keywords = {⛔ No DOI found,conf,TeX},
  file = {C\:\\Home\\Zotero\\storage\\TNTJTE7R\\Schaa et al. - 2005 - EuroTeX 2005.pdf}
}

@inproceedings{vieAdaptiveTestingUsing2016,
  title = {Adaptive {{Testing Using}} a {{General Diagnostic Model}}},
  booktitle = {11th {{European Conference}} on {{Technology Enhanced Learning}}, {{EC-}}TEL 2016},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Bruillard, Eric and Bourda, Yolaine},
  year = {2016},
  month = sep,
  series = {Lecture Notes in Computer Science},
  volume = {9891},
  pages = {331--339},
  publisher = {{Springer International Publishing}},
  address = {{Lyon, France}},
  url = {https://hal.inria.fr/hal-01376944},
  urldate = {2021-08-07},
  abstract = {In online learning platforms such as MOOCs, computerized assessment needs to be optimized in order to prevent boredom and dropout of learners. Indeed, they should spend as little time as possible in tests and still receive valuable feedback. It is actually possible to reduce the number of questions for the same accuracy with computerized adaptive testing (CAT): asking the next question according to the past performance of the examinee. CAT algorithms are divided in two categories: summative CATs, that measure the level of examinees, and formative CATs, that provide feedback to the examinees at the end of the test by specifying which knowledge components need further work. In this paper, we formalize the problem of test-size reduction by predicting student performance, and propose a new hybrid CAT algorithm GenMA based on the general diagnostic model, that is both summative and formative. Using real datasets, we compare our model to popular CAT models and show that GenMA achieves better accuracy while using fewer questions than the existing models.},
  copyright = {All rights reserved},
  keywords = {⚠️ Invalid DOI,conf,EIAH},
  file = {C\:\\Home\\Zotero\\storage\\CHSKBMD6\\Vie et al. - 2016 - Adaptive Testing Using a General Diagnostic Model.pdf}
}

@article{vieAutomatedTestAssembly2018,
  title = {Automated {{Test Assembly}} for {{Handling Learner Cold-Start}} in {{Large-Scale Assessments}}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Bruillard, Eric and Bourda, Yolaine},
  year = {2018},
  journal = {Int. J. Artif. Intell. Educ.},
  volume = {28},
  number = {4},
  pages = {616--631},
  doi = {10/gdvnnj},
  url = {https://doi.org/10.1007/s40593-017-0163-y},
  keywords = {⛔ No DOI found,EIAH,journal},
  file = {C\:\\Home\\Zotero\\storage\\MSK5RZJ2\\Vie et al. - 2018 - Automated Test Assembly for Handling Learner Cold-.pdf}
}

@inproceedings{vieHeuristicMethodLargeScale2017,
  title = {A {{Heuristic Method}} for {{Large-Scale Cognitive-Diagnostic Computerized Adaptive Testing}}},
  booktitle = {Proceedings of the {{Fourth}} (2017) {{ACM Conference}} on {{Learning}} @ {{Scale}}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Tort, Fran{\c c}oise and Marteau, Benjamin and Denos, Nathalie},
  year = {2017},
  month = apr,
  pages = {323--326},
  publisher = {{ACM}},
  address = {{Cambridge Massachusetts USA}},
  doi = {10/ghfbvf},
  url = {https://dl.acm.org/doi/10.1145/3051457.3054015},
  urldate = {2021-08-07},
  abstract = {In formative assessments, one wants to provide a useful feedback to the examinee at the end of the test. In order to reduce the number of questions asked in an assessment, adaptive testing models have been developed for cognitive diagnosis, such as the ones encountered in knowledge space theory. However, when the number of skills assessed is very huge, such methods cannot scale. In this paper, we present a new method to provide adaptive tests and useful feedback to the examinee, even with large databases of skills. It will be used in Pix, a platform for certification of digital competencies for every French citizen.},
  copyright = {All rights reserved},
  isbn = {978-1-4503-4450-0},
  langid = {english},
  keywords = {EIAH,poster},
  file = {C\:\\Home\\Zotero\\storage\\T8JAWCUW\\Vie et al. - 2017 - A Heuristic Method for Large-Scale Cognitive-Diagn.pdf}
}

@phdthesis{vieModelesTestsAdaptatifs2016,
  type = {{Th\`ese de doctorat}},
  title = {{Mod\`eles de tests adaptatifs pour le diagnostic de connaissances dans un cadre d'apprentissage \`a grande \'echelle}},
  author = {Vie, Jill-J{\^e}nn},
  year = {2016},
  month = dec,
  url = {https://theses.fr/2016SACLC090},
  urldate = {2021-08-07},
  abstract = {Cette th\`ese porte sur les tests adaptatifs dans les environnements d'apprentissage. Elle s'inscrit dans les contextes de fouille de donn\'ees \'educatives et d'analytique de l'apprentissage, o\`u l'on s'int\'eresse \`a utiliser les donn\'ees laiss\'ees par les apprenants dans des environnements \'educatifs pour optimiser l'apprentissage au sens large.L'\'evaluation par ordinateur permet de stocker les r\'eponses des apprenants facilement, afin de les analyser et d'am\'eliorer les \'evaluations futures. Dans cette th\`ese, nous nous int\'eressons \`a un certain type de test par ordinateur, les tests adaptatifs. Ceux-ci permettent de poser une question \`a un apprenant, de traiter sa r\'eponse \`a la vol\'ee, et de choisir la question suivante \`a lui poser en fonction de ses r\'eponses pr\'ec\'edentes. Ce processus r\'eduit le nombre de questions \`a poser \`a un apprenant tout en conservant une mesure pr\'ecise de son niveau. Les tests adaptatifs sont aujourd'hui impl\'ement\'es pour des tests standardis\'es tels que le GMAT ou le GRE, administr\'es \`a des centaines de milliers d'\'etudiants. Toutefois, les mod\`eles de tests adaptatifs traditionnels se contentent de noter les apprenants, ce qui est utile pour l'institution qui \'evalue, mais pas pour leur apprentissage. C'est pourquoi des mod\`eles plus formatifs ont \'et\'e propos\'es, permettant de faire un retour plus riche \`a l'apprenant \`a l'issue du test pour qu'il puisse comprendre ses lacunes et y rem\'edier. On parle alors de diagnostic adaptatif.Dans cette th\`ese, nous avons r\'epertori\'e des mod\`eles de tests adaptatifs issus de diff\'erents pans de la litt\'erature. Nous les avons compar\'es de fa\c{c}on qualitative et quantitative. Nous avons ainsi propos\'e un protocole exp\'erimental, que nous avons impl\'ement\'e pour comparer les principaux mod\`eles de tests adaptatifs sur plusieurs jeux de donn\'ees r\'eelles. Cela nous a amen\'es \`a proposer un mod\`ele hybride de diagnostic de connaissances adaptatif, meilleur que les mod\`eles de tests formatifs existants sur tous les jeux de donn\'ees test\'es. Enfin, nous avons \'elabor\'e une strat\'egie pour poser plusieursquestions au tout d\'ebut du test afin de r\'ealiser une meilleure premi\`ere estimation des connaissances de l'apprenant. Ce syst\`eme peut \^etre appliqu\'e \`a la g\'en\'eration automatique de feuilles d'exercices, par exemple sur un cours en ligne ouvert et massif (MOOC).},
  collaborator = {Bourda, Yolaine and Bruillard, {\'E}ric and Popineau, Fabrice},
  copyright = {Licence Etalab},
  langid = {french},
  school = {Universit\'e Paris-Saclay (ComUE)},
  keywords = {Adaptive testing,Analytique de l'apprentissage,Cognitive diagnosis,Cours en ligne ouverts à tous,Cours en ligne ouverts et massifs (MOOC),Diagnostic de connaissances,Exploration de données,Formation en ligne,Item response theory,Learning analytics,Massive open online courses (MOOCs),Q-Matrice,Q-Matrix,Systèmes adaptatifs (informatique),Technologie éducative,Tests adaptatifs,Théorie de la réponse à l'item,Thesis},
  file = {C\:\\Home\\Zotero\\storage\\KTHRC3D9\\Vie - 2016 - Modèles de tests adaptatifs pour le diagnostic de .pdf}
}

@inproceedings{viePredictingPerformanceDichotomous2015,
  title = {Predicting {{Performance}} on {{Dichotomous Questions}}: {{Comparing Models}} for {{Large-Scale Adaptive Testing}}},
  shorttitle = {Predicting {{Performance}} over {{Dichotomous Questions}}},
  booktitle = {Proceedings of the 8th International Conference on Educational Data Mining, {{EDM}} 2015, Madrid, Spain, June 26-29, 2015},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Grill, Jean-Bastien and Bruillard, Eric and Bourda, Yolaine},
  year = {2015},
  month = jun,
  pages = {618--619},
  publisher = {{International Educational Data Mining Society (IEDMS)}},
  url = {http://www.educationaldatamining.org/EDM2015/proceedings/poster618-619.pdf},
  urldate = {2021-08-07},
  abstract = {Computerized adaptive testing (CAT) is a mode of testing which has gained increasing popularity over the past years. It selects the next question to ask to the examinee in order to evaluate her level efficiently, by using her answers to the previous questions. Traditionally, CAT systems have been relying on item response theory (IRT) in order to provide an effective measure of latent abilities in possibly large-scale assessments. More recently, from the perspective of providing useful feedback to examinees, other models have been studied for cognitive diagnosis. One of them is the q-matrix model, which draws a link between questions and examinee knowledge components. In this paper, we define a protocol based on performance prediction to evaluate adaptive testing algorithms. We use it to evaluate q-matrices in the context of assessments and compare their behavior to item response theory. Results computed on three real datasets of growing size and of various nature suggest that tests of different type need different models.},
  langid = {english},
  keywords = {\#nosource,⛔ No DOI found,conf,EIAH,poster},
  file = {C\:\\Home\\Zotero\\storage\\LKCT3PNV\\Vie et al. - 2015 - Predicting Performance on Dichotomous Questions C.pdf}
}

@inproceedings{viePredictionPerformanceQuestions2015,
  title = {{Pr\'ediction de performance sur des questions dichotomiques: comparaison de mod\`eles pour des tests adaptatifs \`a grande \'echelle}},
  shorttitle = {{Pr\'ediction de performance sur des questions dichotomiques}},
  booktitle = {{Atelier \'Evaluation des Apprentissages et Environnements Informatiques, EIAH 2015}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Grill, Jean-Bastien and Bruillard, Eric and Bourda, Yolaine},
  year = {2015},
  month = jun,
  publisher = {{International Educational Data Mining Society (IEDMS)}},
  address = {{Agadir, Morocco}},
  url = {https://hal.archives-ouvertes.fr/hal-01275277},
  urldate = {2021-08-07},
  abstract = {Les tests adaptatifs sont un moyen d'\'evaluation qui a r\'ecemment gagn\'e en popularit\'e. Ils s\'electionnent la prochaine question \`a poser \`a un examin\'e de mani\`ere \`a estimer son niveau efficacement, en fonction de ses r\'eponses aux questions pr\'ec\'edentes. Les syst\`emes de tests adaptatifs se sont d'abord appuy\'es sur la th\'eorie de la r\'eponse \`a l'item (TRI) afin de fournir une mesure efficace des traits latents dans des \'evaluations pouvant \^etre \`a grande \'echelle. Plus r\'ecemment, dans l'optique de fournir un retour utile \`a l'examin\'e, d'autres mod\`eles ont \'et\'e \'etudi\'es dans la th\'eorie du diagnostic cognitif. L'un d'eux est le mod\`ele qmatrice, qui \'etablit un lien entre questions du test et comp\'etences de l'examin\'e. Dans cet article, nous d\'efinissons un protocole bas\'e sur la pr\'ediction de performance pour \'evaluer deux mod\`eles de tests adaptatifs : qmatrice et le mod\`ele de Rasch issu de la TRI. Les r\'esultats obtenus sur trois jeux de donn\'ees r\'eelles de diff\'erente taille et nature montrent que selon les caract\'eristiques du test, l'un ou l'autre mod\`ele pr\'edit le mieux la performance de l'examin\'e.},
  langid = {french},
  keywords = {\#nosource,⛔ No DOI found,conf,EIAH,poster},
  file = {C\:\\Home\\Zotero\\storage\\IE7PVA65\\Vie et al. - 2015 - Prédiction de performance sur des questions dichot.pdf}
}

@incollection{vieReviewRecentAdvances2017,
  title = {A {{Review}} of {{Recent Advances}} in {{Adaptive Assessment}}},
  booktitle = {Learning {{Analytics}}: {{Fundaments}}, {{Applications}}, and {{Trends}}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Bruillard, {\'E}ric and Bourda, Yolaine},
  year = {2017},
  month = feb,
  series = {Studies in {{Systems}}, {{Decision}} and {{Control}}},
  volume = {94},
  pages = {113--142},
  publisher = {{Springer International Publishing}},
  url = {https://hal.archives-ouvertes.fr/hal-01488284},
  urldate = {2021-08-07},
  abstract = {Computerized assessments are an increasingly popular way to evaluate students. They need to be optimized so that students can receive an accurate evaluation in as little time as possible. Such optimization is possible through learning analytics and computerized adaptive tests (CATs): the next question is then chosen according to the previous responses of the student, thereby making assessment more efficient. Using the data collected from previous students in non-adaptive tests, it is thus possible to provide formative adaptive tests to new students by telling them what to do next. This chapter reviews several models of CATs found in various fields, together with their main characteristics. We then compare these models empirically on real data. We conclude with a discussion of future research directions for computerized assessments.},
  copyright = {All rights reserved},
  keywords = {\#nosource,adaptive testing,cognitive diagnosis models,EIAH,inbook,item response theory,knowledge space theory,latent knowledge extraction,q-matrix},
  file = {C\:\\Home\\Zotero\\storage\\3EXSQZY6\\Vie et al. - 2017 - A Review of Recent Advances in Adaptive Assessment.pdf}
}

@article{vieSimulationValidationTests2017,
  title = {Simulation et Validation de Tests Adaptatifs Dans Les {{MOOC}}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Bruillard, Eric and Bourda, Yolaine},
  year = {2017},
  journal = {Sciences et Technologies de l'Information et de la Communication pour l'\'Education et la Formation},
  volume = {24},
  number = {2},
  pages = {149--167},
  doi = {10/ghfbvd},
  copyright = {All rights reserved},
  keywords = {\#nosource,EIAH,journalnat},
  file = {C\:\\Home\\Zotero\\storage\\3UDYBKJT\\Vie et al. - 2017 - Simulation et validation de tests adaptatifs dans .pdf}
}

@inproceedings{zemirlineAssistingReuseAdaptive2008,
  title = {Assisting in {{Reuse}} of {{Adaptive Hypermedia Creator}}'s {{Models}}},
  booktitle = {Adaptive {{Hypermedia}} and {{Adaptive Web-Based Systems}}},
  author = {Zemirline, Nadjet and Bourda, Yolaine and Reynaud, Chantal and Popineau, Fabrice},
  editor = {Nejdl, Wolfgang and Kay, Judy and Pu, Pearl and Herder, Eelco},
  year = {2008},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {5149},
  pages = {357--360},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Hannover,, Germany}},
  doi = {10.1007/978-3-540-70987-9\_53},
  url = {http://link.springer.com/10.1007/978-3-540-70987-9_53},
  urldate = {2019-05-08},
  abstract = {The design of Adaptive Hypermedia is a difficult task which can be made easier if generic systems and AH creators' models are reused. We address this design problem in the setting of the GLAM platform only made up of generic components. We present a rule-based approach helping an AH creator in reusing its user and domain models to create a specific adaptive hypermedia. This semi-automatic approach takes the creator's models as specialisations of GLAM generic models and requires the creator to express a minimum set of mappings between his models and the generic ones. The process results in a merged model consisting of the generic and the corresponding specific model. This merged model can be used by the adaptation model.},
  isbn = {978-3-540-70984-8},
  langid = {english},
  keywords = {\#nosource,⚠️ Invalid DOI,conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\NZMZ5S8Y\\Zemirline et al. - 2008 - Assisting in Reuse of Adaptive Hypermedia Creator’.pdf}
}

@inproceedings{zemirlineMESAMProtegePlugin2009,
  title = {{{MESAM}}: {{A Prot\'eg\'e Plug-in}} for the {{Specialization}} of {{Models}}},
  shorttitle = {{{MESAM}}},
  booktitle = {11th {{International Prot\'eg\'e Conference}}},
  author = {Zemirline, Nadjet and Bourda, Yolaine and Reynaud, Chantal and Popineau, Fabrice},
  year = {2009},
  month = jun,
  pages = {3 pages},
  address = {{Amsterdam, Netherlands}},
  url = {https://hal-supelec.archives-ouvertes.fr/hal-00431319},
  urldate = {2021-08-07},
  abstract = {Nowadays, several efforts are focused on re-using generic platforms to create new systems, in order to make the design process easier and faster. Often, the designer has his own models and resources and would like to reuse the generic system over his resources. That means, he has to integrate his models and resources in the system, and then to directly reuse the generic system. But many problems occur. One of them is that the designer needs to translate his models into the specific format that understood by the system and to use the vocabulary specific to that system. Furthermore, he also needs to translate all the instantiations of his models (i.e. the resources and their metadata). We think that this task is tedious and time-consuming and we want to avoid it. Our objective is to allow the designer to reuse his models (his vocabulary) and his models' instantiations without any change of format or vocabulary. For example, a generic Adaptive Hypermedia System (AHS) is made of a generic adaptation model relying on generic user and domain models. The designer would like to integrate his models and instances in the generic models in order to reuse the generic adaptation engine. Specific systems can be obtained by specializing the generic models. However, this specialization process is not always easy to perform. It has to be supported to make the design process easier and faster. This paper focuses on assisting designers to specialize generic models using their own models. We aim to automate this process which has been so far entirely manual. Our objectives are twofold: to create a support for defining mappings between elements in generic models and elements in the designer's personal models and to help creating consistent and relevant models integrating the generic and specific ones and taking into account the mappings between them. The proposed approach relies on OWL1, a W3C standard and SWRL2, a W3C proposal.},
  keywords = {conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\37CYFQ9T\\Zemirline et al. - 2009 - MESAM A Protégé Plug-in for the Specialization of.pdf}
}

@inproceedings{zemirlinePatternRulebasedApproach2008,
  title = {A Pattern and Rule-Based Approach for Reusing Adaptive Hypermedia Creator's Models},
  booktitle = {Proceedings of 16th International Conference on Knowledge Engineering and Knowledge Management Knowledge Patterns},
  author = {Zemirline, Nadjet and Reynaud, Chantal and Bourda, Yolaine and Popineau, Fabrice},
  editor = {Gangemi, Aldo and Euzenat, J{\'e}r{\^o}me},
  year = {2008},
  series = {Lecture Notes in Computer Science},
  volume = {5268},
  pages = {17--31},
  publisher = {{Springer-Verlag}},
  address = {{Acitrezza, Catania, Italie}},
  doi = {10.1007/978-3-540-87696-0\_5},
  url = {https://doi.org/10.1007/978-3-540-87696-0_5},
  copyright = {All rights reserved},
  keywords = {⚠️ Invalid DOI,❓ Multiple DOI,conf,EIAH,VAE},
  file = {C\:\\Home\\Zotero\\storage\\YE93ZZCA\\Zemirline et al. - 2008 - A pattern and rule-based approach for reusing adap.pdf}
}


