@incollection{hajriPersonalizedRecommendationOpen2018,
  title = {Personalized {{Recommendation}} of {{Open Educational Resources}} in {{MOOCs}}},
  booktitle = {Computer {{Supported Education}} - 10th {{International Conference}}, {{CSEDU}} 2018, {{Funchal}}, {{Madeira}}, {{Portugal}}, {{March}} 15-17, 2018, {{Revised Selected Papers}}},
  author = {Hajri, Hiba and Bourda, Yolaine and Popineau, Fabrice},
  editor = {McLaren, Bruce M. and Reilly, Rob and Zvacek, Susan and Uhomoibhi, James},
  year = {2018},
  series = {Communications in {{Computer}} and {{Information Science}}},
  volume = {1022},
  pages = {166--190},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-21151-6_9},
  url = {http://link.springer.com/10.1007/978-3-030-21151-6_9},
  urldate = {2021-08-07},
  abstract = {Today Online Learning Environments (OLE) like MOOCs and LMS are very commonly used and a huge number of students with very different profiles and backgrounds follow the same online courses. Still, personalized experience for attendees is not widely spread on the platforms hosting these courses. At the same time, there is a growing number of open educational resources (OER) that can helpfully enrich the content of online courses and even be chosen to match one-by-one the student tastes. Recommender systems may support personalization in OLE by providing each learner with learning objects carefully selected to help reaching their learning objectives. This kind of recommendation is more specific to compute than usual recommendations like consumer products: the recommendation depends not only on the learner profile, but also on the content of the course, because the recommendation needs to fit precisely with the course format at any point. In this article, we introduce MOORS, a MOOC-based OER recommender system that can be plugged in an OLE to dynamically provide recommendations of OER to learners on the basis of their profiles and the profile of the MOOC. We also describe the process for calculating recommendations from OER metadata, assuming these metadata follow the Linked Opend Data (LOD) principles. Our implementation has been done in Open edX, an open source MOOC platform widely used, however the same approach could be implemented in any OLE as long as the learners profiles and the course profile can be extracted. Finally, we discuss a life-size evaluation of our recommender system.},
  isbn = {978-3-030-21150-9},
  langid = {english},
  keywords = {⚠️ Invalid DOI,conf,EIAH,inbook,VAE},
  file = {C\:\\Home\\Zotero\\storage\\CIFIKXIR\\Hajri et al. - 2018 - Personalized Recommendation of Open Educational Re.pdf}
}

@incollection{hayAutomaticallySelectingComplementary2018,
  title = {Automatically {{Selecting Complementary Vector Representations}} for {{Semantic Textual Similarity}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Management}}: {{Volume}} 8},
  author = {Hay, Julien and {Van de Cruys}, Tim and Muller, Philippe and Doan, Bich-Li{\^e}n and Popineau, Fabrice and Hay, Julien and Van De Cruys, Tim and Muller, Philippe and Doan, Bich-Lien and Popineau, Fabrice and Ouassim, Ait-Elhara},
  editor = {Pinaud, Bruno and Guillet, Fabrice and Gandon, Fabien and Largeron, Christine},
  year = {2018},
  series = {Studies in {{Computational Intelligence}}},
  volume = {834},
  pages = {45--60},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  url = {https://doi.org/10.1007/978-3-030-18129-1_3},
  abstract = {The goal of the Semantic Textual Similarity task is to automatically quantify the semantic similarity of two text snippets. Since 2012, the task has been organized on a yearly basis as a part of the SemEval evaluation campaign. This paperHay, Julien~presentsVan de Cruys, Tim~a method that aims to combine differentMuller, Philippe~sentence-based vector representations in order to improve the computation of semantic similarity values. Our hypothesis is that such a combinationDoan, Bich-Li\^en~of different representations allows us to pinpoint different semantic aspects, which improves the accuracy ofPopineau, Fabrice~similarity computations. The method's main difficulty lies in the selection of the most complementaryAit-Elhara, Ouassim\textasciitilde{} representations, for which we present an optimization method. Our final system is based on the winning system of the 2015 evaluation campaign, augmented with the complementary vector representations selected by our optimization method. We also present evaluation results on the dataset of the 2016 campaign, which confirms the benefit of our method.},
  copyright = {All rights reserved},
  isbn = {978-3-030-18129-1},
  keywords = {⚠️ Invalid DOI,⛔ No DOI found,inbook,IR},
  file = {C\:\\Home\\Zotero\\storage\\BF3TTFPE\\Hay et al. - 2018 - Automatically selecting complementary vector repre.pdf;C\:\\Home\\Zotero\\storage\\X4MHB2MR\\Hay et al. - 2019 - Automatically Selecting Complementary Vector Repre.pdf}
}

@incollection{vieReviewRecentAdvances2017,
  title = {A {{Review}} of {{Recent Advances}} in {{Adaptive Assessment}}},
  booktitle = {Learning {{Analytics}}: {{Fundaments}}, {{Applications}}, and {{Trends}}},
  author = {Vie, Jill-J{\^e}nn and Popineau, Fabrice and Bruillard, {\'E}ric and Bourda, Yolaine},
  year = {2017},
  month = feb,
  series = {Studies in {{Systems}}, {{Decision}} and {{Control}}},
  volume = {94},
  pages = {113--142},
  publisher = {{Springer International Publishing}},
  url = {https://hal.archives-ouvertes.fr/hal-01488284},
  urldate = {2021-08-07},
  abstract = {Computerized assessments are an increasingly popular way to evaluate students. They need to be optimized so that students can receive an accurate evaluation in as little time as possible. Such optimization is possible through learning analytics and computerized adaptive tests (CATs): the next question is then chosen according to the previous responses of the student, thereby making assessment more efficient. Using the data collected from previous students in non-adaptive tests, it is thus possible to provide formative adaptive tests to new students by telling them what to do next. This chapter reviews several models of CATs found in various fields, together with their main characteristics. We then compare these models empirically on real data. We conclude with a discussion of future research directions for computerized assessments.},
  copyright = {All rights reserved},
  keywords = {\#nosource,adaptive testing,cognitive diagnosis models,EIAH,inbook,item response theory,knowledge space theory,latent knowledge extraction,q-matrix},
  file = {C\:\\Home\\Zotero\\storage\\3EXSQZY6\\Vie et al. - 2017 - A Review of Recent Advances in Adaptive Assessment.pdf}
}
